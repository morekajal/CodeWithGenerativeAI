{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961bf896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619a56fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33134e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8585b86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists\n",
      "Gemini API Key exists\n"
     ]
    }
   ],
   "source": [
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists\")\n",
    "else:\n",
    "    print(\"OpenAI API Key Not Set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Gemini API Key exists\")\n",
    "else:\n",
    "    print(\"Gemini API Key Not Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775ae59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence.\"\n",
    "request += \"Answer only with the questions, no explanation. \"\n",
    "messages = [{\"role\": \"user\", \"content\" : request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6cec88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence.Answer only with the questions, no explanation. '}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7cf546",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177e7e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you approach the ethical implications of using artificial intelligence in surveillance technologies, considering the balance between national security and individual privacy rights?\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b540d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check with different LLMs\n",
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\":\"user\", \"content\":question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cac85b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "# claude = Anthropic()\n",
    "# response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "# answer = response.content[0].text\n",
    "\n",
    "# display(MArkdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65862995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The ethical implications of using artificial intelligence (AI) in surveillance technologies are indeed complex and warrant a multifaceted approach. Balancing national security with individual privacy rights involves careful consideration of several key factors:\n",
       "\n",
       "1. **Transparency and Accountability**: It is crucial to establish clear guidelines and accountability mechanisms regarding how surveillance technologies are deployed. Governments and organizations should be transparent about their use of AI in surveillance, including the purpose, scope, and methods employed. This transparency can build public trust and ensure that stakeholders understand how their data is being used.\n",
       "\n",
       "2. **Legal Frameworks**: There should be robust legal protections in place that delineate the boundaries of surveillance practices. This includes ensuring that any data collection efforts adhere to existing laws and regulations, as well as developing new policies as necessary to protect individual privacy rights in the face of rapidly advancing technology.\n",
       "\n",
       "3. **Proportionality and Necessity**: The use of AI in surveillance should adhere to the principles of proportionality and necessity. Any surveillance measures should be proportionate to the security threats being addressed and should be deemed necessary for accomplishing legitimate national security objectives. This requires a rigorous assessment of risks and benefits.\n",
       "\n",
       "4. **Data Minimization and Retention**: Surveillance systems should be designed to collect only the data necessary for their stated purposes, and there should be strict policies governing data retention. Personal data should not be stored longer than necessary, and mechanisms should be in place to ensure that data is deleted when it is no longer needed.\n",
       "\n",
       "5. **Mitigating Bias and Discrimination**: AI systems can perpetuate or amplify biases present in training data or algorithms themselves. Steps should be taken to monitor and mitigate bias in surveillance systems to prevent discrimination against specific groups. This includes regular audits, diverse data sets, and inclusion of various stakeholders in the development and implementation of AI technologies.\n",
       "\n",
       "6. **Public Engagement and Deliberation**: Engaging the public in discussions regarding the ethical use of AI in surveillance is vital. This can ensure that a variety of perspectives are considered, particularly from those who may be disproportionately affected by such technologies. Public forums, stakeholder consultations, and participatory design processes can help shape acceptable practices that align with societal values.\n",
       "\n",
       "7. **Oversight Mechanisms**: Independent oversight bodies should be established to monitor the use of surveillance technologies. These bodies can help ensure compliance with ethical standards and regulations, investigate abuses, and provide recommendations for best practices, thus enhancing accountability.\n",
       "\n",
       "8. **Balancing Interests**: Ongoing dialogue"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages, max_tokens=500)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916015a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here OpenAI is not the OpenAI key, but the lightweight library that just wraps HTTP calls to an endpoint of a particular structure, \n",
    "# OpenAI acts here as endpoints\n",
    "# Except Anthropic, every other platforms like Google, Claude, DeepSeek, Groq, Ollama : has introduced an OpenAI-compatible endpoint \n",
    "\n",
    "gemini = OpenAI(\n",
    "    api_key=google_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3388555",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gemini-2.0-flash\"\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16758e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Addressing the ethical implications of using AI in surveillance technologies requires a multi-faceted approach that carefully balances national security concerns with the protection of individual privacy rights. Here's a breakdown of key considerations and potential approaches:\n",
       "\n",
       "**1. Understanding the Trade-offs and Defining \"Legitimate\" Use Cases:**\n",
       "\n",
       "*   **National Security Benefits:** Acknowledge the potential benefits of AI-powered surveillance in preventing terrorism, cyberattacks, organized crime, and other threats to national security. These benefits must be clearly articulated and supported by evidence.\n",
       "*   **Privacy Risks:** Recognize the significant risks to individual privacy, including:\n",
       "    *   **Mass surveillance:**  AI can analyze vast amounts of data, enabling constant monitoring of entire populations, eroding anonymity.\n",
       "    *   **Bias and discrimination:** AI algorithms trained on biased data can disproportionately target certain groups, leading to unfair treatment and discrimination.\n",
       "    *   **Chilling effect:** Awareness of surveillance can discourage free speech, dissent, and political activism.\n",
       "    *   **Misidentification and errors:**  AI systems, especially facial recognition, can make mistakes, leading to wrongful accusations or detentions.\n",
       "    *   **Data breaches and misuse:** Storing and processing large amounts of personal data creates vulnerabilities to data breaches and potential misuse by governments or malicious actors.\n",
       "*   **Define \"Legitimate\" Use Cases:**  Establish clear criteria for what constitutes a legitimate use of AI surveillance. This should be narrowly defined and focused on specific, demonstrable threats to national security or public safety.  \"Fishing expeditions\" or the collection of data on individuals without reasonable suspicion should be prohibited.  Examples might include:\n",
       "    *   Targeted surveillance of known terrorist suspects.\n",
       "    *   Cybersecurity threat detection.\n",
       "    *   Locating missing persons in emergency situations.\n",
       "\n",
       "**2. Implementing Robust Legal and Regulatory Frameworks:**\n",
       "\n",
       "*   **Legislation and Oversight:** Develop comprehensive legislation that specifically addresses the use of AI in surveillance. This legislation should:\n",
       "    *   Clearly define the scope of permissible surveillance activities.\n",
       "    *   Establish strict limitations on data collection, retention, and sharing.\n",
       "    *   Require transparency and accountability.\n",
       "    *   Create independent oversight bodies to monitor compliance and investigate abuses.\n",
       "*   **Judicial Review:**  Require judicial warrants based on probable cause for intrusive surveillance activities, such as facial recognition or the tracking of individuals' movements.  Ensure judicial bodies have the technical expertise to understand the capabilities and limitations of AI surveillance systems.\n",
       "*   **Data Protection Principles:**  Incorporate data protection principles, such as:\n",
       "    *   **Data minimization:** Collect only the data that is strictly necessary for the specified purpose.\n",
       "    *   **Purpose limitation:** Use data only for the purpose for which it was collected.\n",
       "    *   **Storage limitation:** Retain data only for as long as necessary.\n",
       "    *   **Data accuracy:**  Ensure data is accurate and up-to-date.\n",
       "    *   **Data security:**  Implement robust security measures to protect data from unauthorized access, use, or disclosure.\n",
       "\n",
       "**3. Ensuring Transparency and Accountability:**\n",
       "\n",
       "*   **Public Disclosure:**  Disclose information about the types of AI surveillance technologies used, the purposes for which they are used, and the data that is collected.  Publish regular reports on the use of AI surveillance, including statistics on the number of investigations, arrests, and convictions resulting from its use.\n",
       "*   **Transparency in Algorithms:**  While complete transparency may not be possible (due to security concerns), strive for as much transparency as possible regarding the algorithms used in AI surveillance.  This could include providing general information about the algorithm's design and the factors it considers.\n",
       "*   **Explainability (XAI):**  Develop and implement explainable AI (XAI) techniques to understand why an AI system made a particular decision. This is crucial for accountability and for identifying potential biases or errors.\n",
       "*   **Independent Audits:**  Conduct regular independent audits of AI surveillance systems to assess their effectiveness, identify potential biases, and ensure compliance with legal and ethical guidelines.\n",
       "*   **Whistleblower Protection:**  Protect whistleblowers who report abuses of AI surveillance.\n",
       "\n",
       "**4. Promoting Fairness and Preventing Bias:**\n",
       "\n",
       "*   **Data Diversity:**  Ensure that training data is diverse and representative of the population to minimize bias.  Actively identify and mitigate bias in existing datasets.\n",
       "*   **Bias Detection and Mitigation Techniques:**  Employ bias detection and mitigation techniques throughout the AI development lifecycle.\n",
       "*   **Algorithmic Auditing:**  Conduct regular algorithmic audits to assess the fairness of AI systems and identify potential disparities in outcomes for different groups.\n",
       "*   **Human Oversight:**  Maintain human oversight over AI systems, especially in high-stakes situations.  Humans should have the ability to override AI decisions if they are deemed to be unfair or inaccurate.\n",
       "\n",
       "**5. Protecting Individual Rights and Redress:**\n",
       "\n",
       "*   **Right to Information:** Individuals should have the right to know whether they are being subjected to AI surveillance, what data is being collected about them, and how that data is being used.\n",
       "*   **Right to Access and Correction:**  Individuals should have the right to access and correct inaccurate information about themselves.\n",
       "*   **Right to Challenge:**  Individuals should have the right to challenge decisions made by AI systems that affect them.\n",
       "*   **Redress Mechanisms:**  Establish accessible and effective redress mechanisms for individuals who have been harmed by AI surveillance. This could include the right to file complaints, seek legal remedies, and receive compensation for damages.\n",
       "\n",
       "**6. International Cooperation:**\n",
       "\n",
       "*   **Harmonization of Standards:**  Work with other countries to harmonize international standards for the ethical use of AI in surveillance.\n",
       "*   **Data Sharing Agreements:**  Establish clear guidelines for international data sharing, ensuring that privacy rights are protected and that data is not used for purposes that are inconsistent with human rights principles.\n",
       "\n",
       "**7. Continuous Evaluation and Adaptation:**\n",
       "\n",
       "*   **Regular Reviews:** Regularly review the effectiveness of AI surveillance policies and practices and adapt them as necessary.\n",
       "*   **Technological Monitoring:**  Continuously monitor advances in AI technology and assess their potential implications for privacy and security.\n",
       "*   **Stakeholder Engagement:**  Engage with stakeholders, including civil society organizations, academics, and the public, to discuss the ethical implications of AI surveillance and to solicit feedback on policies and practices.\n",
       "\n",
       "**Key Considerations throughout:**\n",
       "\n",
       "*   **Proportionality:** Any use of AI surveillance must be proportionate to the threat being addressed. The potential benefits must outweigh the risks to individual privacy.\n",
       "*   **Necessity:** AI surveillance should only be used when other less intrusive methods are not effective.\n",
       "*   **Focus on Serious Threats:**  Focus AI surveillance on addressing serious threats to national security or public safety, rather than using it for general monitoring or social control.\n",
       "\n",
       "By implementing these measures, we can strive to harness the potential benefits of AI in surveillance while mitigating the risks to individual privacy and ensuring that these technologies are used in a responsible and ethical manner. This is an ongoing process that requires continuous vigilance and adaptation.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34718f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a35b9dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The ethical implications of using artificial intelligence (AI) in surveillance technologies are indeed complex and warrant a multifaceted approach. Balancing national security with individual privacy rights involves careful consideration of several key factors:\\n\\n1. **Transparency and Accountability**: It is crucial to establish clear guidelines and accountability mechanisms regarding how surveillance technologies are deployed. Governments and organizations should be transparent about their use of AI in surveillance, including the purpose, scope, and methods employed. This transparency can build public trust and ensure that stakeholders understand how their data is being used.\\n\\n2. **Legal Frameworks**: There should be robust legal protections in place that delineate the boundaries of surveillance practices. This includes ensuring that any data collection efforts adhere to existing laws and regulations, as well as developing new policies as necessary to protect individual privacy rights in the face of rapidly advancing technology.\\n\\n3. **Proportionality and Necessity**: The use of AI in surveillance should adhere to the principles of proportionality and necessity. Any surveillance measures should be proportionate to the security threats being addressed and should be deemed necessary for accomplishing legitimate national security objectives. This requires a rigorous assessment of risks and benefits.\\n\\n4. **Data Minimization and Retention**: Surveillance systems should be designed to collect only the data necessary for their stated purposes, and there should be strict policies governing data retention. Personal data should not be stored longer than necessary, and mechanisms should be in place to ensure that data is deleted when it is no longer needed.\\n\\n5. **Mitigating Bias and Discrimination**: AI systems can perpetuate or amplify biases present in training data or algorithms themselves. Steps should be taken to monitor and mitigate bias in surveillance systems to prevent discrimination against specific groups. This includes regular audits, diverse data sets, and inclusion of various stakeholders in the development and implementation of AI technologies.\\n\\n6. **Public Engagement and Deliberation**: Engaging the public in discussions regarding the ethical use of AI in surveillance is vital. This can ensure that a variety of perspectives are considered, particularly from those who may be disproportionately affected by such technologies. Public forums, stakeholder consultations, and participatory design processes can help shape acceptable practices that align with societal values.\\n\\n7. **Oversight Mechanisms**: Independent oversight bodies should be established to monitor the use of surveillance technologies. These bodies can help ensure compliance with ethical standards and regulations, investigate abuses, and provide recommendations for best practices, thus enhancing accountability.\\n\\n8. **Balancing Interests**: Ongoing dialogue',\n",
       " 'Addressing the ethical implications of using AI in surveillance technologies requires a multi-faceted approach that carefully balances national security concerns with the protection of individual privacy rights. Here\\'s a breakdown of key considerations and potential approaches:\\n\\n**1. Understanding the Trade-offs and Defining \"Legitimate\" Use Cases:**\\n\\n*   **National Security Benefits:** Acknowledge the potential benefits of AI-powered surveillance in preventing terrorism, cyberattacks, organized crime, and other threats to national security. These benefits must be clearly articulated and supported by evidence.\\n*   **Privacy Risks:** Recognize the significant risks to individual privacy, including:\\n    *   **Mass surveillance:**  AI can analyze vast amounts of data, enabling constant monitoring of entire populations, eroding anonymity.\\n    *   **Bias and discrimination:** AI algorithms trained on biased data can disproportionately target certain groups, leading to unfair treatment and discrimination.\\n    *   **Chilling effect:** Awareness of surveillance can discourage free speech, dissent, and political activism.\\n    *   **Misidentification and errors:**  AI systems, especially facial recognition, can make mistakes, leading to wrongful accusations or detentions.\\n    *   **Data breaches and misuse:** Storing and processing large amounts of personal data creates vulnerabilities to data breaches and potential misuse by governments or malicious actors.\\n*   **Define \"Legitimate\" Use Cases:**  Establish clear criteria for what constitutes a legitimate use of AI surveillance. This should be narrowly defined and focused on specific, demonstrable threats to national security or public safety.  \"Fishing expeditions\" or the collection of data on individuals without reasonable suspicion should be prohibited.  Examples might include:\\n    *   Targeted surveillance of known terrorist suspects.\\n    *   Cybersecurity threat detection.\\n    *   Locating missing persons in emergency situations.\\n\\n**2. Implementing Robust Legal and Regulatory Frameworks:**\\n\\n*   **Legislation and Oversight:** Develop comprehensive legislation that specifically addresses the use of AI in surveillance. This legislation should:\\n    *   Clearly define the scope of permissible surveillance activities.\\n    *   Establish strict limitations on data collection, retention, and sharing.\\n    *   Require transparency and accountability.\\n    *   Create independent oversight bodies to monitor compliance and investigate abuses.\\n*   **Judicial Review:**  Require judicial warrants based on probable cause for intrusive surveillance activities, such as facial recognition or the tracking of individuals\\' movements.  Ensure judicial bodies have the technical expertise to understand the capabilities and limitations of AI surveillance systems.\\n*   **Data Protection Principles:**  Incorporate data protection principles, such as:\\n    *   **Data minimization:** Collect only the data that is strictly necessary for the specified purpose.\\n    *   **Purpose limitation:** Use data only for the purpose for which it was collected.\\n    *   **Storage limitation:** Retain data only for as long as necessary.\\n    *   **Data accuracy:**  Ensure data is accurate and up-to-date.\\n    *   **Data security:**  Implement robust security measures to protect data from unauthorized access, use, or disclosure.\\n\\n**3. Ensuring Transparency and Accountability:**\\n\\n*   **Public Disclosure:**  Disclose information about the types of AI surveillance technologies used, the purposes for which they are used, and the data that is collected.  Publish regular reports on the use of AI surveillance, including statistics on the number of investigations, arrests, and convictions resulting from its use.\\n*   **Transparency in Algorithms:**  While complete transparency may not be possible (due to security concerns), strive for as much transparency as possible regarding the algorithms used in AI surveillance.  This could include providing general information about the algorithm\\'s design and the factors it considers.\\n*   **Explainability (XAI):**  Develop and implement explainable AI (XAI) techniques to understand why an AI system made a particular decision. This is crucial for accountability and for identifying potential biases or errors.\\n*   **Independent Audits:**  Conduct regular independent audits of AI surveillance systems to assess their effectiveness, identify potential biases, and ensure compliance with legal and ethical guidelines.\\n*   **Whistleblower Protection:**  Protect whistleblowers who report abuses of AI surveillance.\\n\\n**4. Promoting Fairness and Preventing Bias:**\\n\\n*   **Data Diversity:**  Ensure that training data is diverse and representative of the population to minimize bias.  Actively identify and mitigate bias in existing datasets.\\n*   **Bias Detection and Mitigation Techniques:**  Employ bias detection and mitigation techniques throughout the AI development lifecycle.\\n*   **Algorithmic Auditing:**  Conduct regular algorithmic audits to assess the fairness of AI systems and identify potential disparities in outcomes for different groups.\\n*   **Human Oversight:**  Maintain human oversight over AI systems, especially in high-stakes situations.  Humans should have the ability to override AI decisions if they are deemed to be unfair or inaccurate.\\n\\n**5. Protecting Individual Rights and Redress:**\\n\\n*   **Right to Information:** Individuals should have the right to know whether they are being subjected to AI surveillance, what data is being collected about them, and how that data is being used.\\n*   **Right to Access and Correction:**  Individuals should have the right to access and correct inaccurate information about themselves.\\n*   **Right to Challenge:**  Individuals should have the right to challenge decisions made by AI systems that affect them.\\n*   **Redress Mechanisms:**  Establish accessible and effective redress mechanisms for individuals who have been harmed by AI surveillance. This could include the right to file complaints, seek legal remedies, and receive compensation for damages.\\n\\n**6. International Cooperation:**\\n\\n*   **Harmonization of Standards:**  Work with other countries to harmonize international standards for the ethical use of AI in surveillance.\\n*   **Data Sharing Agreements:**  Establish clear guidelines for international data sharing, ensuring that privacy rights are protected and that data is not used for purposes that are inconsistent with human rights principles.\\n\\n**7. Continuous Evaluation and Adaptation:**\\n\\n*   **Regular Reviews:** Regularly review the effectiveness of AI surveillance policies and practices and adapt them as necessary.\\n*   **Technological Monitoring:**  Continuously monitor advances in AI technology and assess their potential implications for privacy and security.\\n*   **Stakeholder Engagement:**  Engage with stakeholders, including civil society organizations, academics, and the public, to discuss the ethical implications of AI surveillance and to solicit feedback on policies and practices.\\n\\n**Key Considerations throughout:**\\n\\n*   **Proportionality:** Any use of AI surveillance must be proportionate to the threat being addressed. The potential benefits must outweigh the risks to individual privacy.\\n*   **Necessity:** AI surveillance should only be used when other less intrusive methods are not effective.\\n*   **Focus on Serious Threats:**  Focus AI surveillance on addressing serious threats to national security or public safety, rather than using it for general monitoring or social control.\\n\\nBy implementing these measures, we can strive to harness the potential benefits of AI in surveillance while mitigating the risks to individual privacy and ensuring that these technologies are used in a responsible and ethical manner. This is an ongoing process that requires continuous vigilance and adaptation.\\n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe1b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
