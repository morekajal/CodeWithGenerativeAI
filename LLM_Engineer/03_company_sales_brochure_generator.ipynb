{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem : Company Sales Brochure Generator\n",
    "\n",
    "- Create a product that can generate marketing brochures about a company \n",
    "    - For prospective clients\n",
    "    - For investors\n",
    "    - For recruitment\n",
    "\n",
    "- Can use Technology like : OpenAI API, One shot prompting, Stream back results and show with formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found\")\n",
    "elif api_key[:8]!= \"sk-proj-\":\n",
    "    print(\"An API Key was found, but it doesn't start with 'sk-proj-', please check you're using right api key\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scrapped, now lets try to collect the links as well\n",
    "    \"\"\"\n",
    "    url : str\n",
    "    title : str\n",
    "    body : str\n",
    "    links : List[str]\n",
    "    text : str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title : \\n {self.title} \\n Webpage Contents : \\n {self.text} \\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek - Wikipedia\n",
      "Jump to content\n",
      "Main menu\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "Navigation\n",
      "Main page\n",
      "Contents\n",
      "Current events\n",
      "Random article\n",
      "About Wikipedia\n",
      "Contact us\n",
      "Contribute\n",
      "Help\n",
      "Learn to edit\n",
      "Community portal\n",
      "Recent changes\n",
      "Upload file\n",
      "Search\n",
      "Search\n",
      "Appearance\n",
      "Donate\n",
      "Create account\n",
      "Log in\n",
      "Personal tools\n",
      "Donate\n",
      "Create account\n",
      "Log in\n",
      "Pages for logged out editors\n",
      "learn more\n",
      "Contributions\n",
      "Talk\n",
      "Contents\n",
      "move to sidebar\n",
      "hide\n",
      "(Top)\n",
      "1\n",
      "Background\n",
      "2\n",
      "Development and release history\n",
      "Toggle Development and release history subsection\n",
      "2.1\n",
      "DeepSeek Coder\n",
      "2.2\n",
      "DeepSeek LLM\n",
      "2.3\n",
      "V2\n",
      "2.4\n",
      "V3\n",
      "2.5\n",
      "R1\n",
      "3\n",
      "Assessment and reactions\n",
      "4\n",
      "Concerns\n",
      "Toggle Concerns subsection\n",
      "4.1\n",
      "Censorship\n",
      "4.2\n",
      "Security and privacy\n",
      "5\n",
      "See also\n",
      "6\n",
      "Notes\n",
      "7\n",
      "References\n",
      "8\n",
      "External links\n",
      "Toggle the table of contents\n",
      "DeepSeek\n",
      "58 languages\n",
      "Afrikaans\n",
      "العربية\n",
      "Aragonés\n",
      "অসমীয়া\n",
      "Azərbaycanca\n",
      "বাংলা\n",
      "Български\n",
      "Català\n",
      "Čeština\n",
      "Dansk\n",
      "الدارجة\n",
      "Deutsch\n",
      "Ελληνικά\n",
      "Español\n",
      "Esperanto\n",
      "Euskara\n",
      "فارسی\n",
      "Français\n",
      "Frysk\n",
      "Fulfulde\n",
      "Gaeilge\n",
      "Galego\n",
      "한국어\n",
      "Ido\n",
      "Bahasa Indonesia\n",
      "Italiano\n",
      "עברית\n",
      "Kiswahili\n",
      "Latviešu\n",
      "Magyar\n",
      "Македонски\n",
      "മലയാളം\n",
      "Nederlands\n",
      "नेपाली\n",
      "日本語\n",
      "Oʻzbekcha / ўзбекча\n",
      "Polski\n",
      "Português\n",
      "Qaraqalpaqsha\n",
      "Română\n",
      "Русский\n",
      "Simple English\n",
      "Slovenščina\n",
      "Српски / srpski\n",
      "Suomi\n",
      "Svenska\n",
      "Tagalog\n",
      "தமிழ்\n",
      "ၽႃႇသႃႇတႆး\n",
      "ไทย\n",
      "Türkçe\n",
      "Українська\n",
      "اردو\n",
      "ئۇيغۇرچە / Uyghurche\n",
      "Tiếng Việt\n",
      "吴语\n",
      "粵語\n",
      "中文\n",
      "Edit links\n",
      "Article\n",
      "Talk\n",
      "English\n",
      "Read\n",
      "Edit\n",
      "View history\n",
      "Tools\n",
      "Tools\n",
      "move to sidebar\n",
      "hide\n",
      "Actions\n",
      "Read\n",
      "Edit\n",
      "View history\n",
      "General\n",
      "What links here\n",
      "Related changes\n",
      "Upload file\n",
      "Special pages\n",
      "Permanent link\n",
      "Page information\n",
      "Cite this page\n",
      "Get shortened URL\n",
      "Download QR code\n",
      "Print/export\n",
      "Download as PDF\n",
      "Printable version\n",
      "In other projects\n",
      "Wikimedia Commons\n",
      "Wikidata item\n",
      "Appearance\n",
      "move to sidebar\n",
      "hide\n",
      "From Wikipedia, the free encyclopedia\n",
      "Chinese artificial intelligence company\n",
      "Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd.\n",
      "Native name\n",
      "杭州深度求索人工智能基础技术研究有限公司\n",
      "Company type\n",
      "Privately held company\n",
      "Industry\n",
      "Information technology\n",
      "Artificial intelligence\n",
      "Founded\n",
      "17 July 2023\n",
      "; 18 months ago\n",
      "(\n",
      "2023-07-17\n",
      ")\n",
      "Founder\n",
      "Liang Wenfeng\n",
      "Headquarters\n",
      "Hangzhou\n",
      ", Zhejiang, China\n",
      "Key people\n",
      "Liang Wenfeng (CEO)\n",
      "Owner\n",
      "High-Flyer\n",
      "Number of employees\n",
      "Under 200\n",
      "Website\n",
      "deepseek\n",
      ".com\n",
      "DeepSeek\n",
      "[\n",
      "a\n",
      "]\n",
      "(\n",
      "Chinese\n",
      ":\n",
      "深度求索\n",
      ";\n",
      "pinyin\n",
      ":\n",
      "Shēndù Qiúsuǒ\n",
      ") is a Chinese\n",
      "artificial intelligence\n",
      "company that develops\n",
      "open-source\n",
      "large language models\n",
      "(LLMs). Based in\n",
      "Hangzhou, Zhejiang\n",
      ", it is owned and funded by Chinese hedge fund\n",
      "High-Flyer\n",
      ", whose co-founder,\n",
      "Liang Wenfeng\n",
      ", established the company in 2023 and serves as its CEO.\n",
      "The DeepSeek-R1 model provides responses comparable to other contemporary\n",
      "large language models\n",
      ", such as\n",
      "OpenAI\n",
      "'s\n",
      "GPT-4o\n",
      "and\n",
      "o1\n",
      ".\n",
      "[\n",
      "2\n",
      "]\n",
      "It is\n",
      "trained\n",
      "at a significantly lower cost—stated at US$6 million compared to $100 million for OpenAI's\n",
      "GPT-4\n",
      "in 2023\n",
      "[\n",
      "3\n",
      "]\n",
      "—and requires a tenth of the computing power of a comparable LLM.\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "4\n",
      "]\n",
      "[\n",
      "5\n",
      "]\n",
      "DeepSeek's AI models were developed amid United States sanctions on China for\n",
      "Nvidia\n",
      "chips, which were intended to restrict the ability of China to develop advanced AI systems.\n",
      "[\n",
      "6\n",
      "]\n",
      "[\n",
      "7\n",
      "]\n",
      "On 10 January 2025, DeepSeek released its first free\n",
      "chatbot app\n",
      ", based on the DeepSeek-R1 model, for\n",
      "iOS\n",
      "and\n",
      "Android\n",
      "; by 27 January, DeepSeek-R1 had surpassed\n",
      "ChatGPT\n",
      "as the most-downloaded free app on the\n",
      "iOS App Store\n",
      "in the United States,\n",
      "[\n",
      "8\n",
      "]\n",
      "causing Nvidia's share price to drop by 18%.\n",
      "[\n",
      "9\n",
      "]\n",
      "[\n",
      "10\n",
      "]\n",
      "DeepSeek's success against larger and more established rivals has been described as \"upending AI\",\n",
      "[\n",
      "8\n",
      "]\n",
      "constituting \"the first shot at what is emerging as a global AI space race\",\n",
      "[\n",
      "11\n",
      "]\n",
      "and ushering in \"a new era of AI\n",
      "brinkmanship\n",
      "\".\n",
      "[\n",
      "12\n",
      "]\n",
      "DeepSeek makes its\n",
      "generative artificial intelligence\n",
      "algorithms, models, and training details open-source, allowing its code to be freely available for use, modification, viewing, and designing documents for building purposes.\n",
      "[\n",
      "13\n",
      "]\n",
      "The company reportedly vigorously recruits young AI researchers from top Chinese universities,\n",
      "[\n",
      "8\n",
      "]\n",
      "and hires from outside the\n",
      "computer science\n",
      "field to diversify its models' knowledge and abilities.\n",
      "[\n",
      "4\n",
      "]\n",
      "Background\n",
      "[\n",
      "edit\n",
      "]\n",
      "In February 2016, High-Flyer was co-founded by AI enthusiast Liang Wenfeng, who had been trading since the\n",
      "2007–2008 financial crisis\n",
      "while attending\n",
      "Zhejiang University\n",
      ".\n",
      "[\n",
      "14\n",
      "]\n",
      "By 2019, he established High-Flyer as a hedge fund focused on developing and using AI trading algorithms. By 2021, High-Flyer exclusively used AI in trading,\n",
      "[\n",
      "15\n",
      "]\n",
      "often using Nvidia chips.\n",
      "[\n",
      "16\n",
      "]\n",
      "DeepSeek has made its\n",
      "generative artificial intelligence\n",
      "chatbot\n",
      "open source\n",
      ", meaning its code is freely available for use, modification, and viewing. This includes permission to access and use the source code, as well as design documents, for building purposes.\n",
      "[\n",
      "13\n",
      "]\n",
      "In 2021, while running High-Flyer, Liang began stockpiling Nvidia GPUs for an AI project.\n",
      "[\n",
      "16\n",
      "]\n",
      "According to\n",
      "36Kr\n",
      ", Liang had built up a store of 10,000\n",
      "Nvidia A100\n",
      "GPUs, which are used to train AI,\n",
      "[\n",
      "17\n",
      "]\n",
      "before the United States federal government imposed AI chip restrictions on China.\n",
      "[\n",
      "15\n",
      "]\n",
      "In April 2023, High-Flyer started an\n",
      "artificial general intelligence\n",
      "lab dedicated to research developing AI tools separate from High-Flyer's financial business.\n",
      "[\n",
      "18\n",
      "]\n",
      "[\n",
      "19\n",
      "]\n",
      "Incorporated on 17 July 2023,\n",
      "[\n",
      "20\n",
      "]\n",
      "with High-Flyer as the investor and backer, the lab became its own company, DeepSeek.\n",
      "[\n",
      "15\n",
      "]\n",
      "[\n",
      "21\n",
      "]\n",
      "[\n",
      "19\n",
      "]\n",
      "Venture capital\n",
      "firms were reluctant in providing funding as it was unlikely that it would be able to generate an\n",
      "exit\n",
      "in a short period of time.\n",
      "[\n",
      "15\n",
      "]\n",
      "After releasing DeepSeek-V2 in May 2024, which offered strong performance for a low price, DeepSeek became known as the catalyst for China's AI model\n",
      "price war\n",
      ". It was quickly dubbed the \"\n",
      "Pinduoduo\n",
      "of AI\", and other major tech giants such as\n",
      "ByteDance\n",
      ",\n",
      "Tencent\n",
      ",\n",
      "Baidu\n",
      ", and\n",
      "Alibaba\n",
      "began to cut the price of their AI models to compete with the company. Despite the low price charged by DeepSeek, it was profitable compared to its rivals that were losing money.\n",
      "[\n",
      "22\n",
      "]\n",
      "DeepSeek is focused on research and has no detailed plans for commercialization,\n",
      "[\n",
      "22\n",
      "]\n",
      "which also allows its technology to avoid the most stringent provisions of China's AI regulations, such as requiring consumer-facing technology to comply with the government's controls on information.\n",
      "[\n",
      "4\n",
      "]\n",
      "DeepSeek's hiring preferences target technical abilities rather than work experience, resulting in most new hires being either recent university graduates or developers whose AI careers are less established.\n",
      "[\n",
      "19\n",
      "]\n",
      "[\n",
      "4\n",
      "]\n",
      "Likewise, the company recruits individuals without any computer science background to help its technology understand other topics and knowledge areas, including being able to generate poetry and perform well on the notoriously difficult\n",
      "Chinese college admissions exams (Gaokao)\n",
      ".\n",
      "[\n",
      "4\n",
      "]\n",
      "Development and release history\n",
      "[\n",
      "edit\n",
      "]\n",
      "This section\n",
      "may be too technical for most readers to understand\n",
      ".\n",
      "Please\n",
      "help improve it\n",
      "to\n",
      "make it understandable to non-experts\n",
      ", without removing the technical details.\n",
      "(\n",
      "January 2025\n",
      ")\n",
      "(\n",
      "Learn how and when to remove this message\n",
      ")\n",
      "This section presents the technical details of the major versions of DeepSeek. It starts with a table that provides a concise overview of each major version, including its release date, notable variants, and key features.\n",
      "Major Versions of DeepSeek Models. SFT stands for supervised finetuning.\n",
      "Major Versions\n",
      "Release Date\n",
      "Major Variants\n",
      "Remarks\n",
      "DeepSeek Coder\n",
      "2 Nov 2023\n",
      "Base (pretrained); Instruct (with instruction-finetuned)\n",
      "The architecture is essentially the same as Llama.\n",
      "DeepSeek LLM\n",
      "29 Nov 2023\n",
      "Base;\n",
      "Chat (with SFT)\n",
      "The architecture is essentially the same as Llama.\n",
      "DeepSeek-MoE\n",
      "9 Jan 2024\n",
      "Base;\n",
      "Chat\n",
      "Developed a variant of mixture of experts (MoE).\n",
      "DeepSeek-Math\n",
      "Apr 2024\n",
      "Base\n",
      "Initialized with DS-Coder-Base-v1.5\n",
      "Instruct (with SFT)\n",
      "RL (using a process reward model)\n",
      "Developed Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO).\n",
      "DeepSeek V2\n",
      "May 2024\n",
      "DeepSeek-V2\n",
      "DeepSeek-V2-Lite\n",
      "DeepSeek-Coder-V2\n",
      "DeepSeek-V2.5\n",
      "Developed multi-head latent attention (MLA). Also used mixture of experts (MoE).\n",
      "DeepSeek V3\n",
      "Dec 2024\n",
      "DeepSeek-V3-Base\n",
      "DeepSeek-V3 (a chat model)\n",
      "The architecture is essentially the same as V2.\n",
      "DeepSeek R1\n",
      "20 Nov 2024\n",
      "DeepSeek-R1-Lite-Preview\n",
      "Only accessed through API and a chat interface.\n",
      "20 Jan 2025\n",
      "DeepSeek-R1\n",
      "DeepSeek-R1-Zero\n",
      "Initialized from DeepSeek-V3-Base and sharing the V3 architecture.\n",
      "Distilled models\n",
      "Initialized from other models, such as Llama, Qwen, etc. Distilled from data synthesized by R1 and R1-Zero.\n",
      "DeepSeek Coder\n",
      "[\n",
      "edit\n",
      "]\n",
      "On 2 November 2023, DeepSeek released its first series of model,\n",
      "DeepSeek-Coder\n",
      ", which is available for free to both researchers and commercial users. The code for the model was made open-source under the\n",
      "MIT License\n",
      ", with an additional license agreement (\"DeepSeek license\") regarding \"open and responsible downstream usage\" for the model itself.\n",
      "[\n",
      "23\n",
      "]\n",
      "They are of the same architecture as DeepSeek LLM detailed below. The series includes 8 models, 4 pretrained (\n",
      "Base\n",
      ") and 4 instruction-finetuned (\n",
      "Instruct\n",
      "). They all have 16K context lengths. The\n",
      "training\n",
      "was as follows:\n",
      "[\n",
      "24\n",
      "]\n",
      "[\n",
      "25\n",
      "]\n",
      "[\n",
      "26\n",
      "]\n",
      "Pretraining: 1.8T tokens (87% source code, 10% code-related English (GitHub markdown and\n",
      "Stack Exchange\n",
      "), and 3% code-unrelated Chinese).\n",
      "Long-context pretraining: 200B tokens. This extends the context length from 4K to 16K. This produced the\n",
      "Base\n",
      "models.\n",
      "Supervised\n",
      "finetuning\n",
      "(SFT): 2B tokens of instruction data. This produced the\n",
      "Instruct\n",
      "models.\n",
      "They were trained on clusters of A100 and\n",
      "H800\n",
      "Nvidia GPUs, connected by\n",
      "InfiniBand\n",
      ",\n",
      "NVLink\n",
      ",\n",
      "NVSwitch\n",
      ".\n",
      "[\n",
      "24\n",
      "]\n",
      "DeepSeek Coder properties\n",
      "[\n",
      "24\n",
      "]\n",
      ": Table 2\n",
      "[\n",
      "27\n",
      "]\n",
      "Params\n",
      ".\n",
      "n\n",
      "layers\n",
      "{\\displaystyle n_{\\text{layers}}}\n",
      "d\n",
      "model\n",
      "{\\displaystyle d_{\\text{model}}}\n",
      "d\n",
      "intermediate\n",
      "{\\displaystyle d_{\\text{intermediate}}}\n",
      "n\n",
      "heads\n",
      "{\\displaystyle n_{\\text{heads}}}\n",
      "n\n",
      "kv-heads\n",
      "{\\displaystyle n_{\\text{kv-heads}}}\n",
      "1.3B\n",
      "24\n",
      "2048\n",
      "5504\n",
      "16\n",
      "16\n",
      "5.7B\n",
      "32\n",
      "4096\n",
      "11008\n",
      "32\n",
      "1\n",
      "[\n",
      "note 1\n",
      "]\n",
      "6.7B\n",
      "32\n",
      "4096\n",
      "11008\n",
      "32\n",
      "32\n",
      "33B\n",
      "62\n",
      "7168\n",
      "19200\n",
      "56\n",
      "7\n",
      "[\n",
      "note 1\n",
      "]\n",
      "DeepSeek LLM\n",
      "[\n",
      "edit\n",
      "]\n",
      "On 29 November 2023, DeepSeek released the\n",
      "DeepSeek-LLM\n",
      "series of models, with 7B and 67B parameters in both\n",
      "Base\n",
      "and\n",
      "Chat\n",
      "forms (no\n",
      "Instruct\n",
      "was released). It was developed to compete with other LLMs available at the time. The paper claimed benchmark results higher than most open source LLMs at the time, especially Llama 2.\n",
      "[\n",
      "28\n",
      "]\n",
      ": section 5\n",
      "Like DeepSeek Coder, the code for the model was under MIT license, with DeepSeek license for the model itself.\n",
      "[\n",
      "29\n",
      "]\n",
      "The architecture was essentially the same as those of the\n",
      "Llama\n",
      "series. They used the\n",
      "pre-norm\n",
      "decoder-only Transformer\n",
      "with\n",
      "RMSNorm\n",
      "as the normalization,\n",
      "SwiGLU\n",
      "in the feedforward layers,\n",
      "rotary positional embedding\n",
      "(RoPE), and\n",
      "grouped-query attention\n",
      "(GQA). Both had vocabulary size 102,400 (\n",
      "byte-level BPE\n",
      ") and context length of 4096. They trained on 2 trillion tokens of English and Chinese text obtained by deduplicating the\n",
      "Common Crawl\n",
      ".\n",
      "[\n",
      "28\n",
      "]\n",
      "DeepSeek LLM properties\n",
      "[\n",
      "28\n",
      "]\n",
      ": Table 2\n",
      "Params\n",
      ".\n",
      "n\n",
      "layers\n",
      "{\\displaystyle n_{\\text{layers}}}\n",
      "d\n",
      "model\n",
      "{\\displaystyle d_{\\text{model}}}\n",
      "d\n",
      "intermediate\n",
      "{\\displaystyle d_{\\text{intermediate}}}\n",
      "n\n",
      "heads\n",
      "{\\displaystyle n_{\\text{heads}}}\n",
      "n\n",
      "kv-heads\n",
      "{\\displaystyle n_{\\text{kv-heads}}}\n",
      "7B\n",
      "30\n",
      "4096\n",
      "11008\n",
      "32\n",
      "32\n",
      "67B\n",
      "95\n",
      "8192\n",
      "22016\n",
      "64\n",
      "8\n",
      "[\n",
      "note 1\n",
      "]\n",
      "The\n",
      "Chat\n",
      "versions of the two\n",
      "Base\n",
      "models was also released concurrently, obtained by training\n",
      "Base\n",
      "by\n",
      "supervised finetuning (SFT) followed by direct policy optimization (DPO)\n",
      ".\n",
      "[\n",
      "28\n",
      "]\n",
      "On 9 January 2024, they released 2\n",
      "DeepSeek-MoE\n",
      "models (\n",
      "Base\n",
      ",\n",
      "Chat\n",
      "), each of 16B parameters (2.7B activated per token, 4K context length). The training was essentially the same as\n",
      "DeepSeek-LLM 7B\n",
      ", and was trained on a part of its training dataset. They claimed comparable performance with a 16B MoE as a 7B non-MoE. In architecture, it is a variant of the standard\n",
      "sparsely-gated MoE\n",
      ", with \"shared experts\" that are always queried, and \"routed experts\" that might not be. They found this to help with expert balancing. In standard MoE, some experts can become overly relied on, while other experts might be rarely used, wasting parameters. Attempting to balance the experts so that they are equally used then causes experts to replicate the same capacity. They proposed the shared experts to learn core capacities that are often used, and let the routed experts to learn the peripheral capacities that are rarely used.\n",
      "[\n",
      "30\n",
      "]\n",
      "In April 2024, they released 3\n",
      "DeepSeek-Math\n",
      "models specialized for doing math:\n",
      "Base\n",
      ",\n",
      "Instruct\n",
      ",\n",
      "RL\n",
      ". It was trained as follows:\n",
      "[\n",
      "31\n",
      "]\n",
      "Initialize with a previously pretrained\n",
      "DeepSeek-Coder-Base-v1.5 7B\n",
      ".\n",
      "Further pretrain with 500B tokens (6% DeepSeekMath Corpus, 4% AlgebraicStack, 10% arXiv, 20% GitHub code, 10% Common Crawl). This produced the\n",
      "Base\n",
      "model.\n",
      "Train an instruction-following model by SFT\n",
      "Base\n",
      "with 776K math problems and their tool-use-integrated step-by-step solutions. This produced the\n",
      "Instruct\n",
      "model.\n",
      "Reinforcement learning\n",
      "(RL): The reward model was a\n",
      "process reward model\n",
      "(PRM) trained from\n",
      "Base\n",
      "according to the Math-Shepherd method.\n",
      "[\n",
      "32\n",
      "]\n",
      "This reward model was then used to train\n",
      "Instruct\n",
      "using\n",
      "Group Relative Policy Optimization\n",
      "(GRPO) on a dataset of 144K math questions \"related to GSM8K and MATH\". The reward model was continuously updated during training to avoid reward hacking. This resulted in the\n",
      "RL\n",
      "model.\n",
      "V2\n",
      "[\n",
      "edit\n",
      "]\n",
      "The architecture of V2, showing both shared-routed MoE and MLA.\n",
      "[\n",
      "33\n",
      "]\n",
      ": Figure 2\n",
      "In May 2024, they released the\n",
      "DeepSeek-V2\n",
      "series. The series includes 4 models, 2 base models (\n",
      "DeepSeek-V2\n",
      ",\n",
      "DeepSeek-V2-Lite\n",
      ") and 2 chatbots (\n",
      "-Chat\n",
      "). The two larger models were trained as follows:\n",
      "[\n",
      "33\n",
      "]\n",
      "Pretrain on a dataset of 8.1T tokens, where Chinese tokens are 12% more than English ones.\n",
      "Extend context length from 4K to 128K using YaRN.\n",
      "[\n",
      "34\n",
      "]\n",
      "This resulted in\n",
      "DeepSeek-V2\n",
      ".\n",
      "SFT with 1.2M instances for helpfulness and 0.3M for safety. This resulted in\n",
      "DeepSeek-V2-Chat (SFT)\n",
      "which was not released.\n",
      "RL using GRPO in two stages. The first stage was trained to solve math and coding problems. This stage used 1 reward model, trained on compiler feedback (for coding) and ground-truth labels (for math). The second stage was trained to be helpful, safe, and follow rules. This stage used 3 reward models. The helpfulness and safety reward models were trained on human preference data. The rule-based reward model was manually programmed. All trained reward models were initialized from\n",
      "DeepSeek-V2-Chat (SFT)\n",
      ". This resulted in the released version of\n",
      "DeepSeek-V2-Chat\n",
      ".\n",
      "They opted for 2-staged RL, because they found that RL on reasoning data had \"unique characteristics\" different from RL on general data. For example, RL on reasoning could improve over more training steps.\n",
      "[\n",
      "33\n",
      "]\n",
      "The two\n",
      "V2-Lite\n",
      "models were smaller, and trained similarly, though\n",
      "DeepSeek-V2-Lite-Chat\n",
      "only underwent SFT, not RL. They trained the Lite version to help \"further research and development on MLA and DeepSeekMoE\".\n",
      "[\n",
      "33\n",
      "]\n",
      "Architecturally, the V2 models were significantly modified from the DeepSeek LLM series. They changed the standard attention mechanism by a\n",
      "low-rank approximation\n",
      "called\n",
      "multi-head latent attention\n",
      "(MLA), and used the\n",
      "mixture of experts\n",
      "(MoE) variant previously published in January.\n",
      "[\n",
      "30\n",
      "]\n",
      "DeepSeek V2 properties\n",
      "[\n",
      "33\n",
      "]\n",
      ": Section 3.1.2, Appendix B\n",
      "[\n",
      "35\n",
      "]\n",
      "[\n",
      "36\n",
      "]\n",
      "Name\n",
      "Params\n",
      ".\n",
      "Active\n",
      "params\n",
      "n\n",
      "layers\n",
      "{\\displaystyle n_{\\text{layers}}}\n",
      "Context length\n",
      "n\n",
      "shared experts\n",
      "{\\displaystyle n_{\\text{shared experts}}}\n",
      "n\n",
      "routed experts\n",
      "{\\displaystyle n_{\\text{routed experts}}}\n",
      "V2-Lite\n",
      "15.7B\n",
      "2.4B\n",
      "27\n",
      "32K\n",
      "2\n",
      "64\n",
      "V2\n",
      "236B\n",
      "21B\n",
      "60\n",
      "128K\n",
      "2\n",
      "160\n",
      "The\n",
      "Financial Times\n",
      "reported that it was cheaper than its peers with a price of 2\n",
      "RMB\n",
      "for every million output tokens. The\n",
      "University of Waterloo\n",
      "Tiger Lab's leaderboard ranked DeepSeek-V2 seventh on its LLM ranking.\n",
      "[\n",
      "21\n",
      "]\n",
      "In June 2024, they released 4 models in the\n",
      "DeepSeek-Coder-V2\n",
      "series:\n",
      "V2-Base\n",
      ",\n",
      "V2-Lite-Base\n",
      ",\n",
      "V2-Instruct\n",
      ",\n",
      "V2-Lite-Instruct\n",
      ". They were trained as follows:\n",
      "[\n",
      "37\n",
      "]\n",
      "[\n",
      "note 2\n",
      "]\n",
      "The\n",
      "Base\n",
      "models were initialized from corresponding\n",
      "intermediate\n",
      "checkpoints after pretraining on 4.2T tokens (not the version at the end of pretraining), then pretrained further for 6T tokens, then context-extended to 128K context length. This produced the\n",
      "Base\n",
      "models.\n",
      "DeepSeek-Coder\n",
      "and\n",
      "DeepSeek-Math\n",
      "were used to generate 20K code-related and 30K math-related instruction data, then combined with an instruction dataset of 300M tokens. This was used for SFT.\n",
      "RL with GRPO. The reward for math problems was computed by comparing with the ground-truth label. The reward for code problems was generated by a reward model trained to predict whether a program would pass the unit tests.\n",
      "DeepSeek-V2.5\n",
      "was released in September and updated in December 2024. It was made by combining\n",
      "DeepSeek-V2-Chat\n",
      "and\n",
      "DeepSeek-Coder-V2-Instruct\n",
      ".\n",
      "[\n",
      "38\n",
      "]\n",
      "V3\n",
      "[\n",
      "edit\n",
      "]\n",
      "Multi-Token Prediction.\n",
      "In December 2024, they released a base model\n",
      "DeepSeek-V3-Base\n",
      "and a chat model\n",
      "DeepSeek-V3\n",
      ". The model architecture is essentially the same as V2 with the addition of\n",
      "multi-token prediction\n",
      ", which (optionally) decodes extra tokens faster but less accurately. They were trained as follows:\n",
      "[\n",
      "39\n",
      "]\n",
      "Pretraining on 14.8T tokens of a multilingual corpus, mostly English and Chinese. It contained a higher ratio of math and programming than the pretraining dataset of V2.\n",
      "Extend context length twice, from 4K to 32K and then to 128K, using YaRN.\n",
      "[\n",
      "34\n",
      "]\n",
      "This produced\n",
      "DeepSeek-V3-Base\n",
      ".\n",
      "SFT for 2 epochs on 1.5M samples of reasoning (math, programming, logic) and non-reasoning (creative writing, roleplay, simple question answering) data. Reasoning data was generated by \"expert models\". Non-reasoning data was generated by\n",
      "DeepSeek-V2.5\n",
      "and checked by humans.\n",
      "The \"expert models\" were trained by starting with an unspecified base model, then SFT on both\n",
      "<problem, original response>\n",
      "data, and synthetic\n",
      "<system prompt, problem, R1 response>\n",
      "data generated by an internal\n",
      "DeepSeek-R1\n",
      "model. The system prompt asked the\n",
      "R1\n",
      "to reflect and verify during thinking. Then the expert models were RL using an unspecified reward function.\n",
      "Each expert model was trained to generate just synthetic reasoning data in one specific domain (math, programming, logic).\n",
      "Expert models were used, instead of\n",
      "R1\n",
      "itself, since the output from\n",
      "R1\n",
      "itself suffered \"overthinking, poor formatting, and excessive length\".\n",
      "Model-based reward models were made by starting with a SFT checkpoint of\n",
      "V3\n",
      ", then finetuning on human preference data containing both final reward and chain-of-thought leading to the final reward. The reward model produced reward signals for both questions with objective but free-form answers, and questions without objective answers (such as creative writing).\n",
      "A SFT checkpoint of\n",
      "V3\n",
      "was trained by GRPO using both reward models and rule-based reward. The rule-based reward was computed for math problems with a final answer (put in a box), and for programming problems by unit tests. This produced\n",
      "DeepSeek-V3\n",
      ".\n",
      "DeepSeek V3 properties\n",
      "[\n",
      "39\n",
      "]\n",
      ": Section 4.2\n",
      "[\n",
      "40\n",
      "]\n",
      "Name\n",
      "Params\n",
      ".\n",
      "Active\n",
      "params\n",
      "n\n",
      "layers\n",
      "{\\displaystyle n_{\\text{layers}}}\n",
      "Context length\n",
      "n\n",
      "shared experts\n",
      "{\\displaystyle n_{\\text{shared experts}}}\n",
      "n\n",
      "routed experts\n",
      "{\\displaystyle n_{\\text{routed experts}}}\n",
      "V3\n",
      "671B\n",
      "37B\n",
      "61\n",
      "128K\n",
      "1\n",
      "256\n",
      "Mixed-precision framework for\n",
      "V3\n",
      ".\n",
      "[\n",
      "39\n",
      "]\n",
      ": Figure 6\n",
      "The DeepSeek team performed extensive low-level engineering to achieve efficiency. They used\n",
      "mixed-precision arithmetic\n",
      ". Much of the forward pass was performed in\n",
      "8-bit floating point numbers\n",
      "(5E2M: 5-bit exponent and 2-bit\n",
      "mantissa\n",
      ") rather than the standard\n",
      "32-bit\n",
      ", requiring special\n",
      "GEMM\n",
      "routines to accumulate accurately. They used a custom 12-bit float (E5M6) for\n",
      "only\n",
      "the inputs to the linear layers after the attention modules. Optimizer states were in 16-bit (\n",
      "BF16\n",
      "). They minimized the communication latency by overlapping extensively computation and communication, such as dedicating 20 streaming multiprocessors out of 132 per H800 for only inter-GPU communication. They lowered communication by rearranging (every 10 minutes) the exact machine each expert was on so as to avoid certain machines being queried more often than the others, adding auxiliary load-balancing losses to the training loss function, and other load-balancing techniques.\n",
      "[\n",
      "39\n",
      "]\n",
      "After training, it was deployed on H800 clusters. The H800 cards within a cluster are connected by NVLink, and the clusters are connected by InfiniBand.\n",
      "[\n",
      "39\n",
      "]\n",
      "Total cost of training the DeepSeek-V3 model\n",
      "[\n",
      "39\n",
      "]\n",
      ": Table 1\n",
      "Stage\n",
      "Cost (in one thousand GPU hours)\n",
      "Cost (in one million USD$)\n",
      "Pre-training\n",
      "2,664\n",
      "5.328\n",
      "Context extension\n",
      "119\n",
      "0.24\n",
      "Fine-tuning\n",
      "5\n",
      "0.01\n",
      "Total\n",
      "2,788\n",
      "5.576\n",
      "Benchmark tests show that\n",
      "V3\n",
      "outperformed\n",
      "Llama\n",
      "3.1 and\n",
      "Qwen\n",
      "2.5 while matching\n",
      "GPT-4o\n",
      "and\n",
      "Claude\n",
      "3.5 Sonnet.\n",
      "[\n",
      "19\n",
      "]\n",
      "[\n",
      "41\n",
      "]\n",
      "[\n",
      "42\n",
      "]\n",
      "[\n",
      "43\n",
      "]\n",
      "R1\n",
      "[\n",
      "edit\n",
      "]\n",
      "On 20 November 2024,\n",
      "DeepSeek-R1-Lite-Preview\n",
      "became accessible via DeepSeek's API, as well as via a chat interface after logging in.\n",
      "[\n",
      "44\n",
      "]\n",
      "[\n",
      "45\n",
      "]\n",
      "[\n",
      "note 3\n",
      "]\n",
      "It was trained for logical inference, mathematical reasoning, and real-time problem-solving. DeepSeek claimed that it exceeded performance of\n",
      "OpenAI o1\n",
      "on benchmarks such as\n",
      "American Invitational Mathematics Examination\n",
      "(AIME) and MATH.\n",
      "[\n",
      "46\n",
      "]\n",
      "However,\n",
      "The Wall Street Journal\n",
      "stated when it used 15 problems from the 2024 edition of AIME, the o1 model reached a solution faster than\n",
      "DeepSeek-R1-Lite-Preview\n",
      ".\n",
      "[\n",
      "47\n",
      "]\n",
      "On 20 January 2025, DeepSeek released\n",
      "DeepSeek-R1\n",
      "and\n",
      "DeepSeek-R1-Zero\n",
      ".\n",
      "[\n",
      "48\n",
      "]\n",
      "Both were initialized from\n",
      "DeepSeek-V3-Base\n",
      ", and share its architecture. The company also released some \"\n",
      "DeepSeek-R1-Distill\n",
      "\" models, which are\n",
      "not\n",
      "initialized on\n",
      "V3-Base\n",
      ", but instead are initialized from other pretrained open-weight models, including\n",
      "LLaMA\n",
      "and\n",
      "Qwen\n",
      ", then fine-tuned on\n",
      "synthetic data\n",
      "generated by\n",
      "R1\n",
      ".\n",
      "[\n",
      "49\n",
      "]\n",
      "Template for\n",
      "DeepSeek-R1-Zero\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>. User: <prompt>. Assistant:\n",
      "– <prompt> is replaced with the specific reasoning question during training.\n",
      "DeepSeek-R1-Zero\n",
      "was trained exclusively using GRPO RL without SFT. Unlike previous versions, they used no model-based reward. All reward functions were rule-based, \"mainly\" of two types (other types were not specified): accuracy rewards and format rewards. Accuracy reward was checking whether a boxed answer is correct (for math) or whether a code passes tests (for programming). Format reward was checking whether the model puts its thinking trace within\n",
      "<think>...</think>\n",
      ".\n",
      "[\n",
      "49\n",
      "]\n",
      "As\n",
      "R1-Zero\n",
      "has issues with readability and mixing languages,\n",
      "R1\n",
      "was trained to address these issues and further improve reasoning:\n",
      "[\n",
      "49\n",
      "]\n",
      "SFT\n",
      "DeepSeek-V3-Base\n",
      "on \"thousands\" of \"cold-start\" data all with the standard format of\n",
      "|special_token|<reasoning_process>|special_token|<summary>\n",
      ", designed to make the model output more readable.\n",
      "Apply the same GRPO RL process as\n",
      "R1-Zero\n",
      ", but also with a \"language consistency reward\" to encourage it to respond monolingually. This produced an internal model not released.\n",
      "Synthesize 600K reasoning data from the internal model, with rejection sampling (i.e. if the generated reasoning had a wrong final answer, then it is removed). Synthesize 200K non-reasoning data (writing, factual QA, self-cognition, translation) using\n",
      "DeepSeek-V3\n",
      ".\n",
      "SFT\n",
      "DeepSeek-V3-Base\n",
      "on the 800K synthetic data for 2 epochs.\n",
      "Apply the same GRPO RL process as\n",
      "R1-Zero\n",
      "with rule-based reward (for reasoning tasks), but also model-based reward (for non-reasoning tasks, helpfulness, and harmlessness). This produced\n",
      "DeepSeek-R1\n",
      ".\n",
      "Distilled models were trained by SFT on 800K data synthesized from\n",
      "DeepSeek-R1\n",
      ", in a similar way as step 3 above. They were not trained with RL.\n",
      "[\n",
      "49\n",
      "]\n",
      "Assessment and reactions\n",
      "[\n",
      "edit\n",
      "]\n",
      "DeepSeek released its\n",
      "AI Assistant\n",
      ", which uses the V3 model as a\n",
      "chatbot app\n",
      "for\n",
      "Apple IOS\n",
      "and\n",
      "Android\n",
      ". By 27 January 2025, the app had surpassed ChatGPT as the highest-rated free app on the iOS App Store in the United States. Its chatbot reportedly answers questions, solves logic problems, and writes computer programs on par with other chatbots on the market, according to benchmark tests used by American AI companies.\n",
      "[\n",
      "4\n",
      "]\n",
      "DeepSeek-V3 uses significantly fewer resources compared to its peers; for example, whereas the world's leading AI companies train their chatbots with\n",
      "supercomputers\n",
      "using as many as 16,000\n",
      "graphics processing units (GPUs)\n",
      ", if not more, DeepSeek claims to have needed only about 2,000 GPUs, namely the H800 series chip from\n",
      "Nvidia\n",
      ".\n",
      "[\n",
      "39\n",
      "]\n",
      "It was trained in around 55 days at a cost of US$5.58 million,\n",
      "[\n",
      "39\n",
      "]\n",
      "which is roughly one tenth of what United States tech giant\n",
      "Meta\n",
      "spent building its latest AI technology.\n",
      "[\n",
      "4\n",
      "]\n",
      "DeepSeek's competitive performance at relatively minimal cost has been recognized as potentially challenging the global dominance of American AI models.\n",
      "[\n",
      "50\n",
      "]\n",
      "Various publications and news media, such as\n",
      "The Hill\n",
      "and\n",
      "The Guardian\n",
      ",\n",
      "described the release of its chatbot as a \"\n",
      "Sputnik moment\n",
      "\" for American AI.\n",
      "[\n",
      "51\n",
      "]\n",
      "[\n",
      "52\n",
      "]\n",
      "The performance of its\n",
      "R1\n",
      "model was reportedly \"on par with\" one of OpenAI's latest models when used for tasks such as mathematics, coding, and natural language reasoning;\n",
      "[\n",
      "53\n",
      "]\n",
      "echoing other commentators, American Silicon Valley venture capitalist\n",
      "Marc Andreessen\n",
      "likewise described\n",
      "R1\n",
      "as \"AI's Sputnik moment\".\n",
      "[\n",
      "53\n",
      "]\n",
      "DeepSeek's founder, Liang Wenfeng has been compared to Open AI CEO\n",
      "Sam Altman\n",
      ", with\n",
      "CNN\n",
      "calling him the Sam Altman of China and an evangelist for AI.\n",
      "[\n",
      "54\n",
      "]\n",
      "Chinese\n",
      "state media\n",
      "widely praised DeepSeek as a national asset.\n",
      "[\n",
      "55\n",
      "]\n",
      "[\n",
      "56\n",
      "]\n",
      "On 20 January 2025, China's Premier\n",
      "Li Qiang\n",
      "invited Wenfeng to his symposium with experts and asked him to provide opinions and suggestions on a draft for comments of the annual 2024 government work report.\n",
      "[\n",
      "57\n",
      "]\n",
      "DeepSeek's optimization of limited resources has highlighted potential limits of United States sanctions on China's AI development, which include export restrictions on advanced AI chips to China.\n",
      "[\n",
      "19\n",
      "]\n",
      "[\n",
      "58\n",
      "]\n",
      "The success of the company's AI models consequently \"sparked market turmoil\"\n",
      "[\n",
      "59\n",
      "]\n",
      "and caused shares in major global technology companies to plunge on 27 January 2025: Nvidia's stock fell by as much as 17–18%,\n",
      "[\n",
      "60\n",
      "]\n",
      "as did the stock of rival\n",
      "Broadcom\n",
      ". Other tech firms also sank, including\n",
      "Microsoft\n",
      "(down 2.5%),\n",
      "Google\n",
      "'s owner\n",
      "Alphabet\n",
      "(down over 4%), and Dutch chip equipment maker\n",
      "ASML\n",
      "(down over 7%).\n",
      "[\n",
      "53\n",
      "]\n",
      "A global selloff of technology stocks on\n",
      "Nasdaq\n",
      ", prompted by the release of the\n",
      "R1\n",
      "model, had led to record losses of about $593 billion in the market capitalizations of AI and computer hardware companies;\n",
      "[\n",
      "61\n",
      "]\n",
      "by 28 January 2025, a total of $1 trillion of value was wiped off American stocks.\n",
      "[\n",
      "52\n",
      "]\n",
      "The login error DeepSeek gave on 28 January 2025 following a cyberattack\n",
      "Leading figures in the American AI sector had mixed reactions to DeepSeek's success and performance.\n",
      "[\n",
      "62\n",
      "]\n",
      "Microsoft CEO\n",
      "Satya Nadella\n",
      "and OpenAI CEO Sam Altman—whose companies are involved in the United States government-backed \"\n",
      "Stargate Project\n",
      "\" to develop American AI infrastructure—both called DeepSeek \"super impressive\".\n",
      "[\n",
      "63\n",
      "]\n",
      "[\n",
      "64\n",
      "]\n",
      "American President\n",
      "Donald Trump\n",
      ", who announced The Stargate Project, called DeepSeek a wake-up call\n",
      "[\n",
      "65\n",
      "]\n",
      "and a positive development.\n",
      "[\n",
      "66\n",
      "]\n",
      "[\n",
      "52\n",
      "]\n",
      "[\n",
      "53\n",
      "]\n",
      "[\n",
      "67\n",
      "]\n",
      "Other leaders in the field, including\n",
      "Scale AI\n",
      "CEO\n",
      "Alexandr Wang\n",
      ",\n",
      "Anthropic\n",
      "cofounder and CEO\n",
      "Dario Amodei\n",
      ", and\n",
      "Elon Musk\n",
      "expressed skepticism of the app's performance or of the sustainability of its success.\n",
      "[\n",
      "62\n",
      "]\n",
      "[\n",
      "68\n",
      "]\n",
      "[\n",
      "69\n",
      "]\n",
      "Various companies, including\n",
      "Amazon Web Services\n",
      ",\n",
      "Toyota\n",
      ", and\n",
      "Stripe\n",
      ", are seeking to use the model in their program.\n",
      "[\n",
      "70\n",
      "]\n",
      "On 27 January 2025, DeepSeek limited its new user registration to phone numbers from mainland China, email addresses, or Google account logins, after a \"large-scale\"\n",
      "cyberattack\n",
      "disrupted the proper functioning of its servers.\n",
      "[\n",
      "71\n",
      "]\n",
      "[\n",
      "72\n",
      "]\n",
      "Concerns\n",
      "[\n",
      "edit\n",
      "]\n",
      "Censorship\n",
      "[\n",
      "edit\n",
      "]\n",
      "DeepSeek responses when asked about\n",
      "Xi Jinping\n",
      "and\n",
      "Narendra Modi\n",
      "Some sources have observed that the official application programming interface (API) version of R1, which runs from servers located in China, uses censorship mechanisms for topics that are considered politically sensitive for the\n",
      "government of China\n",
      ". For example, the model refuses to answer questions about the\n",
      "1989 Tiananmen Square massacre\n",
      ",\n",
      "persecution of Uyghurs\n",
      ",\n",
      "comparisons between Xi Jinping and Winnie the Pooh\n",
      ", and\n",
      "human rights in China\n",
      ".\n",
      "[\n",
      "73\n",
      "]\n",
      "[\n",
      "74\n",
      "]\n",
      "[\n",
      "75\n",
      "]\n",
      "The AI may initially generate an answer, but then deletes it shortly afterwards and replaces it with a message such as: \"Sorry, that's beyond my current scope. Let's talk about something else.\"\n",
      "[\n",
      "74\n",
      "]\n",
      "The integrated censorship mechanisms and restrictions can only be removed to a limited extent in the open-source version of the R1 model. If the \"\n",
      "Core Socialist Values\n",
      "\" defined by the\n",
      "Chinese Internet regulatory authorities\n",
      "are touched upon, or the\n",
      "political status of Taiwan\n",
      "is raised, discussions are terminated.\n",
      "[\n",
      "76\n",
      "]\n",
      "When tested by\n",
      "NBC News\n",
      ", DeepSeek's R1 described Taiwan as \"an inalienable part of China's territory,\" and stated: \"We firmly oppose any form of '\n",
      "Taiwan independence\n",
      "' separatist activities and are committed to achieving the complete reunification of the motherland through peaceful means.\"\n",
      "[\n",
      "77\n",
      "]\n",
      "In January 2025, Western researchers were able to trick DeepSeek into giving certain answers to some of these topics by requesting in its answer to swap certain letters for\n",
      "similar-looking numbers\n",
      ".\n",
      "[\n",
      "75\n",
      "]\n",
      "Security and privacy\n",
      "[\n",
      "edit\n",
      "]\n",
      "See also:\n",
      "Chinese information operations and information warfare\n",
      "Some experts fear that the government of China could use the AI system for foreign\n",
      "influence operations\n",
      ", spreading\n",
      "disinformation\n",
      ",\n",
      "surveillance\n",
      "and the development of\n",
      "cyberweapons\n",
      ".\n",
      "[\n",
      "78\n",
      "]\n",
      "[\n",
      "79\n",
      "]\n",
      "[\n",
      "80\n",
      "]\n",
      "DeepSeek's privacy terms and conditions say \"We store the information we collect in secure servers located in the People's Republic of China... We may collect your text or audio input, prompt, uploaded files, feedback, chat history, or other content that you provide to our model and Services\". According to a review by\n",
      "Wired\n",
      ", DeepSeek also sends data to\n",
      "Baidu\n",
      "'s web analytics service and collects data from\n",
      "ByteDance\n",
      ".\n",
      "[\n",
      "81\n",
      "]\n",
      "In response, the Italian data protection authority is seeking additional information on DeepSeek's collection and use of personal data, and the\n",
      "United States National Security Council\n",
      "announced that it had started a national security review.\n",
      "[\n",
      "82\n",
      "]\n",
      "[\n",
      "83\n",
      "]\n",
      "South Korea's\n",
      "Personal Information Protection Commission\n",
      "opened an inquiry into DeepSeek's use of personal information.\n",
      "[\n",
      "84\n",
      "]\n",
      "The\n",
      "Dutch Data Protection Authority\n",
      "also launched an investigation.\n",
      "[\n",
      "85\n",
      "]\n",
      "On 31 January 2025, Taiwan's digital ministry advised government departments against using the DeepSeek service to \"prevent information security risks\".\n",
      "[\n",
      "84\n",
      "]\n",
      "On the same day, Texas governor\n",
      "Greg Abbott\n",
      "issued a state ban on government-issued devices for DeepSeek, along with\n",
      "Xiaohongshu\n",
      "and\n",
      "Lemon8\n",
      ".\n",
      "[\n",
      "86\n",
      "]\n",
      "See also\n",
      "[\n",
      "edit\n",
      "]\n",
      "Free and open-source software portal\n",
      "Artificial intelligence industry in China\n",
      "Notes\n",
      "[\n",
      "edit\n",
      "]\n",
      "^\n",
      "Legal name registered as\n",
      "Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd.\n",
      "[\n",
      "1\n",
      "]\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "The number of heads does not equal the number of KV heads, due to GQA.\n",
      "^\n",
      "Inexplicably, the model named\n",
      "DeepSeek-Coder-V2 Chat\n",
      "in the paper was released as\n",
      "DeepSeek-Coder-V2-Instruct\n",
      "in HuggingFace.\n",
      "^\n",
      "At that time, the\n",
      "R1-Lite-Preview\n",
      "required selecting \"Deep Think enabled\", and every user could use it only 50 times a day.\n",
      "References\n",
      "[\n",
      "edit\n",
      "]\n",
      "^\n",
      "\"Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd\"\n",
      ".\n",
      "Bloomberg L.P.\n",
      "Retrieved\n",
      "1 February\n",
      "2025\n",
      ".\n",
      "^\n",
      "Gibney, Elizabeth (23 January 2025).\n",
      "\"China's cheap, open AI model DeepSeek thrills scientists\"\n",
      ".\n",
      "Nature\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1038/d41586-025-00229-6\n",
      ".\n",
      "ISSN\n",
      "1476-4687\n",
      ".\n",
      "PMID\n",
      "39849139\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "Vincent, James (28 January 2025).\n",
      "\"The DeepSeek panic reveals an AI world ready to blow\"\n",
      ".\n",
      "The Guardian\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "Metz, Cade; Tobin, Meaghan (23 January 2025).\n",
      "\"How Chinese A.I. Start-Up DeepSeek Is Competing With Silicon Valley Giants\"\n",
      ".\n",
      "The New York Times\n",
      ".\n",
      "ISSN\n",
      "0362-4331\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Cosgrove, Emma (27 January 2025).\n",
      "\"DeepSeek's cheaper models and weaker chips call into question trillions in AI infrastructure spending\"\n",
      ".\n",
      "Business Insider\n",
      ".\n",
      "^\n",
      "Saran, Cliff (10 December 2024).\n",
      "\"Nvidia investigation signals widening of US and China chip war | Computer Weekly\"\n",
      ".\n",
      "Computer Weekly\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Sherman, Natalie (9 December 2024).\n",
      "\"Nvidia targeted by China in new chip war probe\"\n",
      ".\n",
      "BBC\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "Metz, Cade (27 January 2025).\n",
      "\"What is DeepSeek? And How Is It Upending A.I.?\"\n",
      ".\n",
      "The New York Times\n",
      ".\n",
      "ISSN\n",
      "0362-4331\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Field, Hayden (27 January 2025).\n",
      "\"China's DeepSeek AI dethrones ChatGPT on App Store: Here's what you should know\"\n",
      ".\n",
      "CNBC\n",
      ".\n",
      "^\n",
      "Picchi, Aimee (27 January 2025).\n",
      "\"What is DeepSeek, and why is it causing Nvidia and other stocks to slump?\"\n",
      ".\n",
      "CBS News\n",
      ".\n",
      "^\n",
      "Zahn, Max (27 January 2025).\n",
      "\"Nvidia, Microsoft shares tumble as China-based AI app DeepSeek hammers tech giants\"\n",
      ".\n",
      "ABC News\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Roose, Kevin (28 January 2025).\n",
      "\"Why DeepSeek Could Change What Silicon Valley Believe About A.I.\"\n",
      "The New York Times\n",
      ".\n",
      "ISSN\n",
      "0362-4331\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "Romero, Luis E. (28 January 2025).\n",
      "\"ChatGPT, DeepSeek, Or Llama? Meta's LeCun Says Open-Source Is The Key\"\n",
      ".\n",
      "Forbes\n",
      ".\n",
      "^\n",
      "Chen, Caiwei (24 January 2025).\n",
      "\"How a top Chinese AI model overcame US sanctions\"\n",
      ".\n",
      "MIT Technology Review\n",
      ".\n",
      "Archived\n",
      "from the original on 25 January 2025\n",
      ". Retrieved\n",
      "25 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "Ottinger, Lily (9 December 2024).\n",
      "\"Deepseek: From Hedge Fund to Frontier Model Maker\"\n",
      ".\n",
      "ChinaTalk\n",
      ".\n",
      "Archived\n",
      "from the original on 28 December 2024\n",
      ". Retrieved\n",
      "28 December\n",
      "2024\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "Olcott, Eleanor; Wu, Zijing (24 January 2025).\n",
      "\"How small Chinese AI start-up DeepSeek shocked Silicon Valley\"\n",
      ".\n",
      "Financial Times\n",
      ". Retrieved\n",
      "31 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Leswing, Kif (23 February 2023).\n",
      "\"Meet the $10,000 Nvidia chip powering the race for A.I.\"\n",
      "CNBC\n",
      ". Retrieved\n",
      "30 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Yu, Xu (17 April 2023).\n",
      "\"[Exclusive] Chinese Quant Hedge Fund High-Flyer Won't Use AGI to Trade Stocks, MD Says\"\n",
      ".\n",
      "Yicai Global\n",
      ".\n",
      "Archived\n",
      "from the original on 31 December 2023\n",
      ". Retrieved\n",
      "28 December\n",
      "2024\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "Jiang, Ben; Perezi, Bien (1 January 2025).\n",
      "\"Meet DeepSeek: the Chinese start-up that is changing how AI models are trained\"\n",
      ".\n",
      "South China Morning Post\n",
      ".\n",
      "Archived\n",
      "from the original on 22 January 2025\n",
      ". Retrieved\n",
      "1 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "\"DeepSeek突传消息！\"\n",
      ".\n",
      "Sina Corp\n",
      ". 1 February 2025\n",
      ". Retrieved\n",
      "1 February\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "McMorrow, Ryan; Olcott, Eleanor (9 June 2024).\n",
      "\"The Chinese quant fund-turned-AI pioneer\"\n",
      ".\n",
      "Financial Times\n",
      ".\n",
      "Archived\n",
      "from the original on 17 July 2024\n",
      ". Retrieved\n",
      "28 December\n",
      "2024\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "Schneider, Jordan (27 November 2024).\n",
      "\"Deepseek: The Quiet Giant Leading China's AI Race\"\n",
      ".\n",
      "ChinaTalk\n",
      ". Retrieved\n",
      "28 December\n",
      "2024\n",
      ".\n",
      "^\n",
      "\"DeepSeek-Coder/LICENSE-MODEL at main · deepseek-ai/DeepSeek-Coder\"\n",
      ".\n",
      "GitHub\n",
      ".\n",
      "Archived\n",
      "from the original on 22 January 2025\n",
      ". Retrieved\n",
      "24 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "Guo, Daya; Zhu, Qihao; Yang, Dejian; Xie, Zhenda; Dong, Kai; Zhang, Wentao; Chen, Guanting; Bi, Xiao; Wu, Y. (26 January 2024),\n",
      "DeepSeek-Coder: When the Large Language Model Meets Programming – The Rise of Code Intelligence\n",
      ",\n",
      "arXiv\n",
      ":\n",
      "2401.14196\n",
      "^\n",
      "\"DeepSeek Coder\"\n",
      ".\n",
      "deepseekcoder.github.io\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "deepseek-ai/DeepSeek-Coder\n",
      ", DeepSeek, 27 January 2025\n",
      ", retrieved\n",
      "27 January\n",
      "2025\n",
      "^\n",
      "\"deepseek-ai/deepseek-coder-5.7bmqa-base · Hugging Face\"\n",
      ".\n",
      "Hugging Face\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "DeepSeek-AI; Bi, Xiao; Chen, Deli; Chen, Guanting; Chen, Shanhuang; Dai, Damai; Deng, Chengqi; Ding, Honghui; Dong, Kai (5 January 2024),\n",
      "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism\n",
      ",\n",
      "arXiv\n",
      ":\n",
      "2401.02954\n",
      "^\n",
      "deepseek-ai/DeepSeek-LLM\n",
      ", DeepSeek, 27 January 2025\n",
      ", retrieved\n",
      "27 January\n",
      "2025\n",
      "^\n",
      "a\n",
      "b\n",
      "Dai, Damai; Deng, Chengqi; Zhao, Chenggang; Xu, R. X.; Gao, Huazuo; Chen, Deli; Li, Jiashi; Zeng, Wangding; Yu, Xingkai (11 January 2024),\n",
      "DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models\n",
      ",\n",
      "arXiv\n",
      ":\n",
      "2401.06066\n",
      "^\n",
      "Shao, Zhihong; Wang, Peiyi; Zhu, Qihao; Xu, Runxin; Song, Junxiao; Bi, Xiao; Zhang, Haowei; Zhang, Mingchuan; Li, Y. K. (27 April 2024),\n",
      "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\n",
      ",\n",
      "arXiv\n",
      ":\n",
      "2402.03300\n",
      ".\n",
      "^\n",
      "Wang, Peiyi; Li, Lei; Shao, Zhihong; Xu, R. X.; Dai, Damai; Li, Yifei; Chen, Deli; Wu, Y.; Sui, Zhifang (19 February 2024),\n",
      "Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations\n",
      ",\n",
      "arXiv\n",
      ":\n",
      "2312.08935\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "DeepSeek-AI; Liu, Aixin; Feng, Bei; Wang, Bin; Wang, Bingxuan; Liu, Bo; Zhao, Chenggang; Dengr, Chengqi; Ruan, Chong (19 June 2024),\n",
      "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model\n",
      ",\n",
      "arXiv\n",
      ":\n",
      "2405.04434\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "Peng, Bowen; Quesnelle, Jeffrey; Fan, Honglu; Shippole, Enrico (1 November 2023),\n",
      "YaRN: Efficient Context Window Extension of Large Language Models\n",
      ",\n",
      "arXiv\n",
      ":\n",
      "2309.00071\n",
      ".\n",
      "^\n",
      "\"config.json · deepseek-ai/DeepSeek-V2-Lite at main\"\n",
      ".\n",
      "Hugging Face\n",
      ". 15 May 2024\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "\"config.json · deepseek-ai/DeepSeek-V2 at main\"\n",
      ".\n",
      "Hugging Face\n",
      ". 6 May 2024\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "DeepSeek-AI; Zhu, Qihao; Guo, Daya; Shao, Zhihong; Yang, Dejian; Wang, Peiyi; Xu, Runxin; Wu, Y.; Li, Yukun (17 June 2024),\n",
      "DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence\n",
      ",\n",
      "arXiv\n",
      ":\n",
      "2406.11931\n",
      "^\n",
      "\"deepseek-ai/DeepSeek-V2.5 · Hugging Face\"\n",
      ".\n",
      "Hugging Face\n",
      ". 3 January 2025\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "DeepSeek-AI; Liu, Aixin; Feng, Bei; Xue, Bing; Wang, Bingxuan; Wu, Bochao; Lu, Chengda; Zhao, Chenggang; Deng, Chengqi (27 December 2024),\n",
      "DeepSeek-V3 Technical Report\n",
      ",\n",
      "arXiv\n",
      ":\n",
      "2412.19437\n",
      "^\n",
      "\"config.json · deepseek-ai/DeepSeek-V3 at main\"\n",
      ".\n",
      "Hugging Face\n",
      ". 26 December 2024\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Jiang, Ben (27 December 2024).\n",
      "\"Chinese start-up DeepSeek's new AI model outperforms Meta, OpenAI products\"\n",
      ".\n",
      "South China Morning Post\n",
      ".\n",
      "Archived\n",
      "from the original on 27 December 2024\n",
      ". Retrieved\n",
      "28 December\n",
      "2024\n",
      ".\n",
      "^\n",
      "Sharma, Shubham (26 December 2024).\n",
      "\"DeepSeek-V3, ultra-large open-source AI, outperforms Llama and Qwen on launch\"\n",
      ".\n",
      "VentureBeat\n",
      ".\n",
      "Archived\n",
      "from the original on 27 December 2024\n",
      ". Retrieved\n",
      "28 December\n",
      "2024\n",
      ".\n",
      "^\n",
      "Wiggers, Kyle (26 December 2024).\n",
      "\"DeepSeek's new AI model appears to be one of the best 'open' challengers yet\"\n",
      ".\n",
      "TechCrunch\n",
      ".\n",
      "Archived\n",
      "from the original on 2 January 2025\n",
      ". Retrieved\n",
      "31 December\n",
      "2024\n",
      ".\n",
      "^\n",
      "\"Deepseek Log in page\"\n",
      ".\n",
      "DeepSeek\n",
      ". Retrieved\n",
      "30 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "\"News | DeepSeek-R1-Lite Release 2024/11/20: 🚀 DeepSeek-R1-Lite-Preview is now live: unleashing supercharged reasoning power!\"\n",
      ".\n",
      "DeepSeek API Docs\n",
      ". Archived from\n",
      "the original\n",
      "on 20 November 2024\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Franzen, Carl (20 November 2024).\n",
      "\"DeepSeek's first reasoning model R1-Lite-Preview turns heads, beating OpenAI o1 performance\"\n",
      ".\n",
      "VentureBeat\n",
      ".\n",
      "Archived\n",
      "from the original on 22 November 2024\n",
      ". Retrieved\n",
      "28 December\n",
      "2024\n",
      ".\n",
      "^\n",
      "Huang, Raffaele (24 December 2024).\n",
      "\"Don't Look Now, but China's AI Is Catching Up Fast\"\n",
      ".\n",
      "The Wall Street Journal\n",
      ".\n",
      "Archived\n",
      "from the original on 27 December 2024\n",
      ". Retrieved\n",
      "28 December\n",
      "2024\n",
      ".\n",
      "^\n",
      "\"Release DeepSeek-R1 · deepseek-ai/DeepSeek-R1@23807ce\"\n",
      ".\n",
      "GitHub\n",
      ".\n",
      "Archived\n",
      "from the original on 21 January 2025\n",
      ". Retrieved\n",
      "21 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "DeepSeek-AI; Guo, Daya; Yang, Dejian; Zhang, Haowei; Song, Junxiao; Zhang, Ruoyu; Xu, Runxin; Zhu, Qihao; Ma, Shirong (22 January 2025),\n",
      "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\n",
      ",\n",
      "arXiv\n",
      ":\n",
      "2501.12948\n",
      "^\n",
      "\"Chinese AI startup DeepSeek overtakes ChatGPT on Apple App Store\"\n",
      ".\n",
      "Reuters\n",
      ". 27 January 2025\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Wade, David (6 December 2024).\n",
      "\"American AI has reached its Sputnik moment\"\n",
      ".\n",
      "The Hill\n",
      ".\n",
      "Archived\n",
      "from the original on 8 December 2024\n",
      ". Retrieved\n",
      "25 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "Milmo, Dan; Hawkins, Amy; Booth, Robert; Kollewe, Julia (28 January 2025).\n",
      "\"\n",
      "'Sputnik moment': $1tn wiped off US stocks after Chinese firm unveils AI chatbot\"\n",
      ".\n",
      "The Guardian\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "Hoskins, Peter; Rahman-Jones, Imran (27 January 2025).\n",
      "\"Nvidia shares sink as Chinese AI app spooks markets\"\n",
      ".\n",
      "BBC\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Goldman, David (27 January 2025).\n",
      "\"What is DeepSeek, the Chinese AI startup that shook the tech world? | CNN Business\"\n",
      ".\n",
      "CNN\n",
      ". Retrieved\n",
      "29 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "\"DeepSeek poses a challenge to Beijing as much as to Silicon Valley\"\n",
      ".\n",
      "The Economist\n",
      ". 29 January 2025.\n",
      "ISSN\n",
      "0013-0613\n",
      ". Retrieved\n",
      "31 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Paul, Katie; Nellis, Stephen (30 January 2025).\n",
      "\"Chinese state-linked accounts hyped DeepSeek AI launch ahead of US stock rout, Graphika says\"\n",
      ".\n",
      "Reuters\n",
      ". Retrieved\n",
      "30 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "江钰涵 (22 January 2025).\n",
      "\"量化巨头幻方创始人梁文锋参加总理座谈会并发言，他还创办了\"AI界拼多多\"\n",
      "\"\n",
      ".\n",
      "Sina Corp\n",
      ". Retrieved\n",
      "31 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Shilov, Anton (27 December 2024).\n",
      "\"Chinese AI company's AI model breakthrough highlights limits of US sanctions\"\n",
      ".\n",
      "Tom's Hardware\n",
      ".\n",
      "Archived\n",
      "from the original on 28 December 2024\n",
      ". Retrieved\n",
      "28 December\n",
      "2024\n",
      ".\n",
      "^\n",
      "\"DeepSeek updates – Chinese AI chatbot sparks US market turmoil, wiping $500bn off Nvidia\"\n",
      ".\n",
      "BBC News\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "{{\n",
      "cite web\n",
      "}}\n",
      ":  CS1 maint: url-status (\n",
      "link\n",
      ")\n",
      "^\n",
      "Nazareth, Rita (26 January 2025).\n",
      "\"Stock Rout Gets Ugly as Nvidia Extends Loss to 17%: Markets Wrap\"\n",
      ".\n",
      "Bloomberg L.P.\n",
      "Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Carew, Sinéad; Cooper, Amanda; Banerjee, Ankur (27 January 2025).\n",
      "\"DeepSeek sparks global AI selloff, Nvidia losses about $593 billion of value\"\n",
      ".\n",
      "Reuters\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "Sherry, Ben (28 January 2025).\n",
      "\"DeepSeek, Calling It 'Impressive' but Staying Skeptical\"\n",
      ".\n",
      "Inc.\n",
      "Retrieved\n",
      "29 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Okemwa, Kevin (28 January 2025).\n",
      "\"Microsoft CEO Satya Nadella touts DeepSeek's open-source AI as \"super impressive\": \"We should take the developments out of China very, very seriously\"\n",
      "\"\n",
      ".\n",
      "Windows Central\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Nazzaro, Miranda (28 January 2025).\n",
      "\"OpenAI's Sam Altman calls DeepSeek model 'impressive'\n",
      "\"\n",
      ".\n",
      "The Hill\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Dou, Eva; Gregg, Aaron; Zakrzewski, Cat; Tiku, Nitasha; Najmabadi, Shannon (28 January 2025).\n",
      "\"Trump calls China's DeepSeek AI app a 'wake-up call' after tech stocks slide\"\n",
      ".\n",
      "The Washington Post\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Habeshian, Sareen (28 January 2025).\n",
      "\"Johnson bashes China on AI, Trump calls DeepSeek development \"positive\"\n",
      "\"\n",
      ".\n",
      "Axios\n",
      ".\n",
      "^\n",
      "Karaian, Jason; Rennison, Joe (27 January 2025).\n",
      "\"China's A.I. Advances Spook Big Tech Investors on Wall Street\"\n",
      ".\n",
      "New York Times\n",
      ".\n",
      "^\n",
      "Sharma, Manoj (6 January 2025).\n",
      "\"Musk dismisses, Altman applauds: What leaders say on DeepSeek's disruption\"\n",
      ".\n",
      "Fortune India\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Dhawan, Sunil (28 January 2025).\n",
      "\"Elon Musk 'questions' DeepSeek's claims, suggests massive Nvidia GPU infrastructure\"\n",
      ".\n",
      "The Financial Express\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Kim, Eugene (27 January 2025).\n",
      "\"Big AWS customers, including Stripe and Toyota, are hounding the cloud giant for access to DeepSeek AI models\"\n",
      ".\n",
      "Business Insider\n",
      ".\n",
      "^\n",
      "Kerr, Dara (27 January 2025).\n",
      "\"DeepSeek hit with 'large-scale' cyber-attack after AI chatbot tops app stores\"\n",
      ".\n",
      "The Guardian\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Tweedie, Steven; Altchek, Ana (27 January 2025).\n",
      "\"DeepSeek temporarily limited new sign-ups, citing 'large-scale malicious attacks'\n",
      "\"\n",
      ".\n",
      "Business Insider\n",
      ".\n",
      "^\n",
      "Field, Matthew; Titcomb, James (27 January 2025).\n",
      "\"Chinese AI has sparked a $1 trillion panic – and it doesn't care about free speech\"\n",
      ".\n",
      "The Daily Telegraph\n",
      ".\n",
      "ISSN\n",
      "0307-1235\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "Steinschaden, Jakob (27 January 2025).\n",
      "\"DeepSeek: This is what live censorship looks like in the Chinese AI chatbot\"\n",
      ".\n",
      "Trending Topics\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "Lu, Donna (28 January 2025).\n",
      "\"We tried out DeepSeek. It worked well, until we asked it about Tiananmen Square and Taiwan\"\n",
      ".\n",
      "The Guardian\n",
      ".\n",
      "ISSN\n",
      "0261-3077\n",
      ". Retrieved\n",
      "30 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "\"The Guardian view on a global AI race: geopolitics, innovation and the rise of chaos\"\n",
      ".\n",
      "The Guardian\n",
      ". 26 January 2025.\n",
      "ISSN\n",
      "0261-3077\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Yang, Angela; Cui, Jasmine (27 January 2025).\n",
      "\"Chinese AI DeepSeek jolts Silicon Valley, giving the AI race its 'Sputnik moment'\n",
      "\"\n",
      ".\n",
      "NBC News\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Kimery, Anthony (26 January 2025).\n",
      "\"China's DeepSeek AI poses formidable cyber, data privacy threats\"\n",
      ".\n",
      "Biometric Update\n",
      ". Retrieved\n",
      "27 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Booth, Robert; Milmo, Dan (28 January 2025).\n",
      "\"Experts urge caution over use of Chinese AI DeepSeek\"\n",
      ".\n",
      "The Guardian\n",
      ".\n",
      "ISSN\n",
      "0261-3077\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Hornby, Rael (28 January 2025).\n",
      "\"DeepSeek's success has painted a huge TikTok-shaped target on its back\"\n",
      ".\n",
      "LaptopMag\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Burgess, Matt; Newman, Lily Hay (27 January 2025).\n",
      "\"DeepSeek's Popular AI App Is Explicitly Sending US Data to China\"\n",
      ".\n",
      "Wired\n",
      ".\n",
      "ISSN\n",
      "1059-1028\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "\"Italy regulator seeks information from DeepSeek on data protection\"\n",
      ".\n",
      "Reuters\n",
      ". 28 January 2025\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "Shalal, Andrea; Shepardson, David (28 January 2025).\n",
      "\"White House evaluates effect of China AI app DeepSeek on national security, official says\"\n",
      ".\n",
      "Reuters\n",
      ". Retrieved\n",
      "28 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "a\n",
      "b\n",
      "\"Taiwan says government departments should not use DeepSeek, citing security concerns\"\n",
      ".\n",
      "Reuters\n",
      ". 31 January 2025\n",
      ". Retrieved\n",
      "31 January\n",
      "2025\n",
      ".\n",
      "^\n",
      "\"Dutch privacy watchdog to launch investigation into China's DeepSeek AI\"\n",
      ".\n",
      "Reuters\n",
      ". 31 January 2025\n",
      ". Retrieved\n",
      "1 February\n",
      "2025\n",
      ".\n",
      "^\n",
      "Lathan, Nadia (31 January 2025).\n",
      "\"Texas governor orders ban on DeepSeek, RedNote for government devices\"\n",
      ".\n",
      "Associated Press\n",
      ". Retrieved\n",
      "1 February\n",
      "2025\n",
      ".\n",
      "External links\n",
      "[\n",
      "edit\n",
      "]\n",
      "Wikimedia Commons has media related to\n",
      "DeepSeek\n",
      ".\n",
      "Official website\n",
      "DeepSeek\n",
      "on\n",
      "GitHub\n",
      "DeepSeek\n",
      "on\n",
      "Hugging Face\n",
      "Official API documentation\n",
      "Anthology of DeepSeek papers\n",
      "v\n",
      "t\n",
      "e\n",
      "Generative AI\n",
      "chatbots\n",
      "United States\n",
      "ChatGPT\n",
      "Claude\n",
      "Copilot\n",
      "Gemini\n",
      "Grok\n",
      "Poe\n",
      "Replika\n",
      "You.com\n",
      "Russia\n",
      "YandexGPT\n",
      "China\n",
      "DeepSeek\n",
      "Qwen\n",
      "Europe\n",
      "Mistral\n",
      "(France)\n",
      "Korea\n",
      "Galaxy AI\n",
      "Defunct\n",
      "Bard\n",
      "Related\n",
      "Large language models\n",
      "Category\n",
      "v\n",
      "t\n",
      "e\n",
      "Generative AI\n",
      "Concepts\n",
      "Autoencoder\n",
      "Deep learning\n",
      "Generative adversarial network\n",
      "Generative pre-trained transformer\n",
      "Large language model\n",
      "Neural network\n",
      "Prompt engineering\n",
      "Retrieval-augmented generation\n",
      "Reinforcement learning from human feedback\n",
      "Self-supervised learning\n",
      "Transformer\n",
      "Variational autoencoder\n",
      "Vision transformer\n",
      "Word embedding\n",
      "Models\n",
      "Text\n",
      "Claude\n",
      "DBRX\n",
      "Gemini\n",
      "GPT\n",
      "1\n",
      "2\n",
      "3\n",
      "J\n",
      "ChatGPT\n",
      "4\n",
      "4o\n",
      "o1\n",
      "o3\n",
      "Grok\n",
      "Granite\n",
      "Llama\n",
      "Mistral Large\n",
      "PanGu-Σ\n",
      "Qwen\n",
      "Image\n",
      "Aurora\n",
      "DALL-E\n",
      "Firefly\n",
      "Flux\n",
      "Ideogram\n",
      "Midjourney\n",
      "Stable Diffusion\n",
      "Video\n",
      "Dream Machine\n",
      "Gen-3 Alpha\n",
      "Hailuo AI\n",
      "Kling\n",
      "Sora\n",
      "Veo\n",
      "VideoPoet\n",
      "Music\n",
      "Udio\n",
      "Suno AI\n",
      "Companies\n",
      "01.AI\n",
      "Alibaba\n",
      "Anthropic\n",
      "Baichuan\n",
      "DeepSeek\n",
      "ElevenLabs\n",
      "Google DeepMind\n",
      "Hugging Face\n",
      "Kuaishou\n",
      "Meta AI\n",
      "MiniMax\n",
      "Mistral AI\n",
      "Moonshot AI\n",
      "OpenAI\n",
      "Runway\n",
      "Stability AI\n",
      "Synthesia\n",
      "xAI\n",
      "Zhipu AI\n",
      "Category\n",
      "Commons\n",
      "Authority control databases\n",
      ": National\n",
      "Germany\n",
      "Retrieved from \"\n",
      "https://en.wikipedia.org/w/index.php?title=DeepSeek&oldid=1273433515\n",
      "\"\n",
      "Categories\n",
      ":\n",
      "2023 establishments in China\n",
      "Artificial intelligence companies\n",
      "Artificial intelligence laboratories\n",
      "Companies based in Hangzhou\n",
      "Technology companies established in 2023\n",
      "Hidden categories:\n",
      "CS1 maint: url-status\n",
      "Articles with short description\n",
      "Short description matches Wikidata\n",
      "Use dmy dates from February 2025\n",
      "Articles containing Chinese-language text\n",
      "Articles containing simplified Chinese-language text\n",
      "Wikipedia articles that are too technical from January 2025\n",
      "All articles that are too technical\n",
      "Commons category link from Wikidata\n",
      "This page was last edited on 2 February 2025, at 07:15\n",
      "(UTC)\n",
      ".\n",
      "Text is available under the\n",
      "Creative Commons Attribution-ShareAlike 4.0 License\n",
      ";\n",
      "additional terms may apply. By using this site, you agree to the\n",
      "Terms of Use\n",
      "and\n",
      "Privacy Policy\n",
      ". Wikipedia® is a registered trademark of the\n",
      "Wikimedia Foundation, Inc.\n",
      ", a non-profit organization.\n",
      "Privacy policy\n",
      "About Wikipedia\n",
      "Disclaimers\n",
      "Contact Wikipedia\n",
      "Code of Conduct\n",
      "Developers\n",
      "Statistics\n",
      "Cookie statement\n",
      "Mobile view\n",
      "Search\n",
      "Search\n",
      "Toggle the table of contents\n",
      "DeepSeek\n",
      "58 languages\n",
      "Add topic\n"
     ]
    }
   ],
   "source": [
    "web = Website(\"https://en.wikipedia.org/wiki/DeepSeek\")\n",
    "print(web.title)\n",
    "print(web.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#bodyContent', '/wiki/Main_Page', '/wiki/Wikipedia:Contents', '/wiki/Portal:Current_events', '/wiki/Special:Random', '/wiki/Wikipedia:About', '//en.wikipedia.org/wiki/Wikipedia:Contact_us', '/wiki/Help:Contents', '/wiki/Help:Introduction', '/wiki/Wikipedia:Community_portal', '/wiki/Special:RecentChanges', '/wiki/Wikipedia:File_upload_wizard', '/wiki/Main_Page', '/wiki/Special:Search', 'https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en', '/w/index.php?title=Special:CreateAccount&returnto=DeepSeek', '/w/index.php?title=Special:UserLogin&returnto=DeepSeek', 'https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en', '/w/index.php?title=Special:CreateAccount&returnto=DeepSeek', '/w/index.php?title=Special:UserLogin&returnto=DeepSeek', '/wiki/Help:Introduction', '/wiki/Special:MyContributions', '/wiki/Special:MyTalk', '#', '#Background', '#Development_and_release_history', '#DeepSeek_Coder', '#DeepSeek_LLM', '#V2', '#V3', '#R1', '#Assessment_and_reactions', '#Concerns', '#Censorship', '#Security_and_privacy', '#See_also', '#Notes', '#References', '#External_links', 'https://af.wikipedia.org/wiki/DeepSeek', 'https://ar.wikipedia.org/wiki/%D8%AF%D9%8A%D8%A8_%D8%B3%D9%8A%D9%83', 'https://an.wikipedia.org/wiki/DeepSeek', 'https://as.wikipedia.org/wiki/%E0%A6%A1%E0%A7%80%E0%A6%AA%E0%A6%9B%E0%A7%80%E0%A6%95', 'https://az.wikipedia.org/wiki/DeepSeek', 'https://bn.wikipedia.org/wiki/%E0%A6%A1%E0%A6%BF%E0%A6%AA%E0%A6%B8%E0%A6%BF%E0%A6%95', 'https://bg.wikipedia.org/wiki/DeepSeek', 'https://ca.wikipedia.org/wiki/DeepSeek', 'https://cs.wikipedia.org/wiki/DeepSeek', 'https://da.wikipedia.org/wiki/DeepSeek', 'https://ary.wikipedia.org/wiki/%D8%AF%D9%8A%D9%BE_%D8%B3%D9%8A%D9%83', 'https://de.wikipedia.org/wiki/DeepSeek', 'https://el.wikipedia.org/wiki/DeepSeek', 'https://es.wikipedia.org/wiki/DeepSeek', 'https://eo.wikipedia.org/wiki/DeepSeek', 'https://eu.wikipedia.org/wiki/DeepSeek', 'https://fa.wikipedia.org/wiki/%D8%AF%DB%8C%D9%BE%E2%80%8C%D8%B3%DB%8C%DA%A9', 'https://fr.wikipedia.org/wiki/DeepSeek', 'https://fy.wikipedia.org/wiki/DeepSeek', 'https://ff.wikipedia.org/wiki/DeepSeek', 'https://ga.wikipedia.org/wiki/DeepSeek', 'https://gl.wikipedia.org/wiki/DeepSeek', 'https://ko.wikipedia.org/wiki/%EB%94%A5%EC%8B%9C%ED%81%AC', 'https://io.wikipedia.org/wiki/DeepSeek', 'https://id.wikipedia.org/wiki/DeepSeek', 'https://it.wikipedia.org/wiki/DeepSeek', 'https://he.wikipedia.org/wiki/DeepSeek', 'https://sw.wikipedia.org/wiki/DeepSeek', 'https://lv.wikipedia.org/wiki/DeepSeek', 'https://hu.wikipedia.org/wiki/DeepSeek', 'https://mk.wikipedia.org/wiki/DeepSeek', 'https://ml.wikipedia.org/wiki/%E0%B4%A1%E0%B5%80%E0%B4%AA%E0%B5%8D%E0%B4%B8%E0%B5%80%E0%B4%95%E0%B5%8D%E0%B4%95%E0%B5%8D', 'https://nl.wikipedia.org/wiki/DeepSeek', 'https://ne.wikipedia.org/wiki/%E0%A4%A1%E0%A4%BF%E0%A4%AA%E0%A4%B8%E0%A4%BF%E0%A4%95', 'https://ja.wikipedia.org/wiki/DeepSeek', 'https://uz.wikipedia.org/wiki/DeepSeek', 'https://pl.wikipedia.org/wiki/DeepSeek', 'https://pt.wikipedia.org/wiki/DeepSeek', 'https://kaa.wikipedia.org/wiki/DeepSeek', 'https://ro.wikipedia.org/wiki/DeepSeek', 'https://ru.wikipedia.org/wiki/DeepSeek', 'https://simple.wikipedia.org/wiki/DeepSeek', 'https://sl.wikipedia.org/wiki/DeepSeek', 'https://sr.wikipedia.org/wiki/DeepSeek', 'https://fi.wikipedia.org/wiki/Deepseek', 'https://sv.wikipedia.org/wiki/Deepseek', 'https://tl.wikipedia.org/wiki/DeepSeek', 'https://ta.wikipedia.org/wiki/%E0%AE%9F%E0%AF%80%E0%AE%AA%E0%AF%8D%E0%AE%9A%E0%AF%80%E0%AE%95%E0%AF%8D', 'https://shn.wikipedia.org/wiki/%E1%80%90%E1%80%AD%E1%80%95%E1%80%BA%E1%82%89%E1%80%9E%E1%80%AD%E1%81%B5%E1%80%BA%E1%82%89%E1%81%B6%E1%80%BA', 'https://th.wikipedia.org/wiki/%E0%B8%94%E0%B8%B5%E0%B8%9B%E0%B8%8B%E0%B8%B5%E0%B8%81', 'https://tr.wikipedia.org/wiki/DeepSeek', 'https://uk.wikipedia.org/wiki/DeepSeek', 'https://ur.wikipedia.org/wiki/%DA%88%DB%8C%D9%BE_%D8%B3%DB%8C%DA%A9', 'https://ug.wikipedia.org/wiki/%DA%86%D9%88%DA%AD%D9%82%DB%87%D8%B1_%D9%82%DB%90%D8%AF%D9%89%D8%B1_(%D8%B3%DB%88%D9%86%D8%A6%D9%89%D9%8A_%D8%A6%DB%95%D9%82%D9%89%D9%84)', 'https://vi.wikipedia.org/wiki/DeepSeek', 'https://wuu.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2', 'https://zh-yue.wikipedia.org/wiki/DeepSeek', 'https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2', 'https://www.wikidata.org/wiki/Special:EntityPage/Q131577453#sitelinks-wikipedia', '/wiki/DeepSeek', '/wiki/Talk:DeepSeek', '/wiki/DeepSeek', '/w/index.php?title=DeepSeek&action=edit', '/w/index.php?title=DeepSeek&action=history', '/wiki/DeepSeek', '/w/index.php?title=DeepSeek&action=edit', '/w/index.php?title=DeepSeek&action=history', '/wiki/Special:WhatLinksHere/DeepSeek', '/wiki/Special:RecentChangesLinked/DeepSeek', '//en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard', '/wiki/Special:SpecialPages', '/w/index.php?title=DeepSeek&oldid=1273433515', '/w/index.php?title=DeepSeek&action=info', '/w/index.php?title=Special:CiteThisPage&page=DeepSeek&id=1273433515&wpFormIdentifier=titleform', '/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDeepSeek', '/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDeepSeek', '/w/index.php?title=Special:DownloadAsPdf&page=DeepSeek&action=show-download-screen', '/w/index.php?title=DeepSeek&printable=yes', 'https://commons.wikimedia.org/wiki/Category:DeepSeek', 'https://www.wikidata.org/wiki/Special:EntityPage/Q131577453', '/wiki/File:DeepSeek_logo.svg', '/wiki/Information_technology', '/wiki/Artificial_intelligence', '/wiki/Liang_Wenfeng', '/wiki/Hangzhou', '/wiki/High-Flyer', 'https://deepseek.com', 'https://www.wikidata.org/wiki/Q131577453#P856', '#cite_note-2', '/wiki/Simplified_Chinese_characters', '/wiki/Pinyin', '/wiki/Artificial_intelligence', '/wiki/Open-source', '/wiki/Large_language_models', '/wiki/Hangzhou,_Zhejiang', '/wiki/High-Flyer', '/wiki/Liang_Wenfeng', '/wiki/Large_language_model', '/wiki/OpenAI', '/wiki/GPT-4o', '/wiki/OpenAI_o1', '#cite_note-3', '/wiki/Training,_validation,_and_test_data_sets', '/wiki/GPT-4', '#cite_note-vincent-4', '#cite_note-vincent-4', '#cite_note-:8-5', '#cite_note-6', '/wiki/Nvidia', '#cite_note-7', '#cite_note-8', '/wiki/Chatbot', '/wiki/IOS', '/wiki/Android_(operating_system)', '/wiki/ChatGPT', '/wiki/App_Store_(Apple)', '#cite_note-auto-9', '#cite_note-10', '#cite_note-11', '#cite_note-auto-9', '#cite_note-12', 'https://en.wiktionary.org/wiki/brinkmanship', '#cite_note-13', '/wiki/Generative_artificial_intelligence', '#cite_note-auto1-14', '#cite_note-auto-9', '/wiki/Computer_science', '#cite_note-:8-5', '/w/index.php?title=DeepSeek&action=edit&section=1', '/wiki/2007%E2%80%932008_financial_crisis', '/wiki/Zhejiang_University', '#cite_note-:6-15', '#cite_note-:0-16', '#cite_note-FT_2025-17', '/wiki/Generative_artificial_intelligence', '/wiki/Chatbot', '/wiki/Open_source', '#cite_note-auto1-14', '#cite_note-FT_2025-17', '/wiki/36Kr', '/wiki/Ampere_(microarchitecture)#A100_accelerator_and_DGX_A100', '#cite_note-CNBC_2023-18', '#cite_note-:0-16', '/wiki/Artificial_general_intelligence', '#cite_note-19', '#cite_note-scmp_1_January_2025-20', '#cite_note-21', '#cite_note-:0-16', '#cite_note-:2-22', '#cite_note-scmp_1_January_2025-20', '/wiki/Venture_capital', '/wiki/Exit_(investing)', '#cite_note-:0-16', '/wiki/Price_war', '/wiki/Pinduoduo', '/wiki/ByteDance', '/wiki/Tencent', '/wiki/Baidu', '/wiki/Alibaba_Group', '#cite_note-:3-23', '#cite_note-:3-23', '#cite_note-:8-5', '#cite_note-scmp_1_January_2025-20', '#cite_note-:8-5', '/wiki/Gaokao', '#cite_note-:8-5', '/w/index.php?title=DeepSeek&action=edit&section=2', 'https://en.wikipedia.org/w/index.php?title=DeepSeek&action=edit', '/wiki/Wikipedia:Make_technical_articles_understandable', '/wiki/Help:Maintenance_template_removal', '/w/index.php?title=DeepSeek&action=edit&section=3', '/wiki/MIT_License', '#cite_note-24', '/wiki/Training,_validation,_and_test_data_sets', '#cite_note-:1-25', '#cite_note-26', '#cite_note-27', '/wiki/Stack_Exchange', '/wiki/Fine-tuning_(deep_learning)', '/wiki/Hopper_(microarchitecture)', '/wiki/InfiniBand', '/wiki/NVLink', '/wiki/NVSwitch', '#cite_note-:1-25', '#cite_note-:1-25', '#cite_note-28', '#cite_note-fn1-29', '#cite_note-fn1-29', '/w/index.php?title=DeepSeek&action=edit&section=4', '/wiki/Chatbot', '#cite_note-:9-30', '#cite_note-31', '/wiki/Llama_(language_model)', '/wiki/Transformer_(deep_learning_architecture)#pre-LN', '/wiki/Transformer_(deep_learning_architecture)#decoder-only', '/wiki/RMSNorm', '/wiki/SwiGLU', '/wiki/Rotary_positional_embedding', '/wiki/Grouped-query_attention', '/wiki/Byte_pair_encoding#Byte-level_BPE', '/wiki/Common_Crawl', '#cite_note-:9-30', '#cite_note-:9-30', '#cite_note-fn1-29', '/wiki/Reinforcement_learning_from_human_feedback', '#cite_note-:9-30', '/wiki/Mixture_of_experts#Sparsely-gated_MoE_layer', '#cite_note-:12-32', '#cite_note-33', '/wiki/Reinforcement_learning', '/wiki/Reasoning_language_model#PRM', '#cite_note-34', '/wiki/Group_Relative_Policy_Optimization', '/w/index.php?title=DeepSeek&action=edit&section=5', '/wiki/File:DeepSeek_MoE_and_MLA_(DeepSeek-V2).svg', '#cite_note-:7-35', '#cite_note-:7-35', '#cite_note-:10-36', '#cite_note-:7-35', '#cite_note-:7-35', '/wiki/Low-rank_approximation', '/wiki/Transformer_(deep_learning_architecture)#MLA', '/wiki/Mixture_of_experts', '#cite_note-:12-32', '#cite_note-:7-35', '#cite_note-37', '#cite_note-38', '/wiki/Financial_Times', '/wiki/Renminbi', '/wiki/University_of_Waterloo', '#cite_note-:2-22', '#cite_note-39', '#cite_note-40', '#cite_note-41', '/w/index.php?title=DeepSeek&action=edit&section=6', '/wiki/File:Multi-Token_Prediction_(DeepSeek)_01.svg', '/wiki/Transformer_(deep_learning_architecture)#Multi-Token_Prediction', '#cite_note-:5-42', '#cite_note-:10-36', '#cite_note-:5-42', '#cite_note-43', '/wiki/File:Mixed-precision_training_in_DeepSeek_V3.svg', '#cite_note-:5-42', '/wiki/Mixed-precision_arithmetic', '/wiki/Floating-point_arithmetic', '/wiki/Mantissa_(floating_point_number)', '/wiki/Single-precision_floating-point_format', '/wiki/General_matrix_multiply', '/wiki/Bfloat16_floating-point_format', '#cite_note-:5-42', '#cite_note-:5-42', '#cite_note-:5-42', '/wiki/Llama_(language_model)', '/wiki/Qwen', '/wiki/GPT-4o', '/wiki/Claude_(language_model)', '#cite_note-scmp_1_January_2025-20', '#cite_note-44', '#cite_note-45', '#cite_note-46', '/w/index.php?title=DeepSeek&action=edit&section=7', '#cite_note-DSLI_1-47', '#cite_note-48', '#cite_note-49', '/wiki/OpenAI_o1', '/wiki/American_Invitational_Mathematics_Examination', '#cite_note-50', '/wiki/The_Wall_Street_Journal', '#cite_note-51', '#cite_note-52', '/wiki/Llama_(language_model)', '/wiki/Qwen', '/wiki/Synthetic_data', '#cite_note-:4-53', '#cite_note-:4-53', '#cite_note-:4-53', '#cite_note-:4-53', '/w/index.php?title=DeepSeek&action=edit&section=8', '/wiki/Virtual_assistant', '/wiki/Chatbot', '/wiki/Apple_IOS', '/wiki/Android_(operating_system)', '#cite_note-:8-5', '/wiki/Supercomputer', '/wiki/Graphics_processing_unit', '/wiki/Nvidia', '#cite_note-:5-42', '#cite_note-:5-42', '/wiki/Meta_Platforms', '#cite_note-:8-5', '#cite_note-54', '/wiki/The_Hill_(newspaper)', '/wiki/The_Guardian', '/wiki/Sputnik_moment', '#cite_note-55', '#cite_note-:11-56', '#cite_note-Hoskins_RJ-57', '/wiki/Marc_Andreessen', '#cite_note-Hoskins_RJ-57', '/wiki/Sam_Altman', '/wiki/CNN', '#cite_note-58', '/wiki/State_media', '#cite_note-59', '#cite_note-60', '/wiki/Li_Qiang', '#cite_note-61', '#cite_note-scmp_1_January_2025-20', '#cite_note-62', '#cite_note-63', '#cite_note-64', '/wiki/Broadcom', '/wiki/Microsoft', '/wiki/Google', '/wiki/Alphabet_Inc.', '/wiki/ASML_Holding', '#cite_note-Hoskins_RJ-57', '/wiki/Nasdaq', '#cite_note-65', '#cite_note-:11-56', '/wiki/File:Deepseek_login_error.png', '#cite_note-DSCI_1-66', '/wiki/Satya_Nadella', '/wiki/Stargate_LLC', '#cite_note-67', '#cite_note-68', '/wiki/Donald_Trump', '#cite_note-69', '#cite_note-70', '#cite_note-:11-56', '#cite_note-Hoskins_RJ-57', '#cite_note-71', '/wiki/Scale_AI', '/wiki/Alexandr_Wang', '/wiki/Anthropic', '/wiki/Dario_Amodei', '/wiki/Elon_Musk', '#cite_note-DSCI_1-66', '#cite_note-72', '#cite_note-73', '/wiki/Amazon_Web_Services', '/wiki/Toyota', '/wiki/Stripe,_Inc.', '#cite_note-74', '/wiki/Cyberattack', '#cite_note-Guardian-75', '#cite_note-76', '/w/index.php?title=DeepSeek&action=edit&section=9', '/w/index.php?title=DeepSeek&action=edit&section=10', '/wiki/File:DeepSeek_when_asked_about_Xi_Jinping_and_Narendra_Modi.png', '/wiki/Xi_Jinping', '/wiki/Narendra_Modi', '/wiki/Government_of_China', '/wiki/1989_Tiananmen_Square_massacre', '/wiki/Persecution_of_Uyghurs_in_China', '/wiki/Censorship_of_Winnie-the-Pooh_in_China', '/wiki/Human_rights_in_China', '#cite_note-:13-77', '#cite_note-tt-78', '#cite_note-Lu_2025-79', '#cite_note-tt-78', '/wiki/Core_Socialist_Values', '/wiki/Cyberspace_Administration_of_China', '/wiki/Political_status_of_Taiwan', '#cite_note-:14-80', '/wiki/NBC_News', '/wiki/Taiwan_independence', '#cite_note-81', '/wiki/Leet', '#cite_note-Lu_2025-79', '/w/index.php?title=DeepSeek&action=edit&section=11', '/wiki/Chinese_information_operations_and_information_warfare', '/wiki/Influence_operations', '/wiki/Disinformation', '/wiki/Surveillance', '/wiki/Cyberweapon', '#cite_note-82', '#cite_note-83', '#cite_note-84', '/wiki/Wired_(magazine)', '/wiki/Baidu', '/wiki/ByteDance', '#cite_note-85', '/wiki/United_States_National_Security_Council', '#cite_note-86', '#cite_note-87', '/wiki/Personal_Information_Protection_Commission_(South_Korea)', '#cite_note-:15-88', '/wiki/Dutch_Data_Protection_Authority', '#cite_note-89', '#cite_note-:15-88', '/wiki/Greg_Abbott', '/wiki/Xiaohongshu', '/wiki/Lemon8', '#cite_note-90', '/w/index.php?title=DeepSeek&action=edit&section=12', '/wiki/Portal:Free_and_open-source_software', '/wiki/Artificial_intelligence_industry_in_China', '/w/index.php?title=DeepSeek&action=edit&section=13', '#cite_ref-2', '#cite_note-1', '#cite_ref-fn1_29-0', '#cite_ref-fn1_29-1', '#cite_ref-fn1_29-2', '#cite_ref-40', '#cite_ref-49', '/w/index.php?title=DeepSeek&action=edit&section=14', '#cite_ref-1', 'https://www.bloomberg.com/profile/company/2544189D:CH', '/wiki/Bloomberg_L.P.', '#cite_ref-3', 'https://www.nature.com/articles/d41586-025-00229-6', '/wiki/Nature_(journal)', '/wiki/Doi_(identifier)', 'https://doi.org/10.1038%2Fd41586-025-00229-6', '/wiki/ISSN_(identifier)', 'https://search.worldcat.org/issn/1476-4687', '/wiki/PMID_(identifier)', 'https://pubmed.ncbi.nlm.nih.gov/39849139', '#cite_ref-vincent_4-0', '#cite_ref-vincent_4-1', 'https://www.theguardian.com/commentisfree/2025/jan/28/deepseek-r1-ai-world-chinese-chatbot-tech-world-western', '/wiki/The_Guardian', '#cite_ref-:8_5-0', '#cite_ref-:8_5-1', '#cite_ref-:8_5-2', '#cite_ref-:8_5-3', '#cite_ref-:8_5-4', '#cite_ref-:8_5-5', '#cite_ref-:8_5-6', 'https://www.nytimes.com/2025/01/23/technology/deepseek-china-ai-chips.html?smid=fb-nytimes&smtyp=cur&fbclid=IwY2xjawIEynFleHRuA2FlbQIxMQABHZYKXN7GJpUyNRsaGEDQVadxRBarp-aBp1GhiuRe3B57Ehe6HYv7oiK78Q_aem_KTeDgqjV_-R80owNNWOBCQ', '/wiki/The_New_York_Times', '/wiki/ISSN_(identifier)', 'https://search.worldcat.org/issn/0362-4331', '#cite_ref-6', 'https://www.businessinsider.com/explaining-deepseek-chinese-models-efficiency-scaring-markets-2025-1', '/wiki/Business_Insider', '#cite_ref-7', 'https://www.computerweekly.com/news/366616907/Nvidia-investigation-signals-widening-of-US-and-China-chip-war', '/wiki/Computer_Weekly', '#cite_ref-8', 'https://www.bbc.com/news/articles/cx2vkd90mk8o', '/wiki/BBC', '#cite_ref-auto_9-0', '#cite_ref-auto_9-1', '#cite_ref-auto_9-2', 'https://www.nytimes.com/2025/01/27/technology/what-is-deepseek-china-ai.html', '/wiki/The_New_York_Times', '/wiki/ISSN_(identifier)', 'https://search.worldcat.org/issn/0362-4331', '#cite_ref-10', 'https://www.cnbc.com/2025/01/27/chinas-deepseek-ai-tops-chatgpt-app-store-what-you-should-know.html', '/wiki/CNBC', '#cite_ref-11', 'https://www.cbsnews.com/news/what-is-deepseek-ai-china-stock-nvidia-nvda-asml/', '/wiki/CBS_News', '#cite_ref-12', 'https://abcnews.go.com/Business/nvidia-microsoft-shares-tumble-china-based-ai-app/story?id=118136157', '/wiki/ABC_News_(United_States)', '#cite_ref-13', 'https://www.nytimes.com/2025/01/28/technology/why-deepseek-could-change-what-silicon-valley-believes-about-ai.html', '/wiki/The_New_York_Times', '/wiki/ISSN_(identifier)', 'https://search.worldcat.org/issn/0362-4331', '#cite_ref-auto1_14-0', '#cite_ref-auto1_14-1', 'https://www.forbes.com/sites/luisromero/2025/01/27/chatgpt-deepseek-or-llama-metas-lecun-says-open-source-is-the-key/', '/wiki/Forbes', '#cite_ref-:6_15-0', 'https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/', '/wiki/MIT_Technology_Review', 'https://web.archive.org/web/20250125180427/https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/', '#cite_ref-:0_16-0', '#cite_ref-:0_16-1', '#cite_ref-:0_16-2', '#cite_ref-:0_16-3', 'https://www.chinatalk.media/p/deepseek-from-hedge-fund-to-frontier', 'https://web.archive.org/web/20241228030725/https://www.chinatalk.media/p/deepseek-from-hedge-fund-to-frontier', '#cite_ref-FT_2025_17-0', '#cite_ref-FT_2025_17-1', 'https://www.removepaywall.com/search?url=https://www.ft.com/content/747a7b11-dcba-4aa5-8d25-403f56216d7e', '/wiki/Financial_Times', '#cite_ref-CNBC_2023_18-0', 'https://www.cnbc.com/2023/02/23/nvidias-a100-is-the-10000-chip-powering-the-race-for-ai-.html', '/wiki/CNBC', '#cite_ref-19', 'https://www.yicaiglobal.com/news/exclusive-chinese-quant-fund-high-flyer-will-not-use-agi-to-trade-stocks-managing-director-says', 'https://web.archive.org/web/20231231030712/https://www.yicaiglobal.com/news/exclusive-chinese-quant-fund-high-flyer-will-not-use-agi-to-trade-stocks-managing-director-says', '#cite_ref-scmp_1_January_2025_20-0', '#cite_ref-scmp_1_January_2025_20-1', '#cite_ref-scmp_1_January_2025_20-2', '#cite_ref-scmp_1_January_2025_20-3', '#cite_ref-scmp_1_January_2025_20-4', 'https://www.scmp.com/tech/tech-trends/article/3293050/meet-deepseek-chinese-start-changing-how-ai-models-are-trained', '/wiki/South_China_Morning_Post', 'https://web.archive.org/web/20250122160046/https://www.scmp.com/tech/tech-trends/article/3293050/meet-deepseek-chinese-start-changing-how-ai-models-are-trained', '#cite_ref-21', 'https://finance.sina.com.cn/jjxw/2025-02-01/doc-inehyqcx9694053.shtml', '/wiki/Sina_Corp', '#cite_ref-:2_22-0', '#cite_ref-:2_22-1', 'https://www.ft.com/content/357f3c68-b866-4c2e-b678-0d075051a260', '/wiki/Financial_Times', 'https://web.archive.org/web/20240717030903/https://www.ft.com/content/357f3c68-b866-4c2e-b678-0d075051a260', '#cite_ref-:3_23-0', '#cite_ref-:3_23-1', 'https://www.chinatalk.media/p/deepseek-ceo-interview-with-chinas', '#cite_ref-24', 'https://github.com/deepseek-ai/DeepSeek-Coder/blob/main/LICENSE-MODEL', '/wiki/GitHub', 'https://web.archive.org/web/20250122195853/https://github.com/deepseek-ai/deepseek-coder/blob/main/LICENSE-MODEL', '#cite_ref-:1_25-0', '#cite_ref-:1_25-1', '#cite_ref-:1_25-2', '/wiki/ArXiv_(identifier)', 'https://arxiv.org/abs/2401.14196', '#cite_ref-26', 'https://deepseekcoder.github.io/', '#cite_ref-27', 'https://github.com/deepseek-ai/deepseek-coder/', '#cite_ref-28', 'https://huggingface.co/deepseek-ai/deepseek-coder-5.7bmqa-base', '/wiki/Hugging_Face', '#cite_ref-:9_30-0', '#cite_ref-:9_30-1', '#cite_ref-:9_30-2', '#cite_ref-:9_30-3', '/wiki/ArXiv_(identifier)', 'https://arxiv.org/abs/2401.02954', '#cite_ref-31', 'https://github.com/deepseek-ai/DeepSeek-LLM', '#cite_ref-:12_32-0', '#cite_ref-:12_32-1', '/wiki/ArXiv_(identifier)', 'https://arxiv.org/abs/2401.06066', '#cite_ref-33', '/wiki/ArXiv_(identifier)', 'https://arxiv.org/abs/2402.03300', '#cite_ref-34', '/wiki/ArXiv_(identifier)', 'https://arxiv.org/abs/2312.08935', '#cite_ref-:7_35-0', '#cite_ref-:7_35-1', '#cite_ref-:7_35-2', '#cite_ref-:7_35-3', '#cite_ref-:7_35-4', '/wiki/ArXiv_(identifier)', 'https://arxiv.org/abs/2405.04434', '#cite_ref-:10_36-0', '#cite_ref-:10_36-1', '/wiki/ArXiv_(identifier)', 'https://arxiv.org/abs/2309.00071', '#cite_ref-37', 'https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite/blob/main/config.json', '/wiki/Hugging_Face', '#cite_ref-38', 'https://huggingface.co/deepseek-ai/DeepSeek-V2/blob/main/config.json', '/wiki/Hugging_Face', '#cite_ref-39', '/wiki/ArXiv_(identifier)', 'https://arxiv.org/abs/2406.11931', '#cite_ref-41', 'https://huggingface.co/deepseek-ai/DeepSeek-V2.5', '/wiki/Hugging_Face', '#cite_ref-:5_42-0', '#cite_ref-:5_42-1', '#cite_ref-:5_42-2', '#cite_ref-:5_42-3', '#cite_ref-:5_42-4', '#cite_ref-:5_42-5', '#cite_ref-:5_42-6', '#cite_ref-:5_42-7', '/wiki/ArXiv_(identifier)', 'https://arxiv.org/abs/2412.19437', '#cite_ref-43', 'https://huggingface.co/deepseek-ai/DeepSeek-V3/blob/main/config.json', '/wiki/Hugging_Face', '#cite_ref-44', 'https://www.scmp.com/tech/tech-trends/article/3292507/chinese-start-deepseek-launches-ai-model-outperforms-meta-openai-products', '/wiki/South_China_Morning_Post', 'https://web.archive.org/web/20241227191529/https://www.scmp.com/tech/tech-trends/article/3292507/chinese-start-deepseek-launches-ai-model-outperforms-meta-openai-products', '#cite_ref-45', 'https://venturebeat.com/ai/deepseek-v3-ultra-large-open-source-ai-outperforms-llama-and-qwen-on-launch/', '/wiki/VentureBeat', 'https://web.archive.org/web/20241227195503/https://venturebeat.com/ai/deepseek-v3-ultra-large-open-source-ai-outperforms-llama-and-qwen-on-launch/', '#cite_ref-46', 'https://techcrunch.com/2024/12/26/deepseeks-new-ai-model-appears-to-be-one-of-the-best-open-challengers-yet/', '/wiki/TechCrunch', 'https://web.archive.org/web/20250102103526/https://techcrunch.com/2024/12/26/deepseeks-new-ai-model-appears-to-be-one-of-the-best-open-challengers-yet/', '#cite_ref-DSLI_1_47-0', 'https://chat.deepseek.com/sign_in', '#cite_ref-48', 'https://web.archive.org/web/20241120141324/https://api-docs.deepseek.com/news/news1120', 'https://api-docs.deepseek.com/news/news1120', '#cite_ref-50', 'https://venturebeat.com/ai/deepseeks-first-reasoning-model-r1-lite-preview-turns-heads-beating-openai-o1-performance/', '/wiki/VentureBeat', 'https://web.archive.org/web/20241122010413/https://venturebeat.com/ai/deepseeks-first-reasoning-model-r1-lite-preview-turns-heads-beating-openai-o1-performance/', '#cite_ref-51', 'https://www.wsj.com/tech/ai/china-ai-advances-us-chips-7838fd20', '/wiki/The_Wall_Street_Journal', 'https://web.archive.org/web/20241227183842/https://www.wsj.com/tech/ai/china-ai-advances-us-chips-7838fd20', '#cite_ref-52', 'https://github.com/deepseek-ai/DeepSeek-R1/commit/23807ced51627276434655dd9f27725354818974', '/wiki/GitHub', 'https://web.archive.org/web/20250121104009/https://github.com/deepseek-ai/DeepSeek-R1/commit/23807ced51627276434655dd9f27725354818974', '#cite_ref-:4_53-0', '#cite_ref-:4_53-1', '#cite_ref-:4_53-2', '#cite_ref-:4_53-3', '/wiki/ArXiv_(identifier)', 'https://arxiv.org/abs/2501.12948', '#cite_ref-54', 'https://www.reuters.com/technology/artificial-intelligence/chinese-ai-startup-deepseek-overtakes-chatgpt-apple-app-store-2025-01-27/', '/wiki/Reuters', '#cite_ref-55', 'https://thehill.com/opinion/technology/5024271-ai-sputnik-moment-china-challenge/', '/wiki/The_Hill_(newspaper)', 'https://web.archive.org/web/20241208215538/https://thehill.com/opinion/technology/5024271-ai-sputnik-moment-china-challenge/', '#cite_ref-:11_56-0', '#cite_ref-:11_56-1', '#cite_ref-:11_56-2', 'https://www.theguardian.com/business/2025/jan/27/tech-shares-asia-europe-fall-china-ai-deepseek', '/wiki/The_Guardian', '#cite_ref-Hoskins_RJ_57-0', '#cite_ref-Hoskins_RJ_57-1', '#cite_ref-Hoskins_RJ_57-2', '#cite_ref-Hoskins_RJ_57-3', 'https://www.bbc.com/news/articles/c0qw7z2v1pgo', '/wiki/BBC', '#cite_ref-58', 'https://www.cnn.com/2025/01/27/tech/deepseek-ai-explainer/index.html', '/wiki/CNN', '#cite_ref-59', 'https://www.economist.com/business/2025/01/29/deepseek-poses-a-challenge-to-beijing-as-much-as-to-silicon-valley', '/wiki/The_Economist', '/wiki/ISSN_(identifier)', 'https://search.worldcat.org/issn/0013-0613', '#cite_ref-60', 'https://www.reuters.com/technology/artificial-intelligence/chinese-state-linked-accounts-hyped-deepseek-ai-launch-ahead-us-stock-rout-2025-01-31/', '/wiki/Reuters', '#cite_ref-61', 'https://finance.sina.com.cn/jjxw/2025-01-22/doc-inefuxsi7314244.shtml', '/wiki/Sina_Corp', '#cite_ref-62', 'https://www.tomshardware.com/tech-industry/artificial-intelligence/chinese-ai-company-says-breakthroughs-enabled-creating-a-leading-edge-ai-model-with-11x-less-compute-deepseeks-optimizations-highlight-limits-of-us-sanctions', '/wiki/Tom%27s_Hardware', 'https://web.archive.org/web/20241228014832/https://www.tomshardware.com/tech-industry/artificial-intelligence/chinese-ai-company-says-breakthroughs-enabled-creating-a-leading-edge-ai-model-with-11x-less-compute-deepseeks-optimizations-highlight-limits-of-us-sanctions', '#cite_ref-63', 'https://www.bbc.co.uk/news/live/cjr85l2e4l4t', '/wiki/BBC_News', '/wiki/Template:Cite_web', '/wiki/Category:CS1_maint:_url-status', '#cite_ref-64', 'https://www.bloomberg.com/news/articles/2025-01-26/asia-eyes-cautious-open-as-tariffs-remain-in-focus-markets-wrap', '/wiki/Bloomberg_L.P.', '#cite_ref-65', 'https://www.reuters.com/technology/chinas-deepseek-sets-off-ai-market-rout-2025-01-27/', '/wiki/Reuters', '#cite_ref-DSCI_1_66-0', '#cite_ref-DSCI_1_66-1', 'https://www.inc.com/ben-sherry/ai-leaders-in-the-u-s-react-to-deepseek-calling-it-impressive-but-staying-skeptical/91140125', '/wiki/Inc._(magazine)', '#cite_ref-67', 'https://www.windowscentral.com/software-apps/microsoft-ceo-satya-nadella-touts-deepseeks-open-source-ai-as-super-impressive', '/wiki/Windows_Central', '#cite_ref-68', 'https://thehill.com/policy/technology/5110258-openai-rival-deepseek-ai-model/', '/wiki/The_Hill_(newspaper)', '#cite_ref-69', 'https://www.washingtonpost.com/business/2025/01/27/deep-seek-ai-markets-nvidia/', '/wiki/The_Washington_Post', '#cite_ref-70', 'https://www.axios.com/2025/01/28/trump-mike-johnson-china-deepseek-ai', '/wiki/Axios_(website)', '#cite_ref-71', 'https://www.nytimes.com/2025/01/27/business/us-stock-market-deepseek-ai-sp500-nvidia.html', '/wiki/New_York_Times', '#cite_ref-72', 'https://www.fortuneindia.com/technology/musk-dismisses-sam-altman-applauds-heres-what-leaders-say-on-deepseeks-ai-disruption/120194', '/wiki/Fortune_India', '#cite_ref-73', 'https://www.financialexpress.com/business/investing-abroad-deepseek-sparks-debate-did-it-build-cutting-edge-ai-for-6-million-3728638/', '/wiki/The_Financial_Express_(India)', '#cite_ref-74', 'https://www.businessinsider.com/aws-deepseek-customer-cloud-access-bedrock-stripe-toyota-cisco-workday-2025-1', '/wiki/Business_Insider', '#cite_ref-Guardian_75-0', 'https://www.theguardian.com/technology/2025/jan/27/deepseek-cyberattack-ai', '/wiki/The_Guardian', '#cite_ref-76', 'https://www.businessinsider.com/deepseek-issues-account-registration-limited-china-phone-numbers-malicious-attack-2025-1', '/wiki/Business_Insider', '#cite_ref-:13_77-0', 'https://www.telegraph.co.uk/business/2025/01/27/chinese-deepseek-ai-has-sparked-a-1-trillion-panic/', '/wiki/The_Daily_Telegraph', '/wiki/ISSN_(identifier)', 'https://search.worldcat.org/issn/0307-1235', '#cite_ref-tt_78-0', '#cite_ref-tt_78-1', 'https://www.trendingtopics.eu/deepseek-this-is-what-live-censorship-looks-like-in-the-chinese-ai-chatbot/', '#cite_ref-Lu_2025_79-0', '#cite_ref-Lu_2025_79-1', 'https://www.theguardian.com/technology/2025/jan/28/we-tried-out-deepseek-it-works-well-until-we-asked-it-about-tiananmen-square-and-taiwan', '/wiki/The_Guardian', '/wiki/ISSN_(identifier)', 'https://search.worldcat.org/issn/0261-3077', '#cite_ref-:14_80-0', 'https://www.theguardian.com/commentisfree/2025/jan/26/the-guardian-view-on-a-global-ai-race-geopolitics-innovation-and-the-rise-of-chaos', '/wiki/The_Guardian', '/wiki/ISSN_(identifier)', 'https://search.worldcat.org/issn/0261-3077', '#cite_ref-81', 'https://www.nbcnews.com/tech/tech-news/china-ai-assistant-deepseek-rcna189385', '/wiki/NBC_News', '#cite_ref-82', 'https://www.biometricupdate.com/202501/chinas-deepseek-ai-poses-formidable-cyber-data-privacy-threats', '#cite_ref-83', 'https://www.theguardian.com/technology/2025/jan/28/experts-urge-caution-over-use-of-chinese-ai-deepseek', '/wiki/The_Guardian', '/wiki/ISSN_(identifier)', 'https://search.worldcat.org/issn/0261-3077', '#cite_ref-84', 'https://www.laptopmag.com/ai/deepseeks-success-has-painted-a-huge-tiktok-shaped-target-on-its-back', '/wiki/LaptopMag', '#cite_ref-85', 'https://www.wired.com/story/deepseek-ai-china-privacy-data/', '/wiki/Wired_(magazine)', '/wiki/ISSN_(identifier)', 'https://search.worldcat.org/issn/1059-1028', '#cite_ref-86', 'https://www.reuters.com/technology/artificial-intelligence/italy-regulator-seeks-info-deepseek-data-protection-2025-01-28/', '/wiki/Reuters', '#cite_ref-87', 'https://www.reuters.com/technology/artificial-intelligence/white-house-evaluates-china-ai-app-deepseeks-affect-national-security-official-2025-01-28/', '/wiki/Reuters', '#cite_ref-:15_88-0', '#cite_ref-:15_88-1', 'https://www.reuters.com/technology/artificial-intelligence/taiwan-says-government-departments-should-not-use-deepseek-citing-security-2025-01-31/', '/wiki/Reuters', '#cite_ref-89', 'https://www.reuters.com/technology/artificial-intelligence/dutch-privacy-watchdog-launch-investigation-into-chinas-deepseek-ai-2025-01-31/', '/wiki/Reuters', '#cite_ref-90', 'https://apnews.com/article/texas-deepseek-apps-ban-3828a4743e9919398dfac0ba9d4a5c25', '/wiki/Associated_Press', '/w/index.php?title=DeepSeek&action=edit&section=15', '/wiki/File:Commons-logo.svg', 'https://commons.wikimedia.org/wiki/Category:DeepSeek', 'https://deepseek.com', 'https://www.wikidata.org/wiki/Q131577453#P856', 'https://github.com/deepseek-ai', '/wiki/GitHub', 'https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210', '/wiki/Hugging_Face', 'https://api-docs.deepseek.com/', 'https://huggingface.co/collections/Presidentlin/deepseek-papers-674c536aa6acddd9bc98c2ac', '/wiki/Template:Generative_AI_chatbots', '/wiki/Template_talk:Generative_AI_chatbots', '/wiki/Special:EditPage/Template:Generative_AI_chatbots', '/wiki/Generative_AI', '/wiki/Chatbot', '/wiki/ChatGPT', '/wiki/Claude_(language_model)', '/wiki/Microsoft_Copilot', '/wiki/Gemini_(chatbot)', '/wiki/Grok_(chatbot)', '/wiki/Poe_(chatbot)', '/wiki/Replika', '/wiki/You.com', '/wiki/YandexGPT', '/wiki/Qwen', '/wiki/Mistral_AI', '/wiki/Galaxy_AI', '/wiki/Bard_(chatbot)', '/wiki/Large_language_models', '/wiki/Category:Chatbots', '/wiki/Template:Generative_AI', '/wiki/Template_talk:Generative_AI', '/wiki/Special:EditPage/Template:Generative_AI', '/wiki/Generative_artificial_intelligence', '/wiki/Autoencoder', '/wiki/Deep_learning', '/wiki/Generative_adversarial_network', '/wiki/Generative_pre-trained_transformer', '/wiki/Large_language_model', '/wiki/Neural_network_(machine_learning)', '/wiki/Prompt_engineering', '/wiki/Retrieval-augmented_generation', '/wiki/Reinforcement_learning_from_human_feedback', '/wiki/Self-supervised_learning', '/wiki/Transformer_(deep_learning_architecture)', '/wiki/Variational_autoencoder', '/wiki/Vision_transformer', '/wiki/Word_embedding', '/wiki/Claude_(language_model)', '/wiki/DBRX', '/wiki/Gemini_(chatbot)', '/wiki/Generative_pre-trained_transformer', '/wiki/GPT-1', '/wiki/GPT-2', '/wiki/GPT-3', '/wiki/GPT-J', '/wiki/ChatGPT', '/wiki/GPT-4', '/wiki/GPT-4o', '/wiki/OpenAI_o1', '/wiki/OpenAI_o3', '/wiki/Grok_(chatbot)', '/wiki/IBM_Granite', '/wiki/Llama_(language_model)', '/wiki/Mistral_AI#Mistral_Large', '/wiki/Huawei_PanGu', '/wiki/Qwen', '/wiki/Text-to-image_model', '/wiki/Aurora_(text-to-image_model)', '/wiki/DALL-E', '/wiki/Adobe_Firefly', '/wiki/Flux_(text-to-image_model)', '/wiki/Ideogram_(text-to-image_model)', '/wiki/Midjourney', '/wiki/Stable_Diffusion', '/wiki/Text-to-video_model', '/wiki/Dream_Machine_(text-to-video_model)', '/wiki/Runway_(company)#Gen-3_Alpha', '/wiki/MiniMax_(company)#Hailuo_AI', '/wiki/Kling_(text-to-video_model)', '/wiki/Sora_(text-to-video_model)', '/wiki/Google_DeepMind#Video_model', '/wiki/VideoPoet', '/wiki/Udio', '/wiki/Suno_AI', '/wiki/List_of_artificial_intelligence_companies', '/wiki/01.AI', '/wiki/Alibaba_Group', '/wiki/Anthropic', '/wiki/Baichuan', '/wiki/ElevenLabs', '/wiki/Google_DeepMind', '/wiki/Hugging_Face', '/wiki/Kuaishou', '/wiki/Meta_AI', '/wiki/MiniMax_(company)', '/wiki/Mistral_AI', '/wiki/Moonshot_AI', '/wiki/OpenAI', '/wiki/Runway_(company)', '/wiki/Stability_AI', '/wiki/Synthesia_(company)', '/wiki/XAI_(company)', '/wiki/Zhipu_AI', '/wiki/Category:Generative_artificial_intelligence', 'https://commons.wikimedia.org/wiki/Category:Generative_artificial_intelligence', '/wiki/Help:Authority_control', 'https://www.wikidata.org/wiki/Q131577453#identifiers', 'https://d-nb.info/gnd/1355055415', 'https://en.wikipedia.org/w/index.php?title=DeepSeek&oldid=1273433515', '/wiki/Help:Category', '/wiki/Category:2023_establishments_in_China', '/wiki/Category:Artificial_intelligence_companies', '/wiki/Category:Artificial_intelligence_laboratories', '/wiki/Category:Companies_based_in_Hangzhou', '/wiki/Category:Technology_companies_established_in_2023', '/wiki/Category:CS1_maint:_url-status', '/wiki/Category:Articles_with_short_description', '/wiki/Category:Short_description_matches_Wikidata', '/wiki/Category:Use_dmy_dates_from_February_2025', '/wiki/Category:Articles_containing_Chinese-language_text', '/wiki/Category:Articles_containing_simplified_Chinese-language_text', '/wiki/Category:Wikipedia_articles_that_are_too_technical_from_January_2025', '/wiki/Category:All_articles_that_are_too_technical', '/wiki/Category:Commons_category_link_from_Wikidata', '/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License', 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use', 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy', 'https://wikimediafoundation.org/', 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy', '/wiki/Wikipedia:About', '/wiki/Wikipedia:General_disclaimer', '//en.wikipedia.org/wiki/Wikipedia:Contact_us', 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct', 'https://developer.wikimedia.org', 'https://stats.wikimedia.org/#/en.wikipedia.org', 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement', '//en.m.wikipedia.org/w/index.php?title=DeepSeek&mobileaction=toggle_view_mobile', 'https://wikimediafoundation.org/', 'https://www.mediawiki.org/', '#', '#', '#', '#', '#', '#', '#', '#']\n"
     ]
    }
   ],
   "source": [
    "print(web.links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Step : Have GPT-4o-mini figure out which links are relevant\n",
    "\n",
    "- Use a call to gpt-4o-mini to read the links on a webpage and respond in structured json\n",
    "- It should decide which links are relevant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \" You are provided with a list of links found on a webpage. \\\n",
    "    You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "    such as links to an About page, or a Company page, or Careers/Job pages. \\n\"\n",
    "\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt +=  \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You are provided with a list of links found on a webpage.     You are able to decide which of the links would be most relevant to include in a brochure about the company,     such as links to an About page, or a Company page, or Careers/Job pages. \n",
      "You should respond in JSON as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "                    Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links are : ) \\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://en.wikipedia.org/wiki/DeepSeek - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format.                     Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links are : ) \n",
      "#bodyContent\n",
      "/wiki/Main_Page\n",
      "/wiki/Wikipedia:Contents\n",
      "/wiki/Portal:Current_events\n",
      "/wiki/Special:Random\n",
      "/wiki/Wikipedia:About\n",
      "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "/wiki/Help:Contents\n",
      "/wiki/Help:Introduction\n",
      "/wiki/Wikipedia:Community_portal\n",
      "/wiki/Special:RecentChanges\n",
      "/wiki/Wikipedia:File_upload_wizard\n",
      "/wiki/Main_Page\n",
      "/wiki/Special:Search\n",
      "https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en\n",
      "/w/index.php?title=Special:CreateAccount&returnto=DeepSeek\n",
      "/w/index.php?title=Special:UserLogin&returnto=DeepSeek\n",
      "https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en\n",
      "/w/index.php?title=Special:CreateAccount&returnto=DeepSeek\n",
      "/w/index.php?title=Special:UserLogin&returnto=DeepSeek\n",
      "/wiki/Help:Introduction\n",
      "/wiki/Special:MyContributions\n",
      "/wiki/Special:MyTalk\n",
      "#\n",
      "#Background\n",
      "#Development_and_release_history\n",
      "#DeepSeek_Coder\n",
      "#DeepSeek_LLM\n",
      "#V2\n",
      "#V3\n",
      "#R1\n",
      "#Assessment_and_reactions\n",
      "#Concerns\n",
      "#Censorship\n",
      "#Security_and_privacy\n",
      "#See_also\n",
      "#Notes\n",
      "#References\n",
      "#External_links\n",
      "https://af.wikipedia.org/wiki/DeepSeek\n",
      "https://ar.wikipedia.org/wiki/%D8%AF%D9%8A%D8%A8_%D8%B3%D9%8A%D9%83\n",
      "https://an.wikipedia.org/wiki/DeepSeek\n",
      "https://as.wikipedia.org/wiki/%E0%A6%A1%E0%A7%80%E0%A6%AA%E0%A6%9B%E0%A7%80%E0%A6%95\n",
      "https://az.wikipedia.org/wiki/DeepSeek\n",
      "https://bn.wikipedia.org/wiki/%E0%A6%A1%E0%A6%BF%E0%A6%AA%E0%A6%B8%E0%A6%BF%E0%A6%95\n",
      "https://bg.wikipedia.org/wiki/DeepSeek\n",
      "https://ca.wikipedia.org/wiki/DeepSeek\n",
      "https://cs.wikipedia.org/wiki/DeepSeek\n",
      "https://da.wikipedia.org/wiki/DeepSeek\n",
      "https://ary.wikipedia.org/wiki/%D8%AF%D9%8A%D9%BE_%D8%B3%D9%8A%D9%83\n",
      "https://de.wikipedia.org/wiki/DeepSeek\n",
      "https://el.wikipedia.org/wiki/DeepSeek\n",
      "https://es.wikipedia.org/wiki/DeepSeek\n",
      "https://eo.wikipedia.org/wiki/DeepSeek\n",
      "https://eu.wikipedia.org/wiki/DeepSeek\n",
      "https://fa.wikipedia.org/wiki/%D8%AF%DB%8C%D9%BE%E2%80%8C%D8%B3%DB%8C%DA%A9\n",
      "https://fr.wikipedia.org/wiki/DeepSeek\n",
      "https://fy.wikipedia.org/wiki/DeepSeek\n",
      "https://ff.wikipedia.org/wiki/DeepSeek\n",
      "https://ga.wikipedia.org/wiki/DeepSeek\n",
      "https://gl.wikipedia.org/wiki/DeepSeek\n",
      "https://ko.wikipedia.org/wiki/%EB%94%A5%EC%8B%9C%ED%81%AC\n",
      "https://io.wikipedia.org/wiki/DeepSeek\n",
      "https://id.wikipedia.org/wiki/DeepSeek\n",
      "https://it.wikipedia.org/wiki/DeepSeek\n",
      "https://he.wikipedia.org/wiki/DeepSeek\n",
      "https://sw.wikipedia.org/wiki/DeepSeek\n",
      "https://lv.wikipedia.org/wiki/DeepSeek\n",
      "https://hu.wikipedia.org/wiki/DeepSeek\n",
      "https://mk.wikipedia.org/wiki/DeepSeek\n",
      "https://ml.wikipedia.org/wiki/%E0%B4%A1%E0%B5%80%E0%B4%AA%E0%B5%8D%E0%B4%B8%E0%B5%80%E0%B4%95%E0%B5%8D%E0%B4%95%E0%B5%8D\n",
      "https://nl.wikipedia.org/wiki/DeepSeek\n",
      "https://ne.wikipedia.org/wiki/%E0%A4%A1%E0%A4%BF%E0%A4%AA%E0%A4%B8%E0%A4%BF%E0%A4%95\n",
      "https://ja.wikipedia.org/wiki/DeepSeek\n",
      "https://uz.wikipedia.org/wiki/DeepSeek\n",
      "https://pl.wikipedia.org/wiki/DeepSeek\n",
      "https://pt.wikipedia.org/wiki/DeepSeek\n",
      "https://kaa.wikipedia.org/wiki/DeepSeek\n",
      "https://ro.wikipedia.org/wiki/DeepSeek\n",
      "https://ru.wikipedia.org/wiki/DeepSeek\n",
      "https://simple.wikipedia.org/wiki/DeepSeek\n",
      "https://sl.wikipedia.org/wiki/DeepSeek\n",
      "https://sr.wikipedia.org/wiki/DeepSeek\n",
      "https://fi.wikipedia.org/wiki/Deepseek\n",
      "https://sv.wikipedia.org/wiki/Deepseek\n",
      "https://tl.wikipedia.org/wiki/DeepSeek\n",
      "https://ta.wikipedia.org/wiki/%E0%AE%9F%E0%AF%80%E0%AE%AA%E0%AF%8D%E0%AE%9A%E0%AF%80%E0%AE%95%E0%AF%8D\n",
      "https://shn.wikipedia.org/wiki/%E1%80%90%E1%80%AD%E1%80%95%E1%80%BA%E1%82%89%E1%80%9E%E1%80%AD%E1%81%B5%E1%80%BA%E1%82%89%E1%81%B6%E1%80%BA\n",
      "https://th.wikipedia.org/wiki/%E0%B8%94%E0%B8%B5%E0%B8%9B%E0%B8%8B%E0%B8%B5%E0%B8%81\n",
      "https://tr.wikipedia.org/wiki/DeepSeek\n",
      "https://uk.wikipedia.org/wiki/DeepSeek\n",
      "https://ur.wikipedia.org/wiki/%DA%88%DB%8C%D9%BE_%D8%B3%DB%8C%DA%A9\n",
      "https://ug.wikipedia.org/wiki/%DA%86%D9%88%DA%AD%D9%82%DB%87%D8%B1_%D9%82%DB%90%D8%AF%D9%89%D8%B1_(%D8%B3%DB%88%D9%86%D8%A6%D9%89%D9%8A_%D8%A6%DB%95%D9%82%D9%89%D9%84)\n",
      "https://vi.wikipedia.org/wiki/DeepSeek\n",
      "https://wuu.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2\n",
      "https://zh-yue.wikipedia.org/wiki/DeepSeek\n",
      "https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2\n",
      "https://www.wikidata.org/wiki/Special:EntityPage/Q131577453#sitelinks-wikipedia\n",
      "/wiki/DeepSeek\n",
      "/wiki/Talk:DeepSeek\n",
      "/wiki/DeepSeek\n",
      "/w/index.php?title=DeepSeek&action=edit\n",
      "/w/index.php?title=DeepSeek&action=history\n",
      "/wiki/DeepSeek\n",
      "/w/index.php?title=DeepSeek&action=edit\n",
      "/w/index.php?title=DeepSeek&action=history\n",
      "/wiki/Special:WhatLinksHere/DeepSeek\n",
      "/wiki/Special:RecentChangesLinked/DeepSeek\n",
      "//en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard\n",
      "/wiki/Special:SpecialPages\n",
      "/w/index.php?title=DeepSeek&oldid=1273433515\n",
      "/w/index.php?title=DeepSeek&action=info\n",
      "/w/index.php?title=Special:CiteThisPage&page=DeepSeek&id=1273433515&wpFormIdentifier=titleform\n",
      "/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDeepSeek\n",
      "/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDeepSeek\n",
      "/w/index.php?title=Special:DownloadAsPdf&page=DeepSeek&action=show-download-screen\n",
      "/w/index.php?title=DeepSeek&printable=yes\n",
      "https://commons.wikimedia.org/wiki/Category:DeepSeek\n",
      "https://www.wikidata.org/wiki/Special:EntityPage/Q131577453\n",
      "/wiki/File:DeepSeek_logo.svg\n",
      "/wiki/Information_technology\n",
      "/wiki/Artificial_intelligence\n",
      "/wiki/Liang_Wenfeng\n",
      "/wiki/Hangzhou\n",
      "/wiki/High-Flyer\n",
      "https://deepseek.com\n",
      "https://www.wikidata.org/wiki/Q131577453#P856\n",
      "#cite_note-2\n",
      "/wiki/Simplified_Chinese_characters\n",
      "/wiki/Pinyin\n",
      "/wiki/Artificial_intelligence\n",
      "/wiki/Open-source\n",
      "/wiki/Large_language_models\n",
      "/wiki/Hangzhou,_Zhejiang\n",
      "/wiki/High-Flyer\n",
      "/wiki/Liang_Wenfeng\n",
      "/wiki/Large_language_model\n",
      "/wiki/OpenAI\n",
      "/wiki/GPT-4o\n",
      "/wiki/OpenAI_o1\n",
      "#cite_note-3\n",
      "/wiki/Training,_validation,_and_test_data_sets\n",
      "/wiki/GPT-4\n",
      "#cite_note-vincent-4\n",
      "#cite_note-vincent-4\n",
      "#cite_note-:8-5\n",
      "#cite_note-6\n",
      "/wiki/Nvidia\n",
      "#cite_note-7\n",
      "#cite_note-8\n",
      "/wiki/Chatbot\n",
      "/wiki/IOS\n",
      "/wiki/Android_(operating_system)\n",
      "/wiki/ChatGPT\n",
      "/wiki/App_Store_(Apple)\n",
      "#cite_note-auto-9\n",
      "#cite_note-10\n",
      "#cite_note-11\n",
      "#cite_note-auto-9\n",
      "#cite_note-12\n",
      "https://en.wiktionary.org/wiki/brinkmanship\n",
      "#cite_note-13\n",
      "/wiki/Generative_artificial_intelligence\n",
      "#cite_note-auto1-14\n",
      "#cite_note-auto-9\n",
      "/wiki/Computer_science\n",
      "#cite_note-:8-5\n",
      "/w/index.php?title=DeepSeek&action=edit&section=1\n",
      "/wiki/2007%E2%80%932008_financial_crisis\n",
      "/wiki/Zhejiang_University\n",
      "#cite_note-:6-15\n",
      "#cite_note-:0-16\n",
      "#cite_note-FT_2025-17\n",
      "/wiki/Generative_artificial_intelligence\n",
      "/wiki/Chatbot\n",
      "/wiki/Open_source\n",
      "#cite_note-auto1-14\n",
      "#cite_note-FT_2025-17\n",
      "/wiki/36Kr\n",
      "/wiki/Ampere_(microarchitecture)#A100_accelerator_and_DGX_A100\n",
      "#cite_note-CNBC_2023-18\n",
      "#cite_note-:0-16\n",
      "/wiki/Artificial_general_intelligence\n",
      "#cite_note-19\n",
      "#cite_note-scmp_1_January_2025-20\n",
      "#cite_note-21\n",
      "#cite_note-:0-16\n",
      "#cite_note-:2-22\n",
      "#cite_note-scmp_1_January_2025-20\n",
      "/wiki/Venture_capital\n",
      "/wiki/Exit_(investing)\n",
      "#cite_note-:0-16\n",
      "/wiki/Price_war\n",
      "/wiki/Pinduoduo\n",
      "/wiki/ByteDance\n",
      "/wiki/Tencent\n",
      "/wiki/Baidu\n",
      "/wiki/Alibaba_Group\n",
      "#cite_note-:3-23\n",
      "#cite_note-:3-23\n",
      "#cite_note-:8-5\n",
      "#cite_note-scmp_1_January_2025-20\n",
      "#cite_note-:8-5\n",
      "/wiki/Gaokao\n",
      "#cite_note-:8-5\n",
      "/w/index.php?title=DeepSeek&action=edit&section=2\n",
      "https://en.wikipedia.org/w/index.php?title=DeepSeek&action=edit\n",
      "/wiki/Wikipedia:Make_technical_articles_understandable\n",
      "/wiki/Help:Maintenance_template_removal\n",
      "/w/index.php?title=DeepSeek&action=edit&section=3\n",
      "/wiki/MIT_License\n",
      "#cite_note-24\n",
      "/wiki/Training,_validation,_and_test_data_sets\n",
      "#cite_note-:1-25\n",
      "#cite_note-26\n",
      "#cite_note-27\n",
      "/wiki/Stack_Exchange\n",
      "/wiki/Fine-tuning_(deep_learning)\n",
      "/wiki/Hopper_(microarchitecture)\n",
      "/wiki/InfiniBand\n",
      "/wiki/NVLink\n",
      "/wiki/NVSwitch\n",
      "#cite_note-:1-25\n",
      "#cite_note-:1-25\n",
      "#cite_note-28\n",
      "#cite_note-fn1-29\n",
      "#cite_note-fn1-29\n",
      "/w/index.php?title=DeepSeek&action=edit&section=4\n",
      "/wiki/Chatbot\n",
      "#cite_note-:9-30\n",
      "#cite_note-31\n",
      "/wiki/Llama_(language_model)\n",
      "/wiki/Transformer_(deep_learning_architecture)#pre-LN\n",
      "/wiki/Transformer_(deep_learning_architecture)#decoder-only\n",
      "/wiki/RMSNorm\n",
      "/wiki/SwiGLU\n",
      "/wiki/Rotary_positional_embedding\n",
      "/wiki/Grouped-query_attention\n",
      "/wiki/Byte_pair_encoding#Byte-level_BPE\n",
      "/wiki/Common_Crawl\n",
      "#cite_note-:9-30\n",
      "#cite_note-:9-30\n",
      "#cite_note-fn1-29\n",
      "/wiki/Reinforcement_learning_from_human_feedback\n",
      "#cite_note-:9-30\n",
      "/wiki/Mixture_of_experts#Sparsely-gated_MoE_layer\n",
      "#cite_note-:12-32\n",
      "#cite_note-33\n",
      "/wiki/Reinforcement_learning\n",
      "/wiki/Reasoning_language_model#PRM\n",
      "#cite_note-34\n",
      "/wiki/Group_Relative_Policy_Optimization\n",
      "/w/index.php?title=DeepSeek&action=edit&section=5\n",
      "/wiki/File:DeepSeek_MoE_and_MLA_(DeepSeek-V2).svg\n",
      "#cite_note-:7-35\n",
      "#cite_note-:7-35\n",
      "#cite_note-:10-36\n",
      "#cite_note-:7-35\n",
      "#cite_note-:7-35\n",
      "/wiki/Low-rank_approximation\n",
      "/wiki/Transformer_(deep_learning_architecture)#MLA\n",
      "/wiki/Mixture_of_experts\n",
      "#cite_note-:12-32\n",
      "#cite_note-:7-35\n",
      "#cite_note-37\n",
      "#cite_note-38\n",
      "/wiki/Financial_Times\n",
      "/wiki/Renminbi\n",
      "/wiki/University_of_Waterloo\n",
      "#cite_note-:2-22\n",
      "#cite_note-39\n",
      "#cite_note-40\n",
      "#cite_note-41\n",
      "/w/index.php?title=DeepSeek&action=edit&section=6\n",
      "/wiki/File:Multi-Token_Prediction_(DeepSeek)_01.svg\n",
      "/wiki/Transformer_(deep_learning_architecture)#Multi-Token_Prediction\n",
      "#cite_note-:5-42\n",
      "#cite_note-:10-36\n",
      "#cite_note-:5-42\n",
      "#cite_note-43\n",
      "/wiki/File:Mixed-precision_training_in_DeepSeek_V3.svg\n",
      "#cite_note-:5-42\n",
      "/wiki/Mixed-precision_arithmetic\n",
      "/wiki/Floating-point_arithmetic\n",
      "/wiki/Mantissa_(floating_point_number)\n",
      "/wiki/Single-precision_floating-point_format\n",
      "/wiki/General_matrix_multiply\n",
      "/wiki/Bfloat16_floating-point_format\n",
      "#cite_note-:5-42\n",
      "#cite_note-:5-42\n",
      "#cite_note-:5-42\n",
      "/wiki/Llama_(language_model)\n",
      "/wiki/Qwen\n",
      "/wiki/GPT-4o\n",
      "/wiki/Claude_(language_model)\n",
      "#cite_note-scmp_1_January_2025-20\n",
      "#cite_note-44\n",
      "#cite_note-45\n",
      "#cite_note-46\n",
      "/w/index.php?title=DeepSeek&action=edit&section=7\n",
      "#cite_note-DSLI_1-47\n",
      "#cite_note-48\n",
      "#cite_note-49\n",
      "/wiki/OpenAI_o1\n",
      "/wiki/American_Invitational_Mathematics_Examination\n",
      "#cite_note-50\n",
      "/wiki/The_Wall_Street_Journal\n",
      "#cite_note-51\n",
      "#cite_note-52\n",
      "/wiki/Llama_(language_model)\n",
      "/wiki/Qwen\n",
      "/wiki/Synthetic_data\n",
      "#cite_note-:4-53\n",
      "#cite_note-:4-53\n",
      "#cite_note-:4-53\n",
      "#cite_note-:4-53\n",
      "/w/index.php?title=DeepSeek&action=edit&section=8\n",
      "/wiki/Virtual_assistant\n",
      "/wiki/Chatbot\n",
      "/wiki/Apple_IOS\n",
      "/wiki/Android_(operating_system)\n",
      "#cite_note-:8-5\n",
      "/wiki/Supercomputer\n",
      "/wiki/Graphics_processing_unit\n",
      "/wiki/Nvidia\n",
      "#cite_note-:5-42\n",
      "#cite_note-:5-42\n",
      "/wiki/Meta_Platforms\n",
      "#cite_note-:8-5\n",
      "#cite_note-54\n",
      "/wiki/The_Hill_(newspaper)\n",
      "/wiki/The_Guardian\n",
      "/wiki/Sputnik_moment\n",
      "#cite_note-55\n",
      "#cite_note-:11-56\n",
      "#cite_note-Hoskins_RJ-57\n",
      "/wiki/Marc_Andreessen\n",
      "#cite_note-Hoskins_RJ-57\n",
      "/wiki/Sam_Altman\n",
      "/wiki/CNN\n",
      "#cite_note-58\n",
      "/wiki/State_media\n",
      "#cite_note-59\n",
      "#cite_note-60\n",
      "/wiki/Li_Qiang\n",
      "#cite_note-61\n",
      "#cite_note-scmp_1_January_2025-20\n",
      "#cite_note-62\n",
      "#cite_note-63\n",
      "#cite_note-64\n",
      "/wiki/Broadcom\n",
      "/wiki/Microsoft\n",
      "/wiki/Google\n",
      "/wiki/Alphabet_Inc.\n",
      "/wiki/ASML_Holding\n",
      "#cite_note-Hoskins_RJ-57\n",
      "/wiki/Nasdaq\n",
      "#cite_note-65\n",
      "#cite_note-:11-56\n",
      "/wiki/File:Deepseek_login_error.png\n",
      "#cite_note-DSCI_1-66\n",
      "/wiki/Satya_Nadella\n",
      "/wiki/Stargate_LLC\n",
      "#cite_note-67\n",
      "#cite_note-68\n",
      "/wiki/Donald_Trump\n",
      "#cite_note-69\n",
      "#cite_note-70\n",
      "#cite_note-:11-56\n",
      "#cite_note-Hoskins_RJ-57\n",
      "#cite_note-71\n",
      "/wiki/Scale_AI\n",
      "/wiki/Alexandr_Wang\n",
      "/wiki/Anthropic\n",
      "/wiki/Dario_Amodei\n",
      "/wiki/Elon_Musk\n",
      "#cite_note-DSCI_1-66\n",
      "#cite_note-72\n",
      "#cite_note-73\n",
      "/wiki/Amazon_Web_Services\n",
      "/wiki/Toyota\n",
      "/wiki/Stripe,_Inc.\n",
      "#cite_note-74\n",
      "/wiki/Cyberattack\n",
      "#cite_note-Guardian-75\n",
      "#cite_note-76\n",
      "/w/index.php?title=DeepSeek&action=edit&section=9\n",
      "/w/index.php?title=DeepSeek&action=edit&section=10\n",
      "/wiki/File:DeepSeek_when_asked_about_Xi_Jinping_and_Narendra_Modi.png\n",
      "/wiki/Xi_Jinping\n",
      "/wiki/Narendra_Modi\n",
      "/wiki/Government_of_China\n",
      "/wiki/1989_Tiananmen_Square_massacre\n",
      "/wiki/Persecution_of_Uyghurs_in_China\n",
      "/wiki/Censorship_of_Winnie-the-Pooh_in_China\n",
      "/wiki/Human_rights_in_China\n",
      "#cite_note-:13-77\n",
      "#cite_note-tt-78\n",
      "#cite_note-Lu_2025-79\n",
      "#cite_note-tt-78\n",
      "/wiki/Core_Socialist_Values\n",
      "/wiki/Cyberspace_Administration_of_China\n",
      "/wiki/Political_status_of_Taiwan\n",
      "#cite_note-:14-80\n",
      "/wiki/NBC_News\n",
      "/wiki/Taiwan_independence\n",
      "#cite_note-81\n",
      "/wiki/Leet\n",
      "#cite_note-Lu_2025-79\n",
      "/w/index.php?title=DeepSeek&action=edit&section=11\n",
      "/wiki/Chinese_information_operations_and_information_warfare\n",
      "/wiki/Influence_operations\n",
      "/wiki/Disinformation\n",
      "/wiki/Surveillance\n",
      "/wiki/Cyberweapon\n",
      "#cite_note-82\n",
      "#cite_note-83\n",
      "#cite_note-84\n",
      "/wiki/Wired_(magazine)\n",
      "/wiki/Baidu\n",
      "/wiki/ByteDance\n",
      "#cite_note-85\n",
      "/wiki/United_States_National_Security_Council\n",
      "#cite_note-86\n",
      "#cite_note-87\n",
      "/wiki/Personal_Information_Protection_Commission_(South_Korea)\n",
      "#cite_note-:15-88\n",
      "/wiki/Dutch_Data_Protection_Authority\n",
      "#cite_note-89\n",
      "#cite_note-:15-88\n",
      "/wiki/Greg_Abbott\n",
      "/wiki/Xiaohongshu\n",
      "/wiki/Lemon8\n",
      "#cite_note-90\n",
      "/w/index.php?title=DeepSeek&action=edit&section=12\n",
      "/wiki/Portal:Free_and_open-source_software\n",
      "/wiki/Artificial_intelligence_industry_in_China\n",
      "/w/index.php?title=DeepSeek&action=edit&section=13\n",
      "#cite_ref-2\n",
      "#cite_note-1\n",
      "#cite_ref-fn1_29-0\n",
      "#cite_ref-fn1_29-1\n",
      "#cite_ref-fn1_29-2\n",
      "#cite_ref-40\n",
      "#cite_ref-49\n",
      "/w/index.php?title=DeepSeek&action=edit&section=14\n",
      "#cite_ref-1\n",
      "https://www.bloomberg.com/profile/company/2544189D:CH\n",
      "/wiki/Bloomberg_L.P.\n",
      "#cite_ref-3\n",
      "https://www.nature.com/articles/d41586-025-00229-6\n",
      "/wiki/Nature_(journal)\n",
      "/wiki/Doi_(identifier)\n",
      "https://doi.org/10.1038%2Fd41586-025-00229-6\n",
      "/wiki/ISSN_(identifier)\n",
      "https://search.worldcat.org/issn/1476-4687\n",
      "/wiki/PMID_(identifier)\n",
      "https://pubmed.ncbi.nlm.nih.gov/39849139\n",
      "#cite_ref-vincent_4-0\n",
      "#cite_ref-vincent_4-1\n",
      "https://www.theguardian.com/commentisfree/2025/jan/28/deepseek-r1-ai-world-chinese-chatbot-tech-world-western\n",
      "/wiki/The_Guardian\n",
      "#cite_ref-:8_5-0\n",
      "#cite_ref-:8_5-1\n",
      "#cite_ref-:8_5-2\n",
      "#cite_ref-:8_5-3\n",
      "#cite_ref-:8_5-4\n",
      "#cite_ref-:8_5-5\n",
      "#cite_ref-:8_5-6\n",
      "https://www.nytimes.com/2025/01/23/technology/deepseek-china-ai-chips.html?smid=fb-nytimes&smtyp=cur&fbclid=IwY2xjawIEynFleHRuA2FlbQIxMQABHZYKXN7GJpUyNRsaGEDQVadxRBarp-aBp1GhiuRe3B57Ehe6HYv7oiK78Q_aem_KTeDgqjV_-R80owNNWOBCQ\n",
      "/wiki/The_New_York_Times\n",
      "/wiki/ISSN_(identifier)\n",
      "https://search.worldcat.org/issn/0362-4331\n",
      "#cite_ref-6\n",
      "https://www.businessinsider.com/explaining-deepseek-chinese-models-efficiency-scaring-markets-2025-1\n",
      "/wiki/Business_Insider\n",
      "#cite_ref-7\n",
      "https://www.computerweekly.com/news/366616907/Nvidia-investigation-signals-widening-of-US-and-China-chip-war\n",
      "/wiki/Computer_Weekly\n",
      "#cite_ref-8\n",
      "https://www.bbc.com/news/articles/cx2vkd90mk8o\n",
      "/wiki/BBC\n",
      "#cite_ref-auto_9-0\n",
      "#cite_ref-auto_9-1\n",
      "#cite_ref-auto_9-2\n",
      "https://www.nytimes.com/2025/01/27/technology/what-is-deepseek-china-ai.html\n",
      "/wiki/The_New_York_Times\n",
      "/wiki/ISSN_(identifier)\n",
      "https://search.worldcat.org/issn/0362-4331\n",
      "#cite_ref-10\n",
      "https://www.cnbc.com/2025/01/27/chinas-deepseek-ai-tops-chatgpt-app-store-what-you-should-know.html\n",
      "/wiki/CNBC\n",
      "#cite_ref-11\n",
      "https://www.cbsnews.com/news/what-is-deepseek-ai-china-stock-nvidia-nvda-asml/\n",
      "/wiki/CBS_News\n",
      "#cite_ref-12\n",
      "https://abcnews.go.com/Business/nvidia-microsoft-shares-tumble-china-based-ai-app/story?id=118136157\n",
      "/wiki/ABC_News_(United_States)\n",
      "#cite_ref-13\n",
      "https://www.nytimes.com/2025/01/28/technology/why-deepseek-could-change-what-silicon-valley-believes-about-ai.html\n",
      "/wiki/The_New_York_Times\n",
      "/wiki/ISSN_(identifier)\n",
      "https://search.worldcat.org/issn/0362-4331\n",
      "#cite_ref-auto1_14-0\n",
      "#cite_ref-auto1_14-1\n",
      "https://www.forbes.com/sites/luisromero/2025/01/27/chatgpt-deepseek-or-llama-metas-lecun-says-open-source-is-the-key/\n",
      "/wiki/Forbes\n",
      "#cite_ref-:6_15-0\n",
      "https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/\n",
      "/wiki/MIT_Technology_Review\n",
      "https://web.archive.org/web/20250125180427/https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/\n",
      "#cite_ref-:0_16-0\n",
      "#cite_ref-:0_16-1\n",
      "#cite_ref-:0_16-2\n",
      "#cite_ref-:0_16-3\n",
      "https://www.chinatalk.media/p/deepseek-from-hedge-fund-to-frontier\n",
      "https://web.archive.org/web/20241228030725/https://www.chinatalk.media/p/deepseek-from-hedge-fund-to-frontier\n",
      "#cite_ref-FT_2025_17-0\n",
      "#cite_ref-FT_2025_17-1\n",
      "https://www.removepaywall.com/search?url=https://www.ft.com/content/747a7b11-dcba-4aa5-8d25-403f56216d7e\n",
      "/wiki/Financial_Times\n",
      "#cite_ref-CNBC_2023_18-0\n",
      "https://www.cnbc.com/2023/02/23/nvidias-a100-is-the-10000-chip-powering-the-race-for-ai-.html\n",
      "/wiki/CNBC\n",
      "#cite_ref-19\n",
      "https://www.yicaiglobal.com/news/exclusive-chinese-quant-fund-high-flyer-will-not-use-agi-to-trade-stocks-managing-director-says\n",
      "https://web.archive.org/web/20231231030712/https://www.yicaiglobal.com/news/exclusive-chinese-quant-fund-high-flyer-will-not-use-agi-to-trade-stocks-managing-director-says\n",
      "#cite_ref-scmp_1_January_2025_20-0\n",
      "#cite_ref-scmp_1_January_2025_20-1\n",
      "#cite_ref-scmp_1_January_2025_20-2\n",
      "#cite_ref-scmp_1_January_2025_20-3\n",
      "#cite_ref-scmp_1_January_2025_20-4\n",
      "https://www.scmp.com/tech/tech-trends/article/3293050/meet-deepseek-chinese-start-changing-how-ai-models-are-trained\n",
      "/wiki/South_China_Morning_Post\n",
      "https://web.archive.org/web/20250122160046/https://www.scmp.com/tech/tech-trends/article/3293050/meet-deepseek-chinese-start-changing-how-ai-models-are-trained\n",
      "#cite_ref-21\n",
      "https://finance.sina.com.cn/jjxw/2025-02-01/doc-inehyqcx9694053.shtml\n",
      "/wiki/Sina_Corp\n",
      "#cite_ref-:2_22-0\n",
      "#cite_ref-:2_22-1\n",
      "https://www.ft.com/content/357f3c68-b866-4c2e-b678-0d075051a260\n",
      "/wiki/Financial_Times\n",
      "https://web.archive.org/web/20240717030903/https://www.ft.com/content/357f3c68-b866-4c2e-b678-0d075051a260\n",
      "#cite_ref-:3_23-0\n",
      "#cite_ref-:3_23-1\n",
      "https://www.chinatalk.media/p/deepseek-ceo-interview-with-chinas\n",
      "#cite_ref-24\n",
      "https://github.com/deepseek-ai/DeepSeek-Coder/blob/main/LICENSE-MODEL\n",
      "/wiki/GitHub\n",
      "https://web.archive.org/web/20250122195853/https://github.com/deepseek-ai/deepseek-coder/blob/main/LICENSE-MODEL\n",
      "#cite_ref-:1_25-0\n",
      "#cite_ref-:1_25-1\n",
      "#cite_ref-:1_25-2\n",
      "/wiki/ArXiv_(identifier)\n",
      "https://arxiv.org/abs/2401.14196\n",
      "#cite_ref-26\n",
      "https://deepseekcoder.github.io/\n",
      "#cite_ref-27\n",
      "https://github.com/deepseek-ai/deepseek-coder/\n",
      "#cite_ref-28\n",
      "https://huggingface.co/deepseek-ai/deepseek-coder-5.7bmqa-base\n",
      "/wiki/Hugging_Face\n",
      "#cite_ref-:9_30-0\n",
      "#cite_ref-:9_30-1\n",
      "#cite_ref-:9_30-2\n",
      "#cite_ref-:9_30-3\n",
      "/wiki/ArXiv_(identifier)\n",
      "https://arxiv.org/abs/2401.02954\n",
      "#cite_ref-31\n",
      "https://github.com/deepseek-ai/DeepSeek-LLM\n",
      "#cite_ref-:12_32-0\n",
      "#cite_ref-:12_32-1\n",
      "/wiki/ArXiv_(identifier)\n",
      "https://arxiv.org/abs/2401.06066\n",
      "#cite_ref-33\n",
      "/wiki/ArXiv_(identifier)\n",
      "https://arxiv.org/abs/2402.03300\n",
      "#cite_ref-34\n",
      "/wiki/ArXiv_(identifier)\n",
      "https://arxiv.org/abs/2312.08935\n",
      "#cite_ref-:7_35-0\n",
      "#cite_ref-:7_35-1\n",
      "#cite_ref-:7_35-2\n",
      "#cite_ref-:7_35-3\n",
      "#cite_ref-:7_35-4\n",
      "/wiki/ArXiv_(identifier)\n",
      "https://arxiv.org/abs/2405.04434\n",
      "#cite_ref-:10_36-0\n",
      "#cite_ref-:10_36-1\n",
      "/wiki/ArXiv_(identifier)\n",
      "https://arxiv.org/abs/2309.00071\n",
      "#cite_ref-37\n",
      "https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite/blob/main/config.json\n",
      "/wiki/Hugging_Face\n",
      "#cite_ref-38\n",
      "https://huggingface.co/deepseek-ai/DeepSeek-V2/blob/main/config.json\n",
      "/wiki/Hugging_Face\n",
      "#cite_ref-39\n",
      "/wiki/ArXiv_(identifier)\n",
      "https://arxiv.org/abs/2406.11931\n",
      "#cite_ref-41\n",
      "https://huggingface.co/deepseek-ai/DeepSeek-V2.5\n",
      "/wiki/Hugging_Face\n",
      "#cite_ref-:5_42-0\n",
      "#cite_ref-:5_42-1\n",
      "#cite_ref-:5_42-2\n",
      "#cite_ref-:5_42-3\n",
      "#cite_ref-:5_42-4\n",
      "#cite_ref-:5_42-5\n",
      "#cite_ref-:5_42-6\n",
      "#cite_ref-:5_42-7\n",
      "/wiki/ArXiv_(identifier)\n",
      "https://arxiv.org/abs/2412.19437\n",
      "#cite_ref-43\n",
      "https://huggingface.co/deepseek-ai/DeepSeek-V3/blob/main/config.json\n",
      "/wiki/Hugging_Face\n",
      "#cite_ref-44\n",
      "https://www.scmp.com/tech/tech-trends/article/3292507/chinese-start-deepseek-launches-ai-model-outperforms-meta-openai-products\n",
      "/wiki/South_China_Morning_Post\n",
      "https://web.archive.org/web/20241227191529/https://www.scmp.com/tech/tech-trends/article/3292507/chinese-start-deepseek-launches-ai-model-outperforms-meta-openai-products\n",
      "#cite_ref-45\n",
      "https://venturebeat.com/ai/deepseek-v3-ultra-large-open-source-ai-outperforms-llama-and-qwen-on-launch/\n",
      "/wiki/VentureBeat\n",
      "https://web.archive.org/web/20241227195503/https://venturebeat.com/ai/deepseek-v3-ultra-large-open-source-ai-outperforms-llama-and-qwen-on-launch/\n",
      "#cite_ref-46\n",
      "https://techcrunch.com/2024/12/26/deepseeks-new-ai-model-appears-to-be-one-of-the-best-open-challengers-yet/\n",
      "/wiki/TechCrunch\n",
      "https://web.archive.org/web/20250102103526/https://techcrunch.com/2024/12/26/deepseeks-new-ai-model-appears-to-be-one-of-the-best-open-challengers-yet/\n",
      "#cite_ref-DSLI_1_47-0\n",
      "https://chat.deepseek.com/sign_in\n",
      "#cite_ref-48\n",
      "https://web.archive.org/web/20241120141324/https://api-docs.deepseek.com/news/news1120\n",
      "https://api-docs.deepseek.com/news/news1120\n",
      "#cite_ref-50\n",
      "https://venturebeat.com/ai/deepseeks-first-reasoning-model-r1-lite-preview-turns-heads-beating-openai-o1-performance/\n",
      "/wiki/VentureBeat\n",
      "https://web.archive.org/web/20241122010413/https://venturebeat.com/ai/deepseeks-first-reasoning-model-r1-lite-preview-turns-heads-beating-openai-o1-performance/\n",
      "#cite_ref-51\n",
      "https://www.wsj.com/tech/ai/china-ai-advances-us-chips-7838fd20\n",
      "/wiki/The_Wall_Street_Journal\n",
      "https://web.archive.org/web/20241227183842/https://www.wsj.com/tech/ai/china-ai-advances-us-chips-7838fd20\n",
      "#cite_ref-52\n",
      "https://github.com/deepseek-ai/DeepSeek-R1/commit/23807ced51627276434655dd9f27725354818974\n",
      "/wiki/GitHub\n",
      "https://web.archive.org/web/20250121104009/https://github.com/deepseek-ai/DeepSeek-R1/commit/23807ced51627276434655dd9f27725354818974\n",
      "#cite_ref-:4_53-0\n",
      "#cite_ref-:4_53-1\n",
      "#cite_ref-:4_53-2\n",
      "#cite_ref-:4_53-3\n",
      "/wiki/ArXiv_(identifier)\n",
      "https://arxiv.org/abs/2501.12948\n",
      "#cite_ref-54\n",
      "https://www.reuters.com/technology/artificial-intelligence/chinese-ai-startup-deepseek-overtakes-chatgpt-apple-app-store-2025-01-27/\n",
      "/wiki/Reuters\n",
      "#cite_ref-55\n",
      "https://thehill.com/opinion/technology/5024271-ai-sputnik-moment-china-challenge/\n",
      "/wiki/The_Hill_(newspaper)\n",
      "https://web.archive.org/web/20241208215538/https://thehill.com/opinion/technology/5024271-ai-sputnik-moment-china-challenge/\n",
      "#cite_ref-:11_56-0\n",
      "#cite_ref-:11_56-1\n",
      "#cite_ref-:11_56-2\n",
      "https://www.theguardian.com/business/2025/jan/27/tech-shares-asia-europe-fall-china-ai-deepseek\n",
      "/wiki/The_Guardian\n",
      "#cite_ref-Hoskins_RJ_57-0\n",
      "#cite_ref-Hoskins_RJ_57-1\n",
      "#cite_ref-Hoskins_RJ_57-2\n",
      "#cite_ref-Hoskins_RJ_57-3\n",
      "https://www.bbc.com/news/articles/c0qw7z2v1pgo\n",
      "/wiki/BBC\n",
      "#cite_ref-58\n",
      "https://www.cnn.com/2025/01/27/tech/deepseek-ai-explainer/index.html\n",
      "/wiki/CNN\n",
      "#cite_ref-59\n",
      "https://www.economist.com/business/2025/01/29/deepseek-poses-a-challenge-to-beijing-as-much-as-to-silicon-valley\n",
      "/wiki/The_Economist\n",
      "/wiki/ISSN_(identifier)\n",
      "https://search.worldcat.org/issn/0013-0613\n",
      "#cite_ref-60\n",
      "https://www.reuters.com/technology/artificial-intelligence/chinese-state-linked-accounts-hyped-deepseek-ai-launch-ahead-us-stock-rout-2025-01-31/\n",
      "/wiki/Reuters\n",
      "#cite_ref-61\n",
      "https://finance.sina.com.cn/jjxw/2025-01-22/doc-inefuxsi7314244.shtml\n",
      "/wiki/Sina_Corp\n",
      "#cite_ref-62\n",
      "https://www.tomshardware.com/tech-industry/artificial-intelligence/chinese-ai-company-says-breakthroughs-enabled-creating-a-leading-edge-ai-model-with-11x-less-compute-deepseeks-optimizations-highlight-limits-of-us-sanctions\n",
      "/wiki/Tom%27s_Hardware\n",
      "https://web.archive.org/web/20241228014832/https://www.tomshardware.com/tech-industry/artificial-intelligence/chinese-ai-company-says-breakthroughs-enabled-creating-a-leading-edge-ai-model-with-11x-less-compute-deepseeks-optimizations-highlight-limits-of-us-sanctions\n",
      "#cite_ref-63\n",
      "https://www.bbc.co.uk/news/live/cjr85l2e4l4t\n",
      "/wiki/BBC_News\n",
      "/wiki/Template:Cite_web\n",
      "/wiki/Category:CS1_maint:_url-status\n",
      "#cite_ref-64\n",
      "https://www.bloomberg.com/news/articles/2025-01-26/asia-eyes-cautious-open-as-tariffs-remain-in-focus-markets-wrap\n",
      "/wiki/Bloomberg_L.P.\n",
      "#cite_ref-65\n",
      "https://www.reuters.com/technology/chinas-deepseek-sets-off-ai-market-rout-2025-01-27/\n",
      "/wiki/Reuters\n",
      "#cite_ref-DSCI_1_66-0\n",
      "#cite_ref-DSCI_1_66-1\n",
      "https://www.inc.com/ben-sherry/ai-leaders-in-the-u-s-react-to-deepseek-calling-it-impressive-but-staying-skeptical/91140125\n",
      "/wiki/Inc._(magazine)\n",
      "#cite_ref-67\n",
      "https://www.windowscentral.com/software-apps/microsoft-ceo-satya-nadella-touts-deepseeks-open-source-ai-as-super-impressive\n",
      "/wiki/Windows_Central\n",
      "#cite_ref-68\n",
      "https://thehill.com/policy/technology/5110258-openai-rival-deepseek-ai-model/\n",
      "/wiki/The_Hill_(newspaper)\n",
      "#cite_ref-69\n",
      "https://www.washingtonpost.com/business/2025/01/27/deep-seek-ai-markets-nvidia/\n",
      "/wiki/The_Washington_Post\n",
      "#cite_ref-70\n",
      "https://www.axios.com/2025/01/28/trump-mike-johnson-china-deepseek-ai\n",
      "/wiki/Axios_(website)\n",
      "#cite_ref-71\n",
      "https://www.nytimes.com/2025/01/27/business/us-stock-market-deepseek-ai-sp500-nvidia.html\n",
      "/wiki/New_York_Times\n",
      "#cite_ref-72\n",
      "https://www.fortuneindia.com/technology/musk-dismisses-sam-altman-applauds-heres-what-leaders-say-on-deepseeks-ai-disruption/120194\n",
      "/wiki/Fortune_India\n",
      "#cite_ref-73\n",
      "https://www.financialexpress.com/business/investing-abroad-deepseek-sparks-debate-did-it-build-cutting-edge-ai-for-6-million-3728638/\n",
      "/wiki/The_Financial_Express_(India)\n",
      "#cite_ref-74\n",
      "https://www.businessinsider.com/aws-deepseek-customer-cloud-access-bedrock-stripe-toyota-cisco-workday-2025-1\n",
      "/wiki/Business_Insider\n",
      "#cite_ref-Guardian_75-0\n",
      "https://www.theguardian.com/technology/2025/jan/27/deepseek-cyberattack-ai\n",
      "/wiki/The_Guardian\n",
      "#cite_ref-76\n",
      "https://www.businessinsider.com/deepseek-issues-account-registration-limited-china-phone-numbers-malicious-attack-2025-1\n",
      "/wiki/Business_Insider\n",
      "#cite_ref-:13_77-0\n",
      "https://www.telegraph.co.uk/business/2025/01/27/chinese-deepseek-ai-has-sparked-a-1-trillion-panic/\n",
      "/wiki/The_Daily_Telegraph\n",
      "/wiki/ISSN_(identifier)\n",
      "https://search.worldcat.org/issn/0307-1235\n",
      "#cite_ref-tt_78-0\n",
      "#cite_ref-tt_78-1\n",
      "https://www.trendingtopics.eu/deepseek-this-is-what-live-censorship-looks-like-in-the-chinese-ai-chatbot/\n",
      "#cite_ref-Lu_2025_79-0\n",
      "#cite_ref-Lu_2025_79-1\n",
      "https://www.theguardian.com/technology/2025/jan/28/we-tried-out-deepseek-it-works-well-until-we-asked-it-about-tiananmen-square-and-taiwan\n",
      "/wiki/The_Guardian\n",
      "/wiki/ISSN_(identifier)\n",
      "https://search.worldcat.org/issn/0261-3077\n",
      "#cite_ref-:14_80-0\n",
      "https://www.theguardian.com/commentisfree/2025/jan/26/the-guardian-view-on-a-global-ai-race-geopolitics-innovation-and-the-rise-of-chaos\n",
      "/wiki/The_Guardian\n",
      "/wiki/ISSN_(identifier)\n",
      "https://search.worldcat.org/issn/0261-3077\n",
      "#cite_ref-81\n",
      "https://www.nbcnews.com/tech/tech-news/china-ai-assistant-deepseek-rcna189385\n",
      "/wiki/NBC_News\n",
      "#cite_ref-82\n",
      "https://www.biometricupdate.com/202501/chinas-deepseek-ai-poses-formidable-cyber-data-privacy-threats\n",
      "#cite_ref-83\n",
      "https://www.theguardian.com/technology/2025/jan/28/experts-urge-caution-over-use-of-chinese-ai-deepseek\n",
      "/wiki/The_Guardian\n",
      "/wiki/ISSN_(identifier)\n",
      "https://search.worldcat.org/issn/0261-3077\n",
      "#cite_ref-84\n",
      "https://www.laptopmag.com/ai/deepseeks-success-has-painted-a-huge-tiktok-shaped-target-on-its-back\n",
      "/wiki/LaptopMag\n",
      "#cite_ref-85\n",
      "https://www.wired.com/story/deepseek-ai-china-privacy-data/\n",
      "/wiki/Wired_(magazine)\n",
      "/wiki/ISSN_(identifier)\n",
      "https://search.worldcat.org/issn/1059-1028\n",
      "#cite_ref-86\n",
      "https://www.reuters.com/technology/artificial-intelligence/italy-regulator-seeks-info-deepseek-data-protection-2025-01-28/\n",
      "/wiki/Reuters\n",
      "#cite_ref-87\n",
      "https://www.reuters.com/technology/artificial-intelligence/white-house-evaluates-china-ai-app-deepseeks-affect-national-security-official-2025-01-28/\n",
      "/wiki/Reuters\n",
      "#cite_ref-:15_88-0\n",
      "#cite_ref-:15_88-1\n",
      "https://www.reuters.com/technology/artificial-intelligence/taiwan-says-government-departments-should-not-use-deepseek-citing-security-2025-01-31/\n",
      "/wiki/Reuters\n",
      "#cite_ref-89\n",
      "https://www.reuters.com/technology/artificial-intelligence/dutch-privacy-watchdog-launch-investigation-into-chinas-deepseek-ai-2025-01-31/\n",
      "/wiki/Reuters\n",
      "#cite_ref-90\n",
      "https://apnews.com/article/texas-deepseek-apps-ban-3828a4743e9919398dfac0ba9d4a5c25\n",
      "/wiki/Associated_Press\n",
      "/w/index.php?title=DeepSeek&action=edit&section=15\n",
      "/wiki/File:Commons-logo.svg\n",
      "https://commons.wikimedia.org/wiki/Category:DeepSeek\n",
      "https://deepseek.com\n",
      "https://www.wikidata.org/wiki/Q131577453#P856\n",
      "https://github.com/deepseek-ai\n",
      "/wiki/GitHub\n",
      "https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210\n",
      "/wiki/Hugging_Face\n",
      "https://api-docs.deepseek.com/\n",
      "https://huggingface.co/collections/Presidentlin/deepseek-papers-674c536aa6acddd9bc98c2ac\n",
      "/wiki/Template:Generative_AI_chatbots\n",
      "/wiki/Template_talk:Generative_AI_chatbots\n",
      "/wiki/Special:EditPage/Template:Generative_AI_chatbots\n",
      "/wiki/Generative_AI\n",
      "/wiki/Chatbot\n",
      "/wiki/ChatGPT\n",
      "/wiki/Claude_(language_model)\n",
      "/wiki/Microsoft_Copilot\n",
      "/wiki/Gemini_(chatbot)\n",
      "/wiki/Grok_(chatbot)\n",
      "/wiki/Poe_(chatbot)\n",
      "/wiki/Replika\n",
      "/wiki/You.com\n",
      "/wiki/YandexGPT\n",
      "/wiki/Qwen\n",
      "/wiki/Mistral_AI\n",
      "/wiki/Galaxy_AI\n",
      "/wiki/Bard_(chatbot)\n",
      "/wiki/Large_language_models\n",
      "/wiki/Category:Chatbots\n",
      "/wiki/Template:Generative_AI\n",
      "/wiki/Template_talk:Generative_AI\n",
      "/wiki/Special:EditPage/Template:Generative_AI\n",
      "/wiki/Generative_artificial_intelligence\n",
      "/wiki/Autoencoder\n",
      "/wiki/Deep_learning\n",
      "/wiki/Generative_adversarial_network\n",
      "/wiki/Generative_pre-trained_transformer\n",
      "/wiki/Large_language_model\n",
      "/wiki/Neural_network_(machine_learning)\n",
      "/wiki/Prompt_engineering\n",
      "/wiki/Retrieval-augmented_generation\n",
      "/wiki/Reinforcement_learning_from_human_feedback\n",
      "/wiki/Self-supervised_learning\n",
      "/wiki/Transformer_(deep_learning_architecture)\n",
      "/wiki/Variational_autoencoder\n",
      "/wiki/Vision_transformer\n",
      "/wiki/Word_embedding\n",
      "/wiki/Claude_(language_model)\n",
      "/wiki/DBRX\n",
      "/wiki/Gemini_(chatbot)\n",
      "/wiki/Generative_pre-trained_transformer\n",
      "/wiki/GPT-1\n",
      "/wiki/GPT-2\n",
      "/wiki/GPT-3\n",
      "/wiki/GPT-J\n",
      "/wiki/ChatGPT\n",
      "/wiki/GPT-4\n",
      "/wiki/GPT-4o\n",
      "/wiki/OpenAI_o1\n",
      "/wiki/OpenAI_o3\n",
      "/wiki/Grok_(chatbot)\n",
      "/wiki/IBM_Granite\n",
      "/wiki/Llama_(language_model)\n",
      "/wiki/Mistral_AI#Mistral_Large\n",
      "/wiki/Huawei_PanGu\n",
      "/wiki/Qwen\n",
      "/wiki/Text-to-image_model\n",
      "/wiki/Aurora_(text-to-image_model)\n",
      "/wiki/DALL-E\n",
      "/wiki/Adobe_Firefly\n",
      "/wiki/Flux_(text-to-image_model)\n",
      "/wiki/Ideogram_(text-to-image_model)\n",
      "/wiki/Midjourney\n",
      "/wiki/Stable_Diffusion\n",
      "/wiki/Text-to-video_model\n",
      "/wiki/Dream_Machine_(text-to-video_model)\n",
      "/wiki/Runway_(company)#Gen-3_Alpha\n",
      "/wiki/MiniMax_(company)#Hailuo_AI\n",
      "/wiki/Kling_(text-to-video_model)\n",
      "/wiki/Sora_(text-to-video_model)\n",
      "/wiki/Google_DeepMind#Video_model\n",
      "/wiki/VideoPoet\n",
      "/wiki/Udio\n",
      "/wiki/Suno_AI\n",
      "/wiki/List_of_artificial_intelligence_companies\n",
      "/wiki/01.AI\n",
      "/wiki/Alibaba_Group\n",
      "/wiki/Anthropic\n",
      "/wiki/Baichuan\n",
      "/wiki/ElevenLabs\n",
      "/wiki/Google_DeepMind\n",
      "/wiki/Hugging_Face\n",
      "/wiki/Kuaishou\n",
      "/wiki/Meta_AI\n",
      "/wiki/MiniMax_(company)\n",
      "/wiki/Mistral_AI\n",
      "/wiki/Moonshot_AI\n",
      "/wiki/OpenAI\n",
      "/wiki/Runway_(company)\n",
      "/wiki/Stability_AI\n",
      "/wiki/Synthesia_(company)\n",
      "/wiki/XAI_(company)\n",
      "/wiki/Zhipu_AI\n",
      "/wiki/Category:Generative_artificial_intelligence\n",
      "https://commons.wikimedia.org/wiki/Category:Generative_artificial_intelligence\n",
      "/wiki/Help:Authority_control\n",
      "https://www.wikidata.org/wiki/Q131577453#identifiers\n",
      "https://d-nb.info/gnd/1355055415\n",
      "https://en.wikipedia.org/w/index.php?title=DeepSeek&oldid=1273433515\n",
      "/wiki/Help:Category\n",
      "/wiki/Category:2023_establishments_in_China\n",
      "/wiki/Category:Artificial_intelligence_companies\n",
      "/wiki/Category:Artificial_intelligence_laboratories\n",
      "/wiki/Category:Companies_based_in_Hangzhou\n",
      "/wiki/Category:Technology_companies_established_in_2023\n",
      "/wiki/Category:CS1_maint:_url-status\n",
      "/wiki/Category:Articles_with_short_description\n",
      "/wiki/Category:Short_description_matches_Wikidata\n",
      "/wiki/Category:Use_dmy_dates_from_February_2025\n",
      "/wiki/Category:Articles_containing_Chinese-language_text\n",
      "/wiki/Category:Articles_containing_simplified_Chinese-language_text\n",
      "/wiki/Category:Wikipedia_articles_that_are_too_technical_from_January_2025\n",
      "/wiki/Category:All_articles_that_are_too_technical\n",
      "/wiki/Category:Commons_category_link_from_Wikidata\n",
      "/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License\n",
      "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use\n",
      "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy\n",
      "https://wikimediafoundation.org/\n",
      "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy\n",
      "/wiki/Wikipedia:About\n",
      "/wiki/Wikipedia:General_disclaimer\n",
      "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct\n",
      "https://developer.wikimedia.org\n",
      "https://stats.wikimedia.org/#/en.wikipedia.org\n",
      "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement\n",
      "//en.m.wikipedia.org/w/index.php?title=DeepSeek&mobileaction=toggle_view_mobile\n",
      "https://wikimediafoundation.org/\n",
      "https://www.mediawiki.org/\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(web))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all of this into a function which calls LLM model\n",
    "# take response in json_format\n",
    "\n",
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "        ],\n",
    "        response_format= {\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://www.anthropic.com/company'},\n",
       "  {'type': 'careers page', 'url': 'https://www.anthropic.com/careers'},\n",
       "  {'type': 'team page', 'url': 'https://www.anthropic.com/team'},\n",
       "  {'type': 'research page', 'url': 'https://www.anthropic.com/research'},\n",
       "  {'type': 'enterprise page', 'url': 'https://www.anthropic.com/enterprise'}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Step : make the brochure!\n",
    "- Assemble all the details into another prompt to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page : \\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    print(\"Found links : \", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n {link['type']} \\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links :  {'links': [{'type': 'about page', 'url': 'https://www.anthropic.com/company'}, {'type': 'careers page', 'url': 'https://www.anthropic.com/careers'}, {'type': 'team page', 'url': 'https://www.anthropic.com/team'}, {'type': 'research page', 'url': 'https://www.anthropic.com/research'}]}\n",
      "Landing page : \n",
      "Webpage Title : \n",
      " Home \\ Anthropic \n",
      " Webpage Contents : \n",
      " Claude\n",
      "Overview\n",
      "Team\n",
      "Enterprise\n",
      "API\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Careers\n",
      "News\n",
      "Try Claude\n",
      "AI\n",
      "research\n",
      "and\n",
      "products\n",
      "that put safety at the frontier\n",
      "Claude.ai\n",
      "Meet Claude 3.5 Sonnet\n",
      "Claude 3.5 Sonnet, our most intelligent AI model, is now available.\n",
      "Talk to Claude\n",
      "API\n",
      "Build with Claude\n",
      "Create AI-powered applications and custom experiences using Claude.\n",
      "Learn more\n",
      "Announcements\n",
      "Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku\n",
      "Oct 22, 2024\n",
      "Model updates\n",
      "3.5 Sonnet\n",
      "3.5 Haiku\n",
      "Our Work\n",
      "Product\n",
      "Claude for Enterprise\n",
      "Sep 4, 2024\n",
      "Alignment\n",
      "·\n",
      "Research\n",
      "Constitutional AI: Harmlessness from AI Feedback\n",
      "Dec 15, 2022\n",
      "Announcements\n",
      "Core Views on AI Safety: When, Why, What, and How\n",
      "Mar 8, 2023\n",
      "Work with Anthropic\n",
      "Anthropic is an AI safety and research company based in San Francisco. Our interdisciplinary team has experience across ML, physics, policy, and product. Together, we generate research and create reliable, beneficial AI systems.\n",
      "See open roles\n",
      "Claude\n",
      "API\n",
      "Team\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Customers\n",
      "News\n",
      "Careers\n",
      "Press Inquiries\n",
      "Support\n",
      "Status\n",
      "Availability\n",
      "Twitter\n",
      "LinkedIn\n",
      "YouTube\n",
      "Terms of Service – Consumer\n",
      "Terms of Service – Commercial\n",
      "Privacy Policy\n",
      "Usage Policy\n",
      "Responsible Disclosure Policy\n",
      "Compliance\n",
      "Privacy Choices\n",
      "© 2025 Anthropic PBC \n",
      "\n",
      "\n",
      "\n",
      " about page \n",
      "Webpage Title : \n",
      " Company \\ Anthropic \n",
      " Webpage Contents : \n",
      " Claude\n",
      "Overview\n",
      "Team\n",
      "Enterprise\n",
      "API\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Careers\n",
      "News\n",
      "Try Claude\n",
      "Making AI systems\n",
      "you can rely on\n",
      "Anthropic is an AI safety and research company. We build reliable, interpretable, and steerable AI systems.\n",
      "Join us\n",
      "Our Purpose\n",
      "We believe AI will have a vast impact on the world. Anthropic is dedicated to building systems that people can rely on and generating research about the opportunities and risks of AI.\n",
      "We Build Safer Systems\n",
      "We aim to build frontier AI systems that are reliable, interpretable, and steerable. We conduct frontier research, develop and apply a variety of safety techniques, and deploy the resulting systems via a set of partnerships and products.\n",
      "Safety Is a Science\n",
      "We treat AI safety as a systematic science, conducting research, applying it to our products, feeding those insights back into our research, and regularly sharing what we learn with the world along the way.\n",
      "Interdisciplinary\n",
      "Anthropic is a collaborative team of researchers, engineers, policy experts, business leaders and operators, who bring our experience from many different domains to our work.\n",
      "AI Companies are One Piece of a Big Puzzle\n",
      "AI has the potential to fundamentally change how the world works. We view ourselves as just one piece of this evolving puzzle. We collaborate with civil society, government, academia, nonprofits and industry to promote safety industry-wide.\n",
      "The Team\n",
      "We’re a team of researchers, engineers, policy experts and operational leaders, with experience spanning a variety of disciplines, all working together to build reliable and understandable AI systems.\n",
      "Research\n",
      "We conduct frontier AI research across a variety of modalities, and explore novel and emerging safety research areas from interpretability to RL from human feedback to policy and societal impacts analysis.\n",
      "Policy\n",
      "We think about the impacts of our work and strive to communicate what we’re seeing at the frontier to policymakers and civil society in the US and abroad to help promote safe and reliable AI.\n",
      "Product\n",
      "We translate our research into tangible, practical tools like Claude that benefit businesses, nonprofits and civil society groups and their clients and people around the globe.\n",
      "Operations\n",
      "Our people, finance, legal, and recruiting teams are the human engines that make Anthropic go. We’ve had previous careers at NASA, startups, and the armed forces and our diverse experiences help make Anthropic a great place to work (and we love plants!).\n",
      "Our Values\n",
      "01\n",
      "Here for the mission\n",
      "Anthropic exists for our mission: to ensure transformative AI helps people and society flourish. Progress this decade may be rapid, and we expect increasingly capable systems to pose novel challenges. We pursue our mission by building frontier systems, studying their behaviors, working to responsibly deploy them, and regularly sharing our safety insights. We collaborate with other projects and stakeholders seeking a similar outcome.\n",
      "02\n",
      "Unusually high trust\n",
      "Our company is an unusually high trust environment: we assume good faith, disagree kindly, and prioritize honesty. We expect emotional maturity and intellectual openness. At its best, our trust enables us to make better decisions as an organization than any one of us could as individuals.\n",
      "03\n",
      "One big team\n",
      "Collaboration is central to our work, culture, and value proposition. While we have many teams at Anthropic, we feel the broader sense in which we are all on the same team working together towards the mission. Leadership sets the strategy, with broad input from everyone, and trusts each piece of the organization to pursue these goals in their unique style. Individuals commonly contribute to work across many different areas.\n",
      "04\n",
      "Do the simple thing that works\n",
      "We celebrate trying the simple thing before the clever, novel thing. We embrace pragmatism - sensible, practical approaches that acknowledge tradeoffs. We love empiricism - finding out what actually works by trying it - and apply this to our research, our engineering and our collaboration. We aim to be open about what we understand and what we don’t.\n",
      "Governance\n",
      "Anthropic is a Public Benefit Corporation, whose purpose is the responsible development and maintenance of advanced AI for the long-term benefit of humanity. Our Board of Directors is elected by stockholders and our Long-Term Benefit Trust, as explained\n",
      "here.\n",
      "Current members of the Board and the Long-Term Benefit Trust (LTBT) are listed below.\n",
      "Anthropic Board of Directors\n",
      "Dario Amodei, Daniela Amodei, Yasmin Razavi, and Jay Kreps.\n",
      "LTBT Trustees\n",
      "Neil Buddy Shah, Kanika Bahl, and Zach Robinson.\n",
      "Company News\n",
      "See All\n",
      "Announcements\n",
      "Anthropic achieves ISO 42001 certification for responsible AI\n",
      "Jan 13, 2025\n",
      "Announcements\n",
      "Introducing the Model Context Protocol\n",
      "Nov 25, 2024\n",
      "Announcements\n",
      "Powering the next generation of AI development with AWS\n",
      "Nov 22, 2024\n",
      "Want to help us build the future of safe AI?\n",
      "Join us\n",
      "Claude\n",
      "API\n",
      "Team\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Customers\n",
      "News\n",
      "Careers\n",
      "Press Inquiries\n",
      "Support\n",
      "Status\n",
      "Availability\n",
      "Twitter\n",
      "LinkedIn\n",
      "YouTube\n",
      "Terms of Service – Consumer\n",
      "Terms of Service – Commercial\n",
      "Privacy Policy\n",
      "Usage Policy\n",
      "Responsible Disclosure Policy\n",
      "Compliance\n",
      "Privacy Choices\n",
      "© 2025 Anthropic PBC \n",
      "\n",
      "\n",
      "\n",
      " careers page \n",
      "Webpage Title : \n",
      " Careers \\ Anthropic \n",
      " Webpage Contents : \n",
      " Claude\n",
      "Overview\n",
      "Team\n",
      "Enterprise\n",
      "API\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Careers\n",
      "News\n",
      "Try Claude\n",
      "Join the team\n",
      "making AI safe\n",
      "We’re a public benefit corporation headquartered in San Francisco. Our team’s experience spans a variety of backgrounds and disciplines, from physics and machine learning to public policy and business. We work as a cohesive team that collectively forecasts the impact and tractability of research ideas in advancing our mission.\n",
      "See open roles\n",
      "Our co-founders discuss the origins of Anthropic, the \"race to the top\" in AI development, and where AI technology will go from here.\n",
      "What We Offer\n",
      "Health & Wellness\n",
      "At Anthropic, we believe that supporting our employees is crucial to our collective success and wellbeing. That's why we offer a range of benefits to best support you and your family, now and in the future.\n",
      "Comprehensive health, dental, and vision insurance for you and your dependents\n",
      "Inclusive fertility benefits via Carrot Fertility\n",
      "22 weeks of paid parental leave\n",
      "Flexible paid time off and absence policies\n",
      "Generous mental health support for you and your dependents\n",
      "Compensation & Support\n",
      "Our goal is to foster an environment where you can thrive professionally while feeling confident that you and your loved ones are taken care of.\n",
      "Competitive salary and equity packages\n",
      "Optional equity donation matching at a 1:1 ratio, up to 25% of your equity grant\n",
      "Robust retirement plans and salary sacrifice programs with market competitive matching\n",
      "Life and income protection plans\n",
      "Additional Benefits\n",
      "$500/month flexible wellness and time saver stipend\n",
      "Commuter benefits\n",
      "Annual education stipend\n",
      "Home office stipends\n",
      "Relocation support for those moving for Anthropic\n",
      "Daily meals and snacks in the office\n",
      "What we value and how we act\n",
      "Every day, we make critical decisions that inform our ability to achieve our mission. Shaping the future of AI and, in turn, the future of our world is a responsibility and a privilege. Our values guide how we work together, the decisions we make, and ultimately how we show up for each other and work toward our mission.\n",
      "Act for the global good.\n",
      "We strive to make decisions that maximize positive outcomes for humanity in the long run. This means we’re willing to be very bold in the actions we take to ensure our technology is a robustly positive force for good. We take seriously the task of safely guiding the world through a technological revolution that has the potential to change the course of human history, and are committed to helping make this transition go well.\n",
      "Hold light and shade.\n",
      "AI has the potential to pose unprecedented risks to humanity if things go badly. It also has the potential to create unprecedented benefits for humanity if things go well. We need shade to understand and protect against the potential for bad outcomes. We need light to realize the good outcomes.\n",
      "Be good to our users.\n",
      "At Anthropic, we define “users” broadly. Users are our customers, policy-makers, Ants, and anyone impacted by the technology we build or the actions we take. We cultivate generosity and kindness in all our interactions — with each other, with our users, and with the world at large. Going above and beyond for each other, our customers, and all of the people affected by our technology is meeting expectations.\n",
      "Ignite a race to the top on safety.\n",
      "As a safety-first company, we believe that building reliable, trustworthy, and secure systems is our collective responsibility - and the market agrees. We work to inspire a ‘race to the top’ dynamic where AI developers must compete to develop the most safe and secure AI systems. We want to constantly set the industry bar for AI safety and security and drive others to do the same.\n",
      "Do the simple thing that works.\n",
      "We take an empirical approach to problems and care about the size of our impact and not the sophistication of our methods. This doesn’t mean we throw together haphazard solutions. It means we try to identify the simplest solution and iterate from there. We don’t invent a spaceship if all we need is a bicycle.\n",
      "Be helpful, honest, and harmless.\n",
      "Anthropic is a high-trust, low-ego organization. We communicate kindly and directly, assuming good intentions even in disagreement. We are thoughtful about our actions, avoiding harm and repairing relationships when needed. Everyone contributes, regardless of role. If something urgently needs to be done, the right person to do it is probably you!\n",
      "Put the mission first.\n",
      "At the end of the day, the mission is what we’re all here for. It gives us a shared purpose and allows us to act swiftly together, rather than being pulled in multiple directions by competing goals. It engenders trust and collaboration and is the final arbiter in our decisions. When it comes to our mission, none of us are bystanders. We each take personal ownership over making our mission successful.\n",
      "Technical Interviews\n",
      "The novel challenges we think about at Anthropic demand diverse expertise and perspectives. Our interview process is designed to identify thoughtful candidates who bring unique strengths to our multidisciplinary team. If you think this may describe you, we’d love to hear from you regardless of your background or experience.\n",
      "One of the most common questions we get is about whether it is worth applying to work at Anthropic if you have not worked on modern machine learning systems in the past. Yes! For some roles, ML experience is expected, but many technical staff have arrived at Anthropic with no machine learning experience. If you aren’t sure about the ML experience needed for your role, ask your recruiter.\n",
      "We use shared environments like Colab and Replit for our programming-focused interviews. We’ll be very interested in how you think through each problem and analyze the tradeoffs between possible approaches, and we’ll also expect you to write, run, and debug your solutions. You’ll be allowed to look things up in documentation or on the web, just like you usually can (which is why we’ll ask you to share your screen throughout each interview); but it’s still important to be familiar with basic syntax, standard libraries, and common idioms in the language you’re interviewing in, so that looking things up doesn’t consume too much time. Your interview process will also include non-technical questions about your experience and what motivates you, and, of course, you’ll have time to ask us about Anthropic! We can’t wait to meet you.\n",
      "Other Things\n",
      "Engineers here do lots of research, and researchers do lots of engineering\n",
      "While there’s historically been a division between engineering and research in machine learning, we think that boundary has dissolved with the advent of large models. The distribution of candidates we interview is strongly bimodal in both engineering and research experience however, and we have necessarily tailored our interview structure to that.\n",
      "If you’ve an engineering background, please apply as an engineer. You’ll perform much better in the interviews, and if you join you’ll have as much input to Anthropic’s direction and interests as anyone else.\n",
      "As evidence towards this: all of our papers have engineers as authors, and often as first author. Research and engineering hires all share a single title - ‘Member of Technical Staff’.\n",
      "We value direct evidence of ability\n",
      "If you’ve done interesting independent research, written an insightful blog post, or made substantial contributions to open-source software, put that at the top of your resume!\n",
      "Feedback\n",
      "We do not provide feedback on resumes or interviews.\n",
      "Visas\n",
      "Anthropic sponsors visas! We aren't able to sponsor them for every role and every candidate; operations roles are especially difficult to support. But if we make you an offer, we will make every effort to get you into the United States, and we retain an immigration lawyer to help with this.\n",
      "Green cards\n",
      "Once you’re eligible, we’re also keen to sponsor green cards!\n",
      "Educational backgrounds and experience vary across our team and across our roles.\n",
      "We do not require\n",
      "PhDs or previous ML experience\n",
      "— About half of Anthropic technical staff have a PhD of some sort; about half had prior experience in ML. We have several brilliant colleagues who never went to college.\n",
      "Remote interviewing\n",
      "All our interviews are conducted over Google Meet. We prefer PST office hours, but we can be flexible if that’s difficult for you.\n",
      "Re-applying\n",
      "Similarly, if interviews don’t work out this time, you’re welcome to re-apply after 12 months, and earlier if something materially changes about your experience or skills.\n",
      "Remote work\n",
      "Anthropic staff all come to the office regularly. Most staff live in the Bay Area, though a few live further away and come in for one week a month. We also understand that moving can take time, so as a transitional phase some folks start while fully remote.\n",
      "Offer timing\n",
      "If we make an offer, we’re happy to give you time to think about it and finish up any other interview processes you’re going through.\n",
      "Internships\n",
      "We do not offer internships.\n",
      "Candidate Privacy Policy\n",
      "US Candidate Privacy Policy\n",
      "UK Employee and Candidate Privacy Policy\n",
      "Claude\n",
      "API\n",
      "Team\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Customers\n",
      "News\n",
      "Careers\n",
      "Press Inquiries\n",
      "Support\n",
      "Status\n",
      "Availability\n",
      "Twitter\n",
      "LinkedIn\n",
      "YouTube\n",
      "Terms of Service – Consumer\n",
      "Terms of Service – Commercial\n",
      "Privacy Policy\n",
      "Usage Policy\n",
      "Responsible Disclosure Policy\n",
      "Compliance\n",
      "Privacy Choices\n",
      "© 2025 Anthropic PBC \n",
      "\n",
      "\n",
      "\n",
      " team page \n",
      "Webpage Title : \n",
      " Team up with Claude \\ Anthropic \n",
      " Webpage Contents : \n",
      " Claude\n",
      "Overview\n",
      "Team\n",
      "Enterprise\n",
      "API\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Careers\n",
      "News\n",
      "Try Claude\n",
      "Team up with Claude\n",
      "Shorten the path from idea to impact with an AI assistant that taps into your team’s shared expertise.\n",
      "Get started\n",
      "Request demo\n",
      "Easy collaboration for better outcomes\n",
      "Claude doesn’t just speed up daily tasks like writing emails or docs. It’s a virtual teammate that moves work forward using your team’s knowledge.\n",
      "Create with Claude\n",
      "Claude can be a sounding board for your ideas, help you generate new ones, and pull insights from data in a snap.\n",
      "Prime the canvas\n",
      "Use Projects to ground Claude in specific knowledge that helps you produce higher-quality work with less effort.\n",
      "Spark inspiration\n",
      "Share your best chats with Claude across the team to spark creativity and improve your project deliverables.\n",
      "Transform how you work\n",
      "Claude makes work more productive—whether you need a partner for deep work, a creative collaborator, or an assistant for daily tasks.\n",
      "Create with Claude\n",
      "Draft and iterate on documents, code and websites, and images alongside your chat with Artifacts.\n",
      "Write and debug code\n",
      "Create marketing campaigns\n",
      "Draft job descriptions\n",
      "Build interactive visualizations\n",
      "Transform how your team works\n",
      "Claude can serve as your go-to expert, empowering each team member with shared knowledge from all across the organization.\n",
      "Prime the canvas\n",
      "Create Projects and add knowledge so each person on the team can deliver expert-level results.\n",
      "Find and summarize information faster\n",
      "Use Claude as your subject-matter expert\n",
      "Expand how each teammate can contribute\n",
      "Spark inspiration\n",
      "Share your best chats with everyone on the Project to spark better ideas, iterate on Artifacts, and move work forward.\n",
      "Brainstorm on new product ideas\n",
      "Discuss insights from user interviews\n",
      "Collaborate on hard research questions\n",
      "Every team can work with Claude\n",
      "Engineering\n",
      "Generate code snippets in seconds\n",
      "Create clear, comprehensive docs with no effort\n",
      "Get help debugging even the most complex issues\n",
      "Turn product feedback into roadmap items faster\n",
      "Support\n",
      "Resolve customer issues in record time\n",
      "Craft personalized responses effortlessly\n",
      "Build a dynamic, user-friendly knowledge base\n",
      "Generate insightful metrics reports instantly\n",
      "Marketing\n",
      "Create engaging content tailored to your audience\n",
      "Segment customers with pinpoint accuracy\n",
      "Analyze competitors with unparalleled depth\n",
      "Optimize campaigns for maximum ROI\n",
      "Sales\n",
      "Customize pitches for any customer segment\n",
      "Uncover hidden sales trends effortlessly\n",
      "Draft compelling follow-up emails in seconds\n",
      "Get comprehensive competitor insights on demand\n",
      "By leveraging content from our help center in Projects, we were able to generate comprehensive standard operating procedures for our core workflows in just a few hours—a task that previously took our team weeks to complete.\n",
      "Bradley Silicani\n",
      "COO, Anrok\n",
      "Claude Team is transforming our way of working at North Highland. Claude is a truly exceptional writer that has helped our team complete content creation and analysis tasks up to 5x faster than before—turning what was once two weeks of writing and research into minutes of work.\n",
      "Luka Anic\n",
      "Senior Director, Technical AI Program and Product Manager, North Highland\n",
      "Generating content, completing creative tasks, and creating summarized reports is much easier than before. There are many other areas of our business—like engineering, legal, risk and compliance—where we're excited to see what Claude can do.\n",
      "Olga Pirog\n",
      "Head of AI Transformation, IG Group\n",
      "Join the teams transforming with Claude\n",
      "See Pricing\n",
      "Claude\n",
      "API\n",
      "Team\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Customers\n",
      "News\n",
      "Careers\n",
      "Press Inquiries\n",
      "Support\n",
      "Status\n",
      "Availability\n",
      "Twitter\n",
      "LinkedIn\n",
      "YouTube\n",
      "Terms of Service – Consumer\n",
      "Terms of Service – Commercial\n",
      "Privacy Policy\n",
      "Usage Policy\n",
      "Responsible Disclosure Policy\n",
      "Compliance\n",
      "Privacy Choices\n",
      "© 2025 Anthropic PBC \n",
      "\n",
      "\n",
      "\n",
      " research page \n",
      "Webpage Title : \n",
      " Research \\ Anthropic \n",
      " Webpage Contents : \n",
      " Claude\n",
      "Overview\n",
      "Team\n",
      "Enterprise\n",
      "API\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Careers\n",
      "News\n",
      "Try Claude\n",
      "Researching\n",
      "at the frontier\n",
      "At Anthropic, we develop large-scale AI systems, and our research teams help us to create safer, steerable, and more reliable models.\n",
      "See open roles\n",
      "Claude\n",
      "API\n",
      "Team\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Customers\n",
      "News\n",
      "Careers\n",
      "Press Inquiries\n",
      "Support\n",
      "Status\n",
      "Availability\n",
      "Twitter\n",
      "LinkedIn\n",
      "YouTube\n",
      "Terms of Service – Consumer\n",
      "Terms of Service – Commercial\n",
      "Privacy Policy\n",
      "Usage Policy\n",
      "Responsible Disclosure Policy\n",
      "Compliance\n",
      "Privacy Choices\n",
      "© 2025 Anthropic PBC \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_all_details(\"https://anthropic.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a comany called : {company_name} \\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links :  {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'blog', 'url': 'https://huggingface.co/blog'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'docs page', 'url': 'https://huggingface.co/docs'}, {'type': 'community forum', 'url': 'https://discuss.huggingface.co'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You are looking at a comany called : HuggingFace \\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page : \\nWebpage Title : \\n Hugging Face – The AI community building the future. \\n Webpage Contents : \\n Hugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nNEW\\nWelcome to Inference Providers on the Hub 🔥\\nsmolagents - a smol library to build great agents\\nUse models from the HF Hub in LM Studio\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nTrending on\\nthis week\\nModels\\ndeepseek-ai/DeepSeek-R1\\nUpdated\\n1 day ago\\n•\\n845k\\n•\\n6k\\ndeepseek-ai/Janus-Pro-7B\\nUpdated\\n1 day ago\\n•\\n134k\\n•\\n2.36k\\ndeepseek-ai/DeepSeek-V3\\nUpdated\\n9 days ago\\n•\\n877k\\n•\\n3.01k\\nmistralai/Mistral-Small-24B-Instruct-2501\\nUpdated\\nabout 2 hours ago\\n•\\n12.1k\\n•\\n474\\nunsloth/DeepSeek-R1-GGUF\\nUpdated\\n3 days ago\\n•\\n262k\\n•\\n469\\nBrowse 400k+ models\\nSpaces\\nRunning\\non\\nZero\\n1.21k\\n🌍\\nChat With Janus-Pro-7B\\nA unified multimodal understanding and generation model.\\nRunning\\non\\nZero\\n1.13k\\n🌍\\nHunyuan3D-2.0\\nText-to-3D and Image-to-3D Generation\\nRunning\\non\\nZero\\n2.35k\\n📈\\nIC Light V2\\nRunning\\n318\\n🐢\\nQwen2.5 Max Demo\\nRunning\\non\\nZero\\n1.83k\\n❤️\\nKokoro TTS\\nUpgraded to v1.0!\\nBrowse 150k+ applications\\nDatasets\\nopen-thoughts/OpenThoughts-114k\\nUpdated\\n4 days ago\\n•\\n11.4k\\n•\\n191\\nfka/awesome-chatgpt-prompts\\nUpdated\\n28 days ago\\n•\\n8.91k\\n•\\n7.27k\\ncognitivecomputations/dolphin-r1\\nUpdated\\n3 days ago\\n•\\n436\\n•\\n136\\nServiceNow-AI/R1-Distill-SFT\\nUpdated\\n5 days ago\\n•\\n1.16k\\n•\\n119\\nbespokelabs/Bespoke-Stratos-17k\\nUpdated\\n3 days ago\\n•\\n21.3k\\n•\\n178\\nBrowse 100k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nEnterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n•\\n381 models\\n•\\n2.07k followers\\nAI at Meta\\nEnterprise\\ncompany\\n•\\n2.06k models\\n•\\n4.36k followers\\nAmazon Web Services\\ncompany\\n•\\n20 models\\n•\\n2.64k followers\\nGoogle\\ncompany\\n•\\n913 models\\n•\\n7.12k followers\\nIntel\\ncompany\\n•\\n218 models\\n•\\n2.19k followers\\nMicrosoft\\ncompany\\n•\\n354 models\\n•\\n7.98k followers\\nGrammarly\\ncompany\\n•\\n10 models\\n•\\n119 followers\\nWriter\\nEnterprise\\ncompany\\n•\\n19 models\\n•\\n203 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n138,440\\nState-of-the-art ML for Pytorch, TensorFlow, and JAX.\\nDiffusers\\n27,347\\nState-of-the-art diffusion models for image and audio generation in PyTorch.\\nSafetensors\\n3,048\\nSimple, safe way to store and distribute neural networks weights safely and quickly.\\nHub Python Library\\n2,286\\nClient library for the HF Hub: manage repositories from your Python runtime.\\nTokenizers\\n9,322\\nFast tokenizers, optimized for both research and production.\\nPEFT\\n17,125\\nParameter efficient finetuning methods for large models.\\nTransformers.js\\n12,785\\nState-of-the-art Machine Learning for the web. Run Transformers directly in your browser, with no need for a server.\\ntimm\\n33,043\\nState-of-the-art computer vision models, layers, optimizers, training/evaluation, and utilities.\\nTRL\\n10,970\\nTrain transformer language models with reinforcement learning.\\nDatasets\\n19,534\\nAccess and share datasets for computer vision, audio, and NLP tasks.\\nText Generation Inference\\n9,682\\nToolkit to serve Large Language Models.\\nAccelerate\\n8,251\\nEasily train and use PyTorch models with multi-GPU, TPU, mixed-precision.\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nTasks\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord \\n\\n\\n\\n about page \\nWebpage Title : \\n huggingface (Hugging Face) \\n Webpage Contents : \\n Hugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nHugging Face\\nEnterprise\\ncompany\\nVerified\\nhttps://huggingface.co\\nhuggingface\\nhuggingface\\nActivity Feed\\nFollow\\n16,469\\nAI & ML interests\\nThe AI community building the future.\\nRecent Activity\\nnielsr\\nupdated\\na dataset\\nabout 4 hours ago\\nhuggingface/community-science-merged\\nm-ric\\nupdated\\na dataset\\n2 days ago\\nhuggingface/documentation-images\\npcuenq\\nnew\\nactivity\\n2 days ago\\nhuggingface/'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_broucher(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links :  {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Brochure\n",
       "\n",
       "## Welcome to Hugging Face!\n",
       "\n",
       "### The AI Community Building the Future\n",
       "Hugging Face is a collaborative platform where the machine learning community can come together to develop, share, and improve upon models, datasets, and applications. With over **400K+ models** and **100K+ datasets**, we aim to accelerate machine learning innovation.\n",
       "\n",
       "---\n",
       "\n",
       "### Our Offerings\n",
       "\n",
       "- **Models**: Explore a wide variety of models tailored for diverse tasks, including deep learning for images, text generation, and more. \n",
       "- **Datasets**: Access a robust collection of datasets to facilitate your machine learning projects.\n",
       "- **Spaces**: Create and discover applications that utilize state-of-the-art machine learning models.\n",
       "- **Enterprise Solutions**: Unlock advanced tools for your team, complete with enterprise-grade security, dedicated support, and access to optimized computing resources.\n",
       "\n",
       "---\n",
       "\n",
       "### Community Engagement\n",
       "At Hugging Face, we believe in the power of open-source collaboration. We are building foundational AI tools alongside a vibrant community of over **50,000 organizations** that trust our platform, including leading names like Amazon Web Services, Google, and Microsoft.\n",
       "\n",
       "- **Open Source**: Engage with a variety of open-source libraries such as Transformers, Diffusers, and more, which have fostered significant contributions from users worldwide.\n",
       "\n",
       "---\n",
       "\n",
       "### Culture & Values\n",
       "\n",
       "- **Collaboration**: We prioritize community efforts to ensure machine learning progresses through shared knowledge and contributions.\n",
       "- **Innovation**: Hugging Face is dedicated to pushing the boundaries of what's possible in AI, encouraging creativity and cutting-edge research.\n",
       "- **Supportive Environment**: We foster a culture of inclusiveness and ongoing learning, where every voice matters.\n",
       "\n",
       "---\n",
       "\n",
       "### Careers at Hugging Face\n",
       "Join us on our mission to create a future driven by AI! We are always looking for talented individuals passionate about machine learning. \n",
       "\n",
       "- **Current Openings**: From research scientists to engineering roles, a variety of opportunities await those eager to innovate in the AI space.\n",
       "- **Why Join Us?**: Enjoy a flexible work environment, competitive benefits, and the chance to work alongside industry-leading experts.\n",
       "\n",
       "---\n",
       "\n",
       "### Let's Connect\n",
       "Become a part of the Hugging Face community:\n",
       "- **Website**: [huggingface.co](https://huggingface.co)\n",
       "- **Social Media**: Follow us on Twitter, LinkedIn, and Discord to stay connected.\n",
       "\n",
       "---\n",
       "\n",
       "Embark on your journey in the AI community with Hugging Face. Together, we can build the future!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_broucher(\"HuggingFace\", \"https://huggingface.co\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Streaming response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model= \"gpt-4o-mini\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "        stream= True\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links :  {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'documentation page', 'url': 'https://huggingface.co/docs'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Brochure\n",
       "\n",
       "Welcome to **Hugging Face**, the AI community building the future. Our mission is to create a collaborative platform where the machine learning community can come together to contribute models, datasets, and applications.\n",
       "\n",
       "## Company Overview\n",
       "\n",
       "**Hugging Face** serves as a home for machine learning, offering resources for developers, researchers, and enterprises. Our platform hosts over 400,000 models and 100,000 datasets, making it a treasure cache for anyone interested in advancing their AI capabilities.\n",
       "\n",
       "## What We Offer\n",
       "\n",
       "- **Models**: Access to a diverse collection of state-of-the-art AI models across various domains.\n",
       "- **Datasets**: Browse an extensive library with over 100k datasets tailored for machine learning tasks.\n",
       "- **Spaces**: Collaborate and run ML applications seamlessly on our robust infrastructure.\n",
       "- **Enterprise Solutions**: Custom solutions with enterprise-grade security and dedicated support.\n",
       "\n",
       "### Community Engagement\n",
       "\n",
       "We believe in the power of collaboration. Our open-source contributions allow users to:\n",
       "- Build and share their ML projects publicly.\n",
       "- Explore different modalities including text, image, video, audio, and even 3D.\n",
       "- Create and enhance their personal ML portfolios.\n",
       "\n",
       "## Who Uses Hugging Face?\n",
       "\n",
       "More than **50,000 organizations** rely on Hugging Face, including industry giants like:\n",
       "- Meta\n",
       "- Amazon Web Services\n",
       "- Google\n",
       "- Microsoft\n",
       "- Intel\n",
       "\n",
       "Join a vibrant community that includes non-profits like **AI2** and innovative enterprises to drive the future of AI.\n",
       "\n",
       "## Company Culture\n",
       "\n",
       "At Hugging Face, we foster a culture of openness and innovation. Our community is built on transparency, collaboration, and a commitment to pushing the boundaries of what AI can achieve. We believe that great ideas come from everyone, and we encourage all members to share their insights and contributions.\n",
       "\n",
       "### Careers at Hugging Face\n",
       "\n",
       "We are always on the lookout for passionate individuals to join our diverse team. If you are enthusiastic about machine learning and want to contribute to a transformative field, check out our **[Jobs Page](https://huggingface.co/jobs)** for current openings and learn how you can be a part of our mission.\n",
       "\n",
       "---\n",
       "\n",
       "For more information, visit our website at [Hugging Face](https://huggingface.co), and join us in building the future of AI. \n",
       "\n",
       "**Connect with Us:**\n",
       "- [GitHub](https://github.com/huggingface)\n",
       "- [Twitter](https://twitter.com/huggingface)\n",
       "- [LinkedIn](https://linkedin.com/company/huggingface)\n",
       "- [Discord](https://discord.gg/huggingface)\n",
       "\n",
       "Together, let’s accelerate the advancement of machine learning and facilitate a collective journey towards innovation in AI!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
